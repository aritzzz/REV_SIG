{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(input, only_char=True, lower=True, stop_remove=True, stemming=False):\n",
    "    input = re.sub(r'[^\\x00-\\x7F]+',' ', input)\n",
    "    if lower: input = input.lower()\n",
    "    if only_char:\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        tokens = tokenizer.tokenize(input)\n",
    "        input = ' '.join(tokens)\n",
    "    tokens = word_tokenize(input)\n",
    "    if stop_remove:\n",
    "        tokens = [w for w in tokens if not w in stopwords.words('english')]\n",
    "\n",
    "    # also remove one-length word\n",
    "    tokens = [w for w in tokens if len(w) > 1]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "columns = ['RECOMMENDATION', 'comments', 'CONFIDENCE', 'Layer 1', 'Layer 1 N', 'Layer 2', 'Layer 2 N', 'Layer 3',\n",
    "       'Layer 3 N']\n",
    "reviews = pd.read_csv('Test_Reviews.csv', usecols=columns)\n",
    "reviews_l = reviews[reviews['Layer 1 N'] < 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev1 = json.load(open('R2.json'))['review']\n",
    "rev2 = json.load(open('R1.json'))['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev1, rev2 =  preprocess(rev1), preprocess(rev2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper studies learning play two player general sum games state markov games imperfect information idea learn cooperate think prisoner dilemma complex domains generally repeated prisoner dilemma one punish one opponent noncooperation paper design apporach learn cooperate complex game like hybrid pong meets prisoner dilemma game fun find particularly surprising game theoretic deep learning point view nfrom game theoretic point view paper begins game theoretic analysis cooperative strategy markov games imperfect information basically straightforward generalization idea punishing common folk theorems game theory give particular equilibrium cooperating markov games many markov games cooperative equilibrium paper restricts attention even games cooperative solution maximizes total welfare clear players would choose game symmetric might natural solution general far clear players would want maximize total payoff nthe paper follows fun experiments implementing new game theory notions unfortunately since game theory particularly well motivated find overall story compelling perhaps interesting one make deep learning learn cooperate imperfect information one could illustrated game theory equally well techniques nin contrast paper coco learning stochastic games side payments sodomka et al example took well motivated game theoretic cooperative solution concept explored implement reinforcement learning would think generalizing solution concepts stochastic games deep learning might interesting nit also noted asked review another iclr submission entitled maintaining cooperation complex social dilemmas using deep reinforcement learning amazingly introduced pong player u2019s dilemma game paper nnotice following suspiciously similar paragraphs two papers nfrom maintaining cooperation complex social dilemmas using deep reinforcement learning nwe also look environment strategies must learned raw pixels use method nof tampuu et al 2017 alter reward structure atari pong whenever agent scores npoint receive reward player receives u22122 refer game pong nplayer u2019s dilemma ppd ppd jointly winning move play however fully ncooperative agent exploited defector nfrom consequentialist conditional cooperation social dilemmas imperfect information nto demonstrate follow method tampuu et al 2017 construct version atari pong nwhich makes game social dilemma call pong player u2019s dilemma ppd agent nscores gain reward partner receives reward u22122 thus ppd jointly winning nmove play selfish agents tempted defect try score points even though nthis decreases total social reward see ccc successful robust simple strategy ngame\n"
     ]
    }
   ],
   "source": [
    "print(rev1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper proposes novel adaptive learning mechanism improve results ergodic cooperation games algorithm tagged consequentialist conditional cooperation uses outcome based accumulative rewards different strategies established prior training core benefit adaptiveness towards diverse opposing player strategies selfish prosocial ccc maintaining maximum reward nwhile contribution explored technical complexity fundamentally algorithm exploits policies selfish prosocial strategies determine expected rewards training phase operation switches strategy depending dynamically calculated threshold reward value considering variation agent specific policies initial game states stochasticity rewards relative total reward played game instance work contrasted tit tat approaches require complete observability operate based expected future rewards addition observability approximate markov tft amtft methods processing intense since fall back game function opposed learned policies making ccc lightweight alternative ncomments nthe findings suggest effectiveness approach experiments ccc based agents fare better agents operating based specific strategy performing worse amtft approach working well larger number iterations outcome based evaluation shows benefits specifically ppd game use ccc produces interesting results paired cooperate agents ppd game ccc based players produce higher overall reward pairing cooperative players see figure explained improve understanding ccc based operation would worthwhile provide additional graph shows action choices ccc agents time clarify behavioural characteristics convergence performance nhowever paired non cooperative players risky ppd game ccc players lead improvement pay offs around 50 percent see figure compared payoff received non cooperative players 28 vs 18 relative defection leads question much ccc perform compared random policy selection given reduction processing intensive need larger number iterations much worse random choice processing independent iterations would worthwhile appreciate benefit proposed approach nanother point relates fishing game game parameterized rewards bases parameter choices would happen higher reward interestingly game extended allow agents fish medium sized fish addition small large fish would interesting see ccc fares combinations cooperators defectors noverall paper well written explores technical details presented approach authors position approach well within contemporary literature conceptually using experimental evaluation explicit strengths limitations npresentation aspects minor typo page last paragraph introduction act act identically figure shifted next page since self explanatory requires context\n"
     ]
    }
   ],
   "source": [
    "print(rev2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By9iRkWA-\n",
      "ByCPHrgCW\n",
      "HktRlUlAZ\n",
      "Hk0wHx-RW\n",
      "B1X0mzZCW\n",
      "B1X4DWWRb\n",
      "HytSvlWRZ\n",
      "BkUHlMZ0b\n",
      "HyUNwulC-\n",
      "HkmaTz-0W\n",
      "BkXmYfbAZ\n",
      "BJDEbngCZ\n",
      "BJ4prNx0W\n",
      "HkeJVllRW\n",
      "BkDB51WR-\n",
      "HkwZSG-CZ\n",
      "HkxF5RgC-\n",
      "HkwBEMWCZ\n",
      "SyProzZAW\n",
      "H1a37GWCZ\n",
      "HyH9lbZAW\n",
      "HyWrIgW0W\n",
      "ByQpn1ZA-\n",
      "BJRZzFlRb\n",
      "ByrZyglCb\n",
      "Bys_NzbC-\n",
      "BJJ9bz-0-\n",
      "H1cKvl-Rb\n",
      "SySaJ0xCZ\n",
      "H1MczcgR-\n",
      "BJj6qGbRW\n",
      "BypdvewVM\n",
      "B1kIr-WRb\n",
      "H1DGha1CZ\n",
      "B1p461b0W\n",
      "Bym0cU1CZ\n",
      "HyI6s40a-\n",
      "Sy4c-3xRW\n",
      "B14TlG-RW\n",
      "HkL7n1-0b\n",
      "Hk2aImxAb\n",
      "B1IDRdeCW\n",
      "B1Gi6LeRZ\n",
      "BJcAWaeCW\n",
      "Bya8fGWAZ\n",
      "HkpYwMZRb\n",
      "B1bgpzZAZ\n",
      "HyB9Np6WG\n",
      "Byni8NLHf\n",
      "HknbyQbC-\n",
      "HJsk5-Z0W\n",
      "BkVsWbbAW\n",
      "Hy_o3x-0b\n",
      "HyiS6k-CW\n",
      "HyI5ro0pW\n",
      "H1VjBebR-\n",
      "SySisz-CW\n",
      "H1U_af-0-\n",
      "HyPpD0g0Z\n",
      "B13njo1R-\n",
      "H1srNebAZ\n",
      "H1wt9x-RW\n",
      "Sy21R9JAW\n",
      "BkPrDFgR-\n",
      "Hk5elxbRW\n",
      "Syhr6pxCW\n",
      "Hy6GHpkCW\n",
      "HkOhuyA6-\n",
      "By3VrbbAb\n",
      "BJy0fcgRZ\n",
      "BywyFQlAW\n",
      "B1hcZZ-AW\n",
      "Bk8ZcAxR-\n",
      "BkQCGzZ0-\n",
      "Sy3nGCYXz\n",
      "BkVf1AeAZ\n",
      "Sy-tszZRZ\n",
      "Hk__kGbCW\n",
      "BJyy3a0Ez\n",
      "BJk59JZ0b\n",
      "HyN-ZvlC-\n",
      "BJ_UL-k0b\n",
      "ByzvHagA-\n",
      "BJjBnN9a-\n",
      "H1bM1fZCW\n",
      "Hyp-JJJRW\n",
      "Hkc-TeZ0W\n",
      "H1Yp-j1Cb\n",
      "BJQRKzbA-\n",
      "SyJS-OgR-\n",
      "H18uzzWAZ\n",
      "H1sUHgb0Z\n",
      "H1K6Tb-AZ\n",
      "B1ydPgTpW\n",
      "HklZOfW0W\n",
      "BkbOsNeSM\n",
      "BykJlIAbM\n",
      "H1vCXOe0b\n",
      "BkrSv0lA-\n",
      "BkQqq0gRb\n",
      "HyXBcYg0b\n",
      "BySRH6CpW\n",
      "Hyig0zb0Z\n",
      "BJjquybCW\n",
      "H13WofbAb\n",
      "Bk_fs6gA-\n",
      "By03VlJGG\n",
      "BJRxfZbAW\n",
      "B1J_rgWRW\n",
      "HyrCWeWCb\n",
      "Bkl1uWb0Z\n",
      "HkcTe-bR-\n",
      "H1BHbmWCZ\n",
      "Bk9zbyZCZ\n",
      "B1nLkl-0Z\n",
      "HJ8W1Q-0Z\n",
      "BJ8c3f-0b\n",
      "B1l8BtlCb\n",
      "H1BO9M-0Z\n",
      "HkjL6MiTb\n",
      "H1A5ztj3b\n",
      "By4HsfWAZ\n",
      "Bki1Ct1AW\n",
      "H1eJxngCW\n",
      "Bys4ob-Rb\n",
      "BJGWO9k0Z\n",
      "H1-IBSgMz\n",
      "HyRVBzap-\n",
      "B1G6uM0WG\n",
      "By3v9k-RZ\n",
      "HkGJUXb0-\n",
      "HJ1HFlZAb\n",
      "B1D6ty-A-\n",
      "HkgNdt26Z\n",
      "HyDAQl-AW\n",
      "By5SY2gA-\n",
      "HyTrSegCb\n",
      "BJvWjcgAZ\n",
      "BJJLHbb0-\n",
      "B1uvH_gC-\n",
      "ByuP8yZRb\n",
      "Byk4My-RZ\n",
      "HymYLebCb\n",
      "ByL48G-AW\n",
      "HyRnez-RW\n",
      "H1DkN7ZCZ\n",
      "H1uR4GZRZ\n",
      "Byht0GbRZ\n",
      "B1CEaMbR-\n",
      "B1Z3W-b0W\n",
      "B1e5ef-C-\n",
      "B1tExikAW\n",
      "BkJ3ibb0-\n",
      "HJBhEMbRb\n",
      "SyhcXjy0Z\n",
      "HydnA1WCb\n",
      "By5ugjyCb\n",
      "BkN_r2lR-\n",
      "B1NGT8xCZ\n",
      "ByUEelW0-\n",
      "B1EGg7ZCb\n",
      "BkIkkseAZ\n",
      "HJcSzz-CZ\n",
      "HyiAuyb0b\n",
      "BkM27IxR-\n",
      "ByOnmlWC-\n",
      "BkLhaGZRW\n",
      "Hy3MvSlRW\n",
      "H1cWzoxA-\n",
      "BJ78bJZCZ\n",
      "BJ8lbVAfz\n",
      "B1tC-LT6W\n",
      "BJ_wN01C-\n",
      "B1wN2f2-G\n",
      "H1OQukZ0-\n",
      "Hk6kPgZA-\n",
      "SyrGJYlRZ\n",
      "BJ8vJebC-\n",
      "ByaQIGg0-\n",
      "HkNGsseC-\n",
      "BJB7fkWR-\n",
      "ByQZjx-0-\n",
      "H196sainb\n",
      "HkCy2uqQM\n",
      "Hyg0vbWC-\n",
      "H1pri9vTZ\n",
      "HkwVAXyCW\n",
      "HylgYB3pZ\n",
      "H1VGkIxRZ\n",
      "BJehNfW0-\n",
      "HktJec1RZ\n",
      "H1q-TM-AW\n",
      "ByhthReRb\n",
      "BJMuY-gRW\n",
      "HkZy-bW0-\n",
      "Hko85plCW\n",
      "BJhxcGZCW\n",
      "BJIgi_eCZ\n",
      "H1mCp-ZRZ\n",
      "ByxLBMZCb\n",
      "H1zriGeCZ\n",
      "H1Nyf7W0Z\n",
      "ByqFhGZCW\n",
      "HkMvEOlAb\n",
      "Hy7fDog0b\n",
      "BJInEZsTb\n",
      "BJ_QxP1AZ\n",
      "SyXNErg0W\n",
      "ByJDAIe0b\n",
      "BkabRiQpb\n",
      "BJ0hF1Z0b\n",
      "B1spAqUp-\n",
      "BJubPWZRW\n",
      "H1BLjgZCb\n",
      "BJlrSmbAZ\n",
      "H1u8fMW0b\n",
      "ByquB-WC-\n",
      "BkCV_W-AZ\n",
      "H135uzZ0-\n",
      "B1zlp1bRW\n",
      "ByuI-mW0W\n",
      "BJuWrGW0Z\n",
      "H1vEXaxA-\n",
      "HJDV5YxCW\n",
      "Hk8XMWgRb\n",
      "BkpXqwUTZ\n",
      "SyqShMZRb\n",
      "B13EC5u6W\n",
      "B1lMMx1CW\n",
      "Hyp3i2xRb\n",
      "B1twdMCab\n",
      "BkoCeqgR-\n",
      "B1al7jg0b\n",
      "H1meywxRW\n",
      "H1zRea1Mf\n",
      "BkUDW_lCb\n",
      "Hy1d-ebAb\n",
      "B1KJJf-R-\n",
      "By0ANxbRW\n",
      "H1tSsb-AW\n",
      "ByW5yxgA-\n",
      "B1nZ1weCZ\n",
      "HJ94fqApW\n",
      "B1QgVti6Z\n",
      "B1CNpYg0-\n",
      "Sy3fJXbA-\n",
      "B1QRgziT-\n",
      "HkAClQgA-\n",
      "B11bwYgfM\n",
      "HkpRBFxRb\n",
      "B12Js_yRb\n",
      "Hy8hkYeRb\n",
      "HkMCybx0-\n",
      "ByJHuTgA-\n",
      "BJaU__eCZ\n",
      "ByOExmWAb\n",
      "HyEi7bWR-\n",
      "BkBCjzp7G\n",
      "BkoXnkWAb\n",
      "HJ4IhxZAb\n",
      "SyL9u-WA-\n",
      "H1Dy---0Z\n",
      "H1uP7ebAW\n",
      "H1WgVz-AZ\n",
      "B1KFAGWAZ\n",
      "Skz_WfbCZ\n",
      "HkPCrEZ0Z\n",
      "B1nxTzbRZ\n",
      "BkrsAzWAb\n",
      "SyMvJrdaW\n",
      "SysEexbRb\n",
      "HJ3d2Ax0-\n",
      "H1Y8hhg0b\n",
      "HkSZyinVG\n",
      "HksxTdiWz\n",
      "BJ6anzb0Z\n",
      "B1EVwkqTW\n",
      "B1mSWUxR-\n",
      "Hk3ddfWRW\n",
      "ByS1VpgRZ\n",
      "HymuJz-A-\n",
      "BJOFETxR-\n",
      "B1ae1lZRb\n",
      "BkA7gfZAb\n",
      "H1dh6Ax0Z\n",
      "BJLmN8xRW\n",
      "Syt0r4bRZ\n",
      "B1DmUzWAW\n",
      "BkeC_J-R-\n",
      "BJNRFNlRW\n",
      "HyHmGyZCZ\n",
      "H1LAqMbRW\n",
      "BJDH5M-AW\n",
      "SkYXvCR6W\n",
      "Bk346Ok0W\n",
      "B1mAkPxCZ\n",
      "BydjJte0-\n",
      "B1Lc-Gb0Z\n",
      "H1-oTz-Cb\n",
      "Bk-ofQZRb\n",
      "BkS3fnl0W\n",
      "B16_iGWCW\n",
      "HkUR_y-RZ\n",
      "H1O0KGC6b\n",
      "H1aIuk-RW\n",
      "B17JTOe0-\n",
      "HyKZyYlRZ\n",
      "Bk9nkMa4G\n",
      "ByRWCqvT-\n",
      "BkUp6GZRW\n",
      "B1jscMbAW\n",
      "Syr8Qc1CW\n",
      "ByYPLJA6W\n",
      "H1bhRHeA-\n",
      "HkCvZXbC-\n",
      "SyGT_6yCZ\n",
      "H15odZ-C-\n",
      "B1n8LexRZ\n",
      "H1l8sz-AW\n",
      "HkfXMz-Ab\n",
      "Sy1f0e-R-\n",
      "HkCsm6lRb\n",
      "Hkp3uhxCW\n",
      "BJk7Gf-CZ\n",
      "B14uJzW0b\n",
      "BJgPCveAW\n",
      "SyjsLqxR-\n",
      "BkwHObbRZ\n",
      "H1T2hmZAb\n",
      "Hk2MHt-3-\n",
      "SyVOjfbRb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "reviews = []\n",
    "for paper in os.listdir('./ScoreData'):\n",
    "    print(paper)\n",
    "    rev_data = json.load(open('./ScoreData/' + paper + '/reviews.json'))\n",
    "    for r in rev_data['reviews']:\n",
    "        reviews.append(preprocess(r['comments']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('topic_tst.txt', 'w') as f:\n",
    "    for review in reviews:\n",
    "        f.write(review + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(992, 1024)\n",
      "Settings: \n",
      "               N Components: 50\n",
      "               Topic Prior Mean: 0.0\n",
      "               Topic Prior Variance: 0.98\n",
      "               Model Type: prodLDA\n",
      "               Hidden Sizes: (100, 100)\n",
      "               Activation: softplus\n",
      "               Dropout: 0.2\n",
      "               Learn Priors: True\n",
      "               Learning Rate: 0.002\n",
      "               Momentum: 0.99\n",
      "               Reduce On Plateau: False\n",
      "               Save Dir: None\n",
      "Epoch: [1/300]\tSamples: [992/297600]\tTrain Loss: 1816.9456314579134\tTime: 0:00:03.908565\n",
      "Epoch: [2/300]\tSamples: [1984/297600]\tTrain Loss: 1812.8156186995968\tTime: 0:00:03.956520\n",
      "Epoch: [3/300]\tSamples: [2976/297600]\tTrain Loss: 1809.001212827621\tTime: 0:00:04.053664\n",
      "Epoch: [4/300]\tSamples: [3968/297600]\tTrain Loss: 1802.9746841922884\tTime: 0:00:03.843488\n",
      "Epoch: [5/300]\tSamples: [4960/297600]\tTrain Loss: 1802.4796772618447\tTime: 0:00:03.863257\n",
      "Epoch: [6/300]\tSamples: [5952/297600]\tTrain Loss: 1798.1181089339718\tTime: 0:00:03.868552\n",
      "Epoch: [7/300]\tSamples: [6944/297600]\tTrain Loss: 1796.3177529611896\tTime: 0:00:03.956924\n",
      "Epoch: [8/300]\tSamples: [7936/297600]\tTrain Loss: 1788.497527091734\tTime: 0:00:03.861202\n",
      "Epoch: [9/300]\tSamples: [8928/297600]\tTrain Loss: 1780.143767326109\tTime: 0:00:03.914678\n",
      "Epoch: [10/300]\tSamples: [9920/297600]\tTrain Loss: 1775.6276067918348\tTime: 0:00:03.954789\n",
      "Epoch: [11/300]\tSamples: [10912/297600]\tTrain Loss: 1771.6238226121473\tTime: 0:00:03.875723\n",
      "Epoch: [12/300]\tSamples: [11904/297600]\tTrain Loss: 1763.596411920363\tTime: 0:00:04.000562\n",
      "Epoch: [13/300]\tSamples: [12896/297600]\tTrain Loss: 1762.9658596900201\tTime: 0:00:03.963000\n",
      "Epoch: [14/300]\tSamples: [13888/297600]\tTrain Loss: 1758.15087890625\tTime: 0:00:04.066820\n",
      "Epoch: [15/300]\tSamples: [14880/297600]\tTrain Loss: 1753.1995573966733\tTime: 0:00:03.843172\n",
      "Epoch: [16/300]\tSamples: [15872/297600]\tTrain Loss: 1748.8728893649193\tTime: 0:00:03.832505\n",
      "Epoch: [17/300]\tSamples: [16864/297600]\tTrain Loss: 1744.2568792527723\tTime: 0:00:03.839221\n",
      "Epoch: [18/300]\tSamples: [17856/297600]\tTrain Loss: 1740.1284376575102\tTime: 0:00:04.600586\n",
      "Epoch: [19/300]\tSamples: [18848/297600]\tTrain Loss: 1737.0844844695062\tTime: 0:00:03.829893\n",
      "Epoch: [20/300]\tSamples: [19840/297600]\tTrain Loss: 1738.5109154485888\tTime: 0:00:03.878500\n",
      "Epoch: [21/300]\tSamples: [20832/297600]\tTrain Loss: 1732.0146996282763\tTime: 0:00:03.836459\n",
      "Epoch: [22/300]\tSamples: [21824/297600]\tTrain Loss: 1731.5096671811996\tTime: 0:00:03.961118\n",
      "Epoch: [23/300]\tSamples: [22816/297600]\tTrain Loss: 1724.6696659211188\tTime: 0:00:03.891499\n",
      "Epoch: [24/300]\tSamples: [23808/297600]\tTrain Loss: 1726.6895830708165\tTime: 0:00:03.810687\n",
      "Epoch: [25/300]\tSamples: [24800/297600]\tTrain Loss: 1720.8451282132057\tTime: 0:00:03.873225\n",
      "Epoch: [26/300]\tSamples: [25792/297600]\tTrain Loss: 1719.7882395098286\tTime: 0:00:04.040061\n",
      "Epoch: [27/300]\tSamples: [26784/297600]\tTrain Loss: 1718.7169346963205\tTime: 0:00:03.881769\n",
      "Epoch: [28/300]\tSamples: [27776/297600]\tTrain Loss: 1720.3099837764616\tTime: 0:00:03.838517\n",
      "Epoch: [29/300]\tSamples: [28768/297600]\tTrain Loss: 1716.3324722782259\tTime: 0:00:03.797196\n",
      "Epoch: [30/300]\tSamples: [29760/297600]\tTrain Loss: 1716.1107138356854\tTime: 0:00:03.873966\n",
      "Epoch: [31/300]\tSamples: [30752/297600]\tTrain Loss: 1714.477523311492\tTime: 0:00:03.829854\n",
      "Epoch: [32/300]\tSamples: [31744/297600]\tTrain Loss: 1715.1097215221773\tTime: 0:00:03.888172\n",
      "Epoch: [33/300]\tSamples: [32736/297600]\tTrain Loss: 1709.8507828251009\tTime: 0:00:03.914340\n",
      "Epoch: [34/300]\tSamples: [33728/297600]\tTrain Loss: 1708.7271925403227\tTime: 0:00:03.840209\n",
      "Epoch: [35/300]\tSamples: [34720/297600]\tTrain Loss: 1709.5730256111392\tTime: 0:00:03.833367\n",
      "Epoch: [36/300]\tSamples: [35712/297600]\tTrain Loss: 1707.2811909337197\tTime: 0:00:03.785731\n",
      "Epoch: [37/300]\tSamples: [36704/297600]\tTrain Loss: 1707.796402469758\tTime: 0:00:03.788062\n",
      "Epoch: [38/300]\tSamples: [37696/297600]\tTrain Loss: 1705.3125118132562\tTime: 0:00:03.854445\n",
      "Epoch: [39/300]\tSamples: [38688/297600]\tTrain Loss: 1702.1560609879032\tTime: 0:00:03.830991\n",
      "Epoch: [40/300]\tSamples: [39680/297600]\tTrain Loss: 1703.2901335685483\tTime: 0:00:03.783189\n",
      "Epoch: [41/300]\tSamples: [40672/297600]\tTrain Loss: 1701.2056609122983\tTime: 0:00:03.860096\n",
      "Epoch: [42/300]\tSamples: [41664/297600]\tTrain Loss: 1698.788345829133\tTime: 0:00:03.835628\n",
      "Epoch: [43/300]\tSamples: [42656/297600]\tTrain Loss: 1697.3279556766634\tTime: 0:00:03.793384\n",
      "Epoch: [44/300]\tSamples: [43648/297600]\tTrain Loss: 1698.5003465221773\tTime: 0:00:03.839263\n",
      "Epoch: [45/300]\tSamples: [44640/297600]\tTrain Loss: 1695.2910865045362\tTime: 0:00:03.884781\n",
      "Epoch: [46/300]\tSamples: [45632/297600]\tTrain Loss: 1696.2013569493447\tTime: 0:00:03.872098\n",
      "Epoch: [47/300]\tSamples: [46624/297600]\tTrain Loss: 1693.7562216481854\tTime: 0:00:03.960123\n",
      "Epoch: [48/300]\tSamples: [47616/297600]\tTrain Loss: 1693.2108272429437\tTime: 0:00:04.081009\n",
      "Epoch: [49/300]\tSamples: [48608/297600]\tTrain Loss: 1690.8701801915322\tTime: 0:00:04.116908\n",
      "Epoch: [50/300]\tSamples: [49600/297600]\tTrain Loss: 1691.8187610257057\tTime: 0:00:03.817177\n",
      "Epoch: [51/300]\tSamples: [50592/297600]\tTrain Loss: 1688.1489533455142\tTime: 0:00:04.048506\n",
      "Epoch: [52/300]\tSamples: [51584/297600]\tTrain Loss: 1688.3619030367943\tTime: 0:00:03.828589\n",
      "Epoch: [53/300]\tSamples: [52576/297600]\tTrain Loss: 1687.9995510962701\tTime: 0:00:03.938482\n",
      "Epoch: [54/300]\tSamples: [53568/297600]\tTrain Loss: 1690.2536187941027\tTime: 0:00:03.859603\n",
      "Epoch: [55/300]\tSamples: [54560/297600]\tTrain Loss: 1687.1827077557964\tTime: 0:00:03.937028\n",
      "Epoch: [56/300]\tSamples: [55552/297600]\tTrain Loss: 1684.6270712575604\tTime: 0:00:03.851017\n",
      "Epoch: [57/300]\tSamples: [56544/297600]\tTrain Loss: 1683.3165401335687\tTime: 0:00:03.884592\n",
      "Epoch: [58/300]\tSamples: [57536/297600]\tTrain Loss: 1683.3899398311491\tTime: 0:00:03.894975\n",
      "Epoch: [59/300]\tSamples: [58528/297600]\tTrain Loss: 1682.6186050907259\tTime: 0:00:03.870883\n",
      "Epoch: [60/300]\tSamples: [59520/297600]\tTrain Loss: 1682.400658392137\tTime: 0:00:03.840044\n",
      "Epoch: [61/300]\tSamples: [60512/297600]\tTrain Loss: 1679.5053199029737\tTime: 0:00:03.854350\n",
      "Epoch: [62/300]\tSamples: [61504/297600]\tTrain Loss: 1678.5550182711693\tTime: 0:00:03.949229\n",
      "Epoch: [63/300]\tSamples: [62496/297600]\tTrain Loss: 1679.1484768775201\tTime: 0:00:03.920580\n",
      "Epoch: [64/300]\tSamples: [63488/297600]\tTrain Loss: 1676.8501173450102\tTime: 0:00:03.912846\n",
      "Epoch: [65/300]\tSamples: [64480/297600]\tTrain Loss: 1676.0259143460182\tTime: 0:00:03.911869\n",
      "Epoch: [66/300]\tSamples: [65472/297600]\tTrain Loss: 1676.1375141759072\tTime: 0:00:03.906997\n",
      "Epoch: [67/300]\tSamples: [66464/297600]\tTrain Loss: 1674.5210748487902\tTime: 0:00:03.863875\n",
      "Epoch: [68/300]\tSamples: [67456/297600]\tTrain Loss: 1675.7991825226813\tTime: 0:00:03.754297\n",
      "Epoch: [69/300]\tSamples: [68448/297600]\tTrain Loss: 1673.184349798387\tTime: 0:00:03.933058\n",
      "Epoch: [70/300]\tSamples: [69440/297600]\tTrain Loss: 1672.2399311680947\tTime: 0:00:03.814540\n",
      "Epoch: [71/300]\tSamples: [70432/297600]\tTrain Loss: 1672.0370975617438\tTime: 0:00:03.820162\n",
      "Epoch: [72/300]\tSamples: [71424/297600]\tTrain Loss: 1671.3774059664818\tTime: 0:00:03.998628\n",
      "Epoch: [73/300]\tSamples: [72416/297600]\tTrain Loss: 1670.620825982863\tTime: 0:00:03.814423\n",
      "Epoch: [74/300]\tSamples: [73408/297600]\tTrain Loss: 1672.0778769216229\tTime: 0:00:03.902839\n",
      "Epoch: [75/300]\tSamples: [74400/297600]\tTrain Loss: 1668.9266633064517\tTime: 0:00:04.288195\n",
      "Epoch: [76/300]\tSamples: [75392/297600]\tTrain Loss: 1667.7972293976813\tTime: 0:00:03.794854\n",
      "Epoch: [77/300]\tSamples: [76384/297600]\tTrain Loss: 1667.1170614919354\tTime: 0:00:03.806514\n",
      "Epoch: [78/300]\tSamples: [77376/297600]\tTrain Loss: 1664.5853074596773\tTime: 0:00:03.904339\n",
      "Epoch: [79/300]\tSamples: [78368/297600]\tTrain Loss: 1666.5244573777723\tTime: 0:00:03.837115\n",
      "Epoch: [80/300]\tSamples: [79360/297600]\tTrain Loss: 1665.1535132623487\tTime: 0:00:03.855359\n",
      "Epoch: [81/300]\tSamples: [80352/297600]\tTrain Loss: 1665.6265672253023\tTime: 0:00:03.829441\n",
      "Epoch: [82/300]\tSamples: [81344/297600]\tTrain Loss: 1664.9197052986392\tTime: 0:00:03.843406\n",
      "Epoch: [83/300]\tSamples: [82336/297600]\tTrain Loss: 1665.4078959803428\tTime: 0:00:03.794939\n",
      "Epoch: [84/300]\tSamples: [83328/297600]\tTrain Loss: 1660.4824612525201\tTime: 0:00:03.879640\n",
      "Epoch: [85/300]\tSamples: [84320/297600]\tTrain Loss: 1662.7449163621473\tTime: 0:00:03.958529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [86/300]\tSamples: [85312/297600]\tTrain Loss: 1659.9177600491432\tTime: 0:00:03.795227\n",
      "Epoch: [87/300]\tSamples: [86304/297600]\tTrain Loss: 1661.0970616494455\tTime: 0:00:03.778997\n",
      "Epoch: [88/300]\tSamples: [87296/297600]\tTrain Loss: 1660.0850436302924\tTime: 0:00:03.993491\n",
      "Epoch: [89/300]\tSamples: [88288/297600]\tTrain Loss: 1658.4351806640625\tTime: 0:00:04.046090\n",
      "Epoch: [90/300]\tSamples: [89280/297600]\tTrain Loss: 1657.2335086945563\tTime: 0:00:03.862528\n",
      "Epoch: [91/300]\tSamples: [90272/297600]\tTrain Loss: 1657.5745810231854\tTime: 0:00:03.884339\n",
      "Epoch: [92/300]\tSamples: [91264/297600]\tTrain Loss: 1655.834204889113\tTime: 0:00:03.876704\n",
      "Epoch: [93/300]\tSamples: [92256/297600]\tTrain Loss: 1656.1182664440523\tTime: 0:00:03.870112\n",
      "Epoch: [94/300]\tSamples: [93248/297600]\tTrain Loss: 1654.1579038558468\tTime: 0:00:03.931253\n",
      "Epoch: [95/300]\tSamples: [94240/297600]\tTrain Loss: 1654.955078125\tTime: 0:00:03.814517\n",
      "Epoch: [96/300]\tSamples: [95232/297600]\tTrain Loss: 1653.8741100680443\tTime: 0:00:04.263753\n",
      "Epoch: [97/300]\tSamples: [96224/297600]\tTrain Loss: 1653.9045961441532\tTime: 0:00:03.768385\n",
      "Epoch: [98/300]\tSamples: [97216/297600]\tTrain Loss: 1652.1240194997479\tTime: 0:00:03.919902\n",
      "Epoch: [99/300]\tSamples: [98208/297600]\tTrain Loss: 1653.3643405052924\tTime: 0:00:03.828677\n",
      "Epoch: [100/300]\tSamples: [99200/297600]\tTrain Loss: 1651.0057097404233\tTime: 0:00:03.817506\n",
      "Epoch: [101/300]\tSamples: [100192/297600]\tTrain Loss: 1649.1914653162803\tTime: 0:00:03.896217\n",
      "Epoch: [102/300]\tSamples: [101184/297600]\tTrain Loss: 1648.9474388860888\tTime: 0:00:03.927247\n",
      "Epoch: [103/300]\tSamples: [102176/297600]\tTrain Loss: 1649.6471144153227\tTime: 0:00:03.849408\n",
      "Epoch: [104/300]\tSamples: [103168/297600]\tTrain Loss: 1648.9738493888608\tTime: 0:00:03.915638\n",
      "Epoch: [105/300]\tSamples: [104160/297600]\tTrain Loss: 1648.9378583354335\tTime: 0:00:03.869807\n",
      "Epoch: [106/300]\tSamples: [105152/297600]\tTrain Loss: 1648.1325565461188\tTime: 0:00:03.797475\n",
      "Epoch: [107/300]\tSamples: [106144/297600]\tTrain Loss: 1647.3179065335182\tTime: 0:00:03.828875\n",
      "Epoch: [108/300]\tSamples: [107136/297600]\tTrain Loss: 1645.9764522429437\tTime: 0:00:03.914172\n",
      "Epoch: [109/300]\tSamples: [108128/297600]\tTrain Loss: 1646.1917527721773\tTime: 0:00:03.819639\n",
      "Epoch: [110/300]\tSamples: [109120/297600]\tTrain Loss: 1644.8512159778227\tTime: 0:00:03.906149\n",
      "Epoch: [111/300]\tSamples: [110112/297600]\tTrain Loss: 1641.8948226436491\tTime: 0:00:03.832569\n",
      "Epoch: [112/300]\tSamples: [111104/297600]\tTrain Loss: 1642.6080164755545\tTime: 0:00:03.908701\n",
      "Epoch: [113/300]\tSamples: [112096/297600]\tTrain Loss: 1642.2336032006049\tTime: 0:00:03.852237\n",
      "Epoch: [114/300]\tSamples: [113088/297600]\tTrain Loss: 1641.6831015309979\tTime: 0:00:03.798143\n",
      "Epoch: [115/300]\tSamples: [114080/297600]\tTrain Loss: 1641.2537290511593\tTime: 0:00:03.968512\n",
      "Epoch: [116/300]\tSamples: [115072/297600]\tTrain Loss: 1641.2074210874496\tTime: 0:00:03.742946\n",
      "Epoch: [117/300]\tSamples: [116064/297600]\tTrain Loss: 1642.7066571635585\tTime: 0:00:03.826626\n",
      "Epoch: [118/300]\tSamples: [117056/297600]\tTrain Loss: 1639.776138797883\tTime: 0:00:03.814972\n",
      "Epoch: [119/300]\tSamples: [118048/297600]\tTrain Loss: 1643.6459764049898\tTime: 0:00:04.326932\n",
      "Epoch: [120/300]\tSamples: [119040/297600]\tTrain Loss: 1639.275855279738\tTime: 0:00:03.819875\n",
      "Epoch: [121/300]\tSamples: [120032/297600]\tTrain Loss: 1640.8275658392138\tTime: 0:00:03.882069\n",
      "Epoch: [122/300]\tSamples: [121024/297600]\tTrain Loss: 1638.1907683341733\tTime: 0:00:04.024606\n",
      "Epoch: [123/300]\tSamples: [122016/297600]\tTrain Loss: 1640.3197612147178\tTime: 0:00:03.882036\n",
      "Epoch: [124/300]\tSamples: [123008/297600]\tTrain Loss: 1637.710189327117\tTime: 0:00:03.877341\n",
      "Epoch: [125/300]\tSamples: [124000/297600]\tTrain Loss: 1636.8393830330142\tTime: 0:00:03.776271\n",
      "Epoch: [126/300]\tSamples: [124992/297600]\tTrain Loss: 1637.4278249432964\tTime: 0:00:03.871271\n",
      "Epoch: [127/300]\tSamples: [125984/297600]\tTrain Loss: 1635.650650516633\tTime: 0:00:03.814865\n",
      "Epoch: [128/300]\tSamples: [126976/297600]\tTrain Loss: 1635.7271059097782\tTime: 0:00:03.824999\n",
      "Epoch: [129/300]\tSamples: [127968/297600]\tTrain Loss: 1637.3862737840223\tTime: 0:00:03.895850\n",
      "Epoch: [130/300]\tSamples: [128960/297600]\tTrain Loss: 1636.5333370085687\tTime: 0:00:03.995895\n",
      "Epoch: [131/300]\tSamples: [129952/297600]\tTrain Loss: 1634.5470167590727\tTime: 0:00:03.885613\n",
      "Epoch: [132/300]\tSamples: [130944/297600]\tTrain Loss: 1634.639183782762\tTime: 0:00:03.836881\n",
      "Epoch: [133/300]\tSamples: [131936/297600]\tTrain Loss: 1635.6513671875\tTime: 0:00:03.893119\n",
      "Epoch: [134/300]\tSamples: [132928/297600]\tTrain Loss: 1635.975318170363\tTime: 0:00:03.826849\n",
      "Epoch: [135/300]\tSamples: [133920/297600]\tTrain Loss: 1635.9256828061996\tTime: 0:00:03.901660\n",
      "Epoch: [136/300]\tSamples: [134912/297600]\tTrain Loss: 1635.3616195186491\tTime: 0:00:03.922532\n",
      "Epoch: [137/300]\tSamples: [135904/297600]\tTrain Loss: 1632.8366226688509\tTime: 0:00:03.869957\n",
      "Epoch: [138/300]\tSamples: [136896/297600]\tTrain Loss: 1633.0235398815523\tTime: 0:00:03.925511\n",
      "Epoch: [139/300]\tSamples: [137888/297600]\tTrain Loss: 1633.2989777595767\tTime: 0:00:03.839598\n",
      "Epoch: [140/300]\tSamples: [138880/297600]\tTrain Loss: 1632.7295748802924\tTime: 0:00:03.855394\n",
      "Epoch: [141/300]\tSamples: [139872/297600]\tTrain Loss: 1632.2991195186491\tTime: 0:00:03.895067\n",
      "Epoch: [142/300]\tSamples: [140864/297600]\tTrain Loss: 1629.641837827621\tTime: 0:00:03.782501\n",
      "Epoch: [143/300]\tSamples: [141856/297600]\tTrain Loss: 1631.2119967552924\tTime: 0:00:03.854071\n",
      "Epoch: [144/300]\tSamples: [142848/297600]\tTrain Loss: 1632.9329715851813\tTime: 0:00:03.822116\n",
      "Epoch: [145/300]\tSamples: [143840/297600]\tTrain Loss: 1631.9997952368951\tTime: 0:00:03.924044\n",
      "Epoch: [146/300]\tSamples: [144832/297600]\tTrain Loss: 1632.9534085181451\tTime: 0:00:03.801415\n",
      "Epoch: [147/300]\tSamples: [145824/297600]\tTrain Loss: 1632.1384159211188\tTime: 0:00:03.917347\n",
      "Epoch: [148/300]\tSamples: [146816/297600]\tTrain Loss: 1630.1959149760585\tTime: 0:00:03.837035\n",
      "Epoch: [149/300]\tSamples: [147808/297600]\tTrain Loss: 1628.7396949029737\tTime: 0:00:03.885653\n",
      "Epoch: [150/300]\tSamples: [148800/297600]\tTrain Loss: 1629.1521586756553\tTime: 0:00:04.134951\n",
      "Epoch: [151/300]\tSamples: [149792/297600]\tTrain Loss: 1630.344947076613\tTime: 0:00:03.814411\n",
      "Epoch: [152/300]\tSamples: [150784/297600]\tTrain Loss: 1629.4883875693045\tTime: 0:00:04.123405\n",
      "Epoch: [153/300]\tSamples: [151776/297600]\tTrain Loss: 1627.5792393838205\tTime: 0:00:03.927653\n",
      "Epoch: [154/300]\tSamples: [152768/297600]\tTrain Loss: 1629.3064752394152\tTime: 0:00:03.951489\n",
      "Epoch: [155/300]\tSamples: [153760/297600]\tTrain Loss: 1627.3694595829134\tTime: 0:00:03.780457\n",
      "Epoch: [156/300]\tSamples: [154752/297600]\tTrain Loss: 1626.2495629095263\tTime: 0:00:03.861335\n",
      "Epoch: [157/300]\tSamples: [155744/297600]\tTrain Loss: 1627.4293724798388\tTime: 0:00:03.764260\n",
      "Epoch: [158/300]\tSamples: [156736/297600]\tTrain Loss: 1626.3478373865928\tTime: 0:00:03.957351\n",
      "Epoch: [159/300]\tSamples: [157728/297600]\tTrain Loss: 1626.3324013986896\tTime: 0:00:03.807165\n",
      "Epoch: [160/300]\tSamples: [158720/297600]\tTrain Loss: 1627.624771610383\tTime: 0:00:03.799898\n",
      "Epoch: [161/300]\tSamples: [159712/297600]\tTrain Loss: 1627.3621314264112\tTime: 0:00:03.895302\n",
      "Epoch: [162/300]\tSamples: [160704/297600]\tTrain Loss: 1625.9205243510585\tTime: 0:00:03.833117\n",
      "Epoch: [163/300]\tSamples: [161696/297600]\tTrain Loss: 1624.7594584803428\tTime: 0:00:03.776574\n",
      "Epoch: [164/300]\tSamples: [162688/297600]\tTrain Loss: 1625.5232839276714\tTime: 0:00:03.786867\n",
      "Epoch: [165/300]\tSamples: [163680/297600]\tTrain Loss: 1628.8111375378023\tTime: 0:00:03.842489\n",
      "Epoch: [166/300]\tSamples: [164672/297600]\tTrain Loss: 1623.7854870211693\tTime: 0:00:03.757976\n",
      "Epoch: [167/300]\tSamples: [165664/297600]\tTrain Loss: 1625.9477184664818\tTime: 0:00:04.003485\n",
      "Epoch: [168/300]\tSamples: [166656/297600]\tTrain Loss: 1626.278099798387\tTime: 0:00:03.834885\n",
      "Epoch: [169/300]\tSamples: [167648/297600]\tTrain Loss: 1624.969742313508\tTime: 0:00:03.841134\n",
      "Epoch: [170/300]\tSamples: [168640/297600]\tTrain Loss: 1624.8243368825604\tTime: 0:00:03.831714\n",
      "Epoch: [171/300]\tSamples: [169632/297600]\tTrain Loss: 1624.8666125882057\tTime: 0:00:03.786338\n",
      "Epoch: [172/300]\tSamples: [170624/297600]\tTrain Loss: 1624.6530131678428\tTime: 0:00:03.834423\n",
      "Epoch: [173/300]\tSamples: [171616/297600]\tTrain Loss: 1627.1085086945563\tTime: 0:00:03.879660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [174/300]\tSamples: [172608/297600]\tTrain Loss: 1624.5345852759576\tTime: 0:00:03.979948\n",
      "Epoch: [175/300]\tSamples: [173600/297600]\tTrain Loss: 1625.7481965095767\tTime: 0:00:03.859847\n",
      "Epoch: [176/300]\tSamples: [174592/297600]\tTrain Loss: 1625.8905895602318\tTime: 0:00:03.960790\n",
      "Epoch: [177/300]\tSamples: [175584/297600]\tTrain Loss: 1624.6775886781754\tTime: 0:00:03.884483\n",
      "Epoch: [178/300]\tSamples: [176576/297600]\tTrain Loss: 1624.4754559916835\tTime: 0:00:03.915649\n",
      "Epoch: [179/300]\tSamples: [177568/297600]\tTrain Loss: 1625.3550828503023\tTime: 0:00:03.809207\n",
      "Epoch: [180/300]\tSamples: [178560/297600]\tTrain Loss: 1624.5035164125504\tTime: 0:00:03.834655\n",
      "Epoch: [181/300]\tSamples: [179552/297600]\tTrain Loss: 1624.4627528036795\tTime: 0:00:04.022796\n",
      "Epoch: [182/300]\tSamples: [180544/297600]\tTrain Loss: 1623.735808341734\tTime: 0:00:03.974965\n",
      "Epoch: [183/300]\tSamples: [181536/297600]\tTrain Loss: 1622.6351042716733\tTime: 0:00:03.877120\n",
      "Epoch: [184/300]\tSamples: [182528/297600]\tTrain Loss: 1621.7273973034273\tTime: 0:00:04.018583\n",
      "Epoch: [185/300]\tSamples: [183520/297600]\tTrain Loss: 1623.0483437815021\tTime: 0:00:04.039915\n",
      "Epoch: [186/300]\tSamples: [184512/297600]\tTrain Loss: 1620.5906194871473\tTime: 0:00:03.844225\n",
      "Epoch: [187/300]\tSamples: [185504/297600]\tTrain Loss: 1623.965796685988\tTime: 0:00:03.876387\n",
      "Epoch: [188/300]\tSamples: [186496/297600]\tTrain Loss: 1622.4427687121977\tTime: 0:00:03.831061\n",
      "Epoch: [189/300]\tSamples: [187488/297600]\tTrain Loss: 1624.7079251197076\tTime: 0:00:03.842420\n",
      "Epoch: [190/300]\tSamples: [188480/297600]\tTrain Loss: 1620.3813004032259\tTime: 0:00:03.912256\n",
      "Epoch: [191/300]\tSamples: [189472/297600]\tTrain Loss: 1621.5061665196572\tTime: 0:00:03.910423\n",
      "Epoch: [192/300]\tSamples: [190464/297600]\tTrain Loss: 1620.3351617628527\tTime: 0:00:03.865766\n",
      "Epoch: [193/300]\tSamples: [191456/297600]\tTrain Loss: 1618.8325628465223\tTime: 0:00:03.809373\n",
      "Epoch: [194/300]\tSamples: [192448/297600]\tTrain Loss: 1618.5850436302924\tTime: 0:00:03.866076\n",
      "Epoch: [195/300]\tSamples: [193440/297600]\tTrain Loss: 1621.5000826927924\tTime: 0:00:03.959836\n",
      "Epoch: [196/300]\tSamples: [194432/297600]\tTrain Loss: 1618.6640231224799\tTime: 0:00:03.881482\n",
      "Epoch: [197/300]\tSamples: [195424/297600]\tTrain Loss: 1620.1517806514616\tTime: 0:00:03.866920\n",
      "Epoch: [198/300]\tSamples: [196416/297600]\tTrain Loss: 1620.0953959803428\tTime: 0:00:03.823213\n",
      "Epoch: [199/300]\tSamples: [197408/297600]\tTrain Loss: 1621.6998133505545\tTime: 0:00:03.843247\n",
      "Epoch: [200/300]\tSamples: [198400/297600]\tTrain Loss: 1619.487273185484\tTime: 0:00:03.789903\n",
      "Epoch: [201/300]\tSamples: [199392/297600]\tTrain Loss: 1619.9667259954638\tTime: 0:00:03.901597\n",
      "Epoch: [202/300]\tSamples: [200384/297600]\tTrain Loss: 1619.5912652784777\tTime: 0:00:03.793799\n",
      "Epoch: [203/300]\tSamples: [201376/297600]\tTrain Loss: 1619.3863170992943\tTime: 0:00:03.831135\n",
      "Epoch: [204/300]\tSamples: [202368/297600]\tTrain Loss: 1615.7453888923892\tTime: 0:00:03.784344\n",
      "Epoch: [205/300]\tSamples: [203360/297600]\tTrain Loss: 1618.3789928805443\tTime: 0:00:04.080622\n",
      "Epoch: [206/300]\tSamples: [204352/297600]\tTrain Loss: 1619.741234564012\tTime: 0:00:04.021017\n",
      "Epoch: [207/300]\tSamples: [205344/297600]\tTrain Loss: 1617.655997983871\tTime: 0:00:03.837592\n",
      "Epoch: [208/300]\tSamples: [206336/297600]\tTrain Loss: 1617.0481350806451\tTime: 0:00:03.766030\n",
      "Epoch: [209/300]\tSamples: [207328/297600]\tTrain Loss: 1616.5355579007057\tTime: 0:00:03.725068\n",
      "Epoch: [210/300]\tSamples: [208320/297600]\tTrain Loss: 1619.9107705393146\tTime: 0:00:04.004613\n",
      "Epoch: [211/300]\tSamples: [209312/297600]\tTrain Loss: 1616.2195572391634\tTime: 0:00:03.788098\n",
      "Epoch: [212/300]\tSamples: [210304/297600]\tTrain Loss: 1613.8871440272178\tTime: 0:00:03.874307\n",
      "Epoch: [213/300]\tSamples: [211296/297600]\tTrain Loss: 1618.0626614478326\tTime: 0:00:03.784980\n",
      "Epoch: [214/300]\tSamples: [212288/297600]\tTrain Loss: 1616.4095970892138\tTime: 0:00:03.830658\n",
      "Epoch: [215/300]\tSamples: [213280/297600]\tTrain Loss: 1616.0525453629032\tTime: 0:00:03.865729\n",
      "Epoch: [216/300]\tSamples: [214272/297600]\tTrain Loss: 1615.5823777721773\tTime: 0:00:04.069812\n",
      "Epoch: [217/300]\tSamples: [215264/297600]\tTrain Loss: 1619.3189618510585\tTime: 0:00:03.852719\n",
      "Epoch: [218/300]\tSamples: [216256/297600]\tTrain Loss: 1617.8324171496977\tTime: 0:00:03.964854\n",
      "Epoch: [219/300]\tSamples: [217248/297600]\tTrain Loss: 1615.3663841985888\tTime: 0:00:03.765715\n",
      "Epoch: [220/300]\tSamples: [218240/297600]\tTrain Loss: 1616.2143200289818\tTime: 0:00:03.851488\n",
      "Epoch: [221/300]\tSamples: [219232/297600]\tTrain Loss: 1616.2794858870968\tTime: 0:00:03.829456\n",
      "Epoch: [222/300]\tSamples: [220224/297600]\tTrain Loss: 1614.738517515121\tTime: 0:00:03.861094\n",
      "Epoch: [223/300]\tSamples: [221216/297600]\tTrain Loss: 1615.1346278036795\tTime: 0:00:03.832205\n",
      "Epoch: [224/300]\tSamples: [222208/297600]\tTrain Loss: 1615.7479287424396\tTime: 0:00:03.831874\n",
      "Epoch: [225/300]\tSamples: [223200/297600]\tTrain Loss: 1612.3306845388104\tTime: 0:00:03.851816\n",
      "Epoch: [226/300]\tSamples: [224192/297600]\tTrain Loss: 1610.9407486454134\tTime: 0:00:03.821536\n",
      "Epoch: [227/300]\tSamples: [225184/297600]\tTrain Loss: 1609.3866203061996\tTime: 0:00:03.906063\n",
      "Epoch: [228/300]\tSamples: [226176/297600]\tTrain Loss: 1610.4354051159273\tTime: 0:00:03.868578\n",
      "Epoch: [229/300]\tSamples: [227168/297600]\tTrain Loss: 1610.0526319934477\tTime: 0:00:03.854503\n",
      "Epoch: [230/300]\tSamples: [228160/297600]\tTrain Loss: 1615.311539188508\tTime: 0:00:03.861279\n",
      "Epoch: [231/300]\tSamples: [229152/297600]\tTrain Loss: 1613.1410463394657\tTime: 0:00:03.838393\n",
      "Epoch: [232/300]\tSamples: [230144/297600]\tTrain Loss: 1612.204345703125\tTime: 0:00:03.861625\n",
      "Epoch: [233/300]\tSamples: [231136/297600]\tTrain Loss: 1613.3234193863407\tTime: 0:00:03.901637\n",
      "Epoch: [234/300]\tSamples: [232128/297600]\tTrain Loss: 1612.6827077557964\tTime: 0:00:03.839149\n",
      "Epoch: [235/300]\tSamples: [233120/297600]\tTrain Loss: 1609.0290960496473\tTime: 0:00:03.697845\n",
      "Epoch: [236/300]\tSamples: [234112/297600]\tTrain Loss: 1610.3325077179938\tTime: 0:00:03.891387\n",
      "Epoch: [237/300]\tSamples: [235104/297600]\tTrain Loss: 1616.9525737147178\tTime: 0:00:03.820496\n",
      "Epoch: [238/300]\tSamples: [236096/297600]\tTrain Loss: 1616.1190539944557\tTime: 0:00:03.806149\n",
      "Epoch: [239/300]\tSamples: [237088/297600]\tTrain Loss: 1611.4009773500504\tTime: 0:00:03.848648\n",
      "Epoch: [240/300]\tSamples: [238080/297600]\tTrain Loss: 1615.1946824596773\tTime: 0:00:03.849884\n",
      "Epoch: [241/300]\tSamples: [239072/297600]\tTrain Loss: 1613.4081361832157\tTime: 0:00:03.897887\n",
      "Epoch: [242/300]\tSamples: [240064/297600]\tTrain Loss: 1610.9773894279233\tTime: 0:00:03.815711\n",
      "Epoch: [243/300]\tSamples: [241056/297600]\tTrain Loss: 1608.9519436743951\tTime: 0:00:03.888526\n",
      "Epoch: [244/300]\tSamples: [242048/297600]\tTrain Loss: 1608.3134214339718\tTime: 0:00:03.850595\n",
      "Epoch: [245/300]\tSamples: [243040/297600]\tTrain Loss: 1610.6499141570062\tTime: 0:00:03.939609\n",
      "Epoch: [246/300]\tSamples: [244032/297600]\tTrain Loss: 1609.2391042401714\tTime: 0:00:03.785937\n",
      "Epoch: [247/300]\tSamples: [245024/297600]\tTrain Loss: 1610.0316674017138\tTime: 0:00:03.815974\n",
      "Epoch: [248/300]\tSamples: [246016/297600]\tTrain Loss: 1607.254662298387\tTime: 0:00:03.843862\n",
      "Epoch: [249/300]\tSamples: [247008/297600]\tTrain Loss: 1608.3389223160282\tTime: 0:00:03.830030\n",
      "Epoch: [250/300]\tSamples: [248000/297600]\tTrain Loss: 1609.1436570690523\tTime: 0:00:03.907410\n",
      "Epoch: [251/300]\tSamples: [248992/297600]\tTrain Loss: 1610.0845829133063\tTime: 0:00:03.864771\n",
      "Epoch: [252/300]\tSamples: [249984/297600]\tTrain Loss: 1611.5789243636593\tTime: 0:00:03.834463\n",
      "Epoch: [253/300]\tSamples: [250976/297600]\tTrain Loss: 1609.1614990234375\tTime: 0:00:04.001395\n",
      "Epoch: [254/300]\tSamples: [251968/297600]\tTrain Loss: 1606.9292622227822\tTime: 0:00:03.846034\n",
      "Epoch: [255/300]\tSamples: [252960/297600]\tTrain Loss: 1608.4320816532259\tTime: 0:00:03.805936\n",
      "Epoch: [256/300]\tSamples: [253952/297600]\tTrain Loss: 1610.4215442288307\tTime: 0:00:03.905558\n",
      "Epoch: [257/300]\tSamples: [254944/297600]\tTrain Loss: 1604.1563445060483\tTime: 0:00:03.952451\n",
      "Epoch: [258/300]\tSamples: [255936/297600]\tTrain Loss: 1608.7291141633063\tTime: 0:00:03.943070\n",
      "Epoch: [259/300]\tSamples: [256928/297600]\tTrain Loss: 1609.7965402910786\tTime: 0:00:03.846400\n",
      "Epoch: [260/300]\tSamples: [257920/297600]\tTrain Loss: 1607.1184554561491\tTime: 0:00:03.893841\n",
      "Epoch: [261/300]\tSamples: [258912/297600]\tTrain Loss: 1610.1061302923388\tTime: 0:00:03.855963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [262/300]\tSamples: [259904/297600]\tTrain Loss: 1605.2110989478326\tTime: 0:00:03.891721\n",
      "Epoch: [263/300]\tSamples: [260896/297600]\tTrain Loss: 1608.8950077179938\tTime: 0:00:03.871840\n",
      "Epoch: [264/300]\tSamples: [261888/297600]\tTrain Loss: 1607.790291078629\tTime: 0:00:03.964930\n",
      "Epoch: [265/300]\tSamples: [262880/297600]\tTrain Loss: 1611.0934192288307\tTime: 0:00:03.854766\n",
      "Epoch: [266/300]\tSamples: [263872/297600]\tTrain Loss: 1608.5734390751009\tTime: 0:00:03.795511\n",
      "Epoch: [267/300]\tSamples: [264864/297600]\tTrain Loss: 1605.515656502016\tTime: 0:00:03.933576\n",
      "Epoch: [268/300]\tSamples: [265856/297600]\tTrain Loss: 1607.4399768460182\tTime: 0:00:04.000693\n",
      "Epoch: [269/300]\tSamples: [266848/297600]\tTrain Loss: 1601.513884513609\tTime: 0:00:03.819420\n",
      "Epoch: [270/300]\tSamples: [267840/297600]\tTrain Loss: 1604.3831117691532\tTime: 0:00:03.947003\n",
      "Epoch: [271/300]\tSamples: [268832/297600]\tTrain Loss: 1609.4636584866432\tTime: 0:00:03.925189\n",
      "Epoch: [272/300]\tSamples: [269824/297600]\tTrain Loss: 1606.233642578125\tTime: 0:00:04.214756\n",
      "Epoch: [273/300]\tSamples: [270816/297600]\tTrain Loss: 1607.2287479523688\tTime: 0:00:03.861958\n",
      "Epoch: [274/300]\tSamples: [271808/297600]\tTrain Loss: 1608.1428104523688\tTime: 0:00:03.887953\n",
      "Epoch: [275/300]\tSamples: [272800/297600]\tTrain Loss: 1607.0679971018146\tTime: 0:00:03.957711\n",
      "Epoch: [276/300]\tSamples: [273792/297600]\tTrain Loss: 1607.674292779738\tTime: 0:00:03.836249\n",
      "Epoch: [277/300]\tSamples: [274784/297600]\tTrain Loss: 1605.543449155746\tTime: 0:00:03.894803\n",
      "Epoch: [278/300]\tSamples: [275776/297600]\tTrain Loss: 1606.4110776839718\tTime: 0:00:03.845979\n",
      "Epoch: [279/300]\tSamples: [276768/297600]\tTrain Loss: 1602.5521043346773\tTime: 0:00:03.862150\n",
      "Epoch: [280/300]\tSamples: [277760/297600]\tTrain Loss: 1603.2732760521674\tTime: 0:00:03.932490\n",
      "Epoch: [281/300]\tSamples: [278752/297600]\tTrain Loss: 1603.7424710181451\tTime: 0:00:04.302308\n",
      "Epoch: [282/300]\tSamples: [279744/297600]\tTrain Loss: 1603.4248598160282\tTime: 0:00:03.922478\n",
      "Epoch: [283/300]\tSamples: [280736/297600]\tTrain Loss: 1606.1311743951612\tTime: 0:00:03.820654\n",
      "Epoch: [284/300]\tSamples: [281728/297600]\tTrain Loss: 1607.0251189201108\tTime: 0:00:03.969155\n",
      "Epoch: [285/300]\tSamples: [282720/297600]\tTrain Loss: 1608.8196745841733\tTime: 0:00:03.804771\n",
      "Epoch: [286/300]\tSamples: [283712/297600]\tTrain Loss: 1604.3343112084174\tTime: 0:00:03.861577\n",
      "Epoch: [287/300]\tSamples: [284704/297600]\tTrain Loss: 1603.0975774949598\tTime: 0:00:03.825154\n",
      "Epoch: [288/300]\tSamples: [285696/297600]\tTrain Loss: 1605.0966599987398\tTime: 0:00:04.042865\n",
      "Epoch: [289/300]\tSamples: [286688/297600]\tTrain Loss: 1604.982689642137\tTime: 0:00:03.837078\n",
      "Epoch: [290/300]\tSamples: [287680/297600]\tTrain Loss: 1604.3846829322076\tTime: 0:00:03.783476\n",
      "Epoch: [291/300]\tSamples: [288672/297600]\tTrain Loss: 1601.460441343246\tTime: 0:00:03.870492\n",
      "Epoch: [292/300]\tSamples: [289664/297600]\tTrain Loss: 1601.3574415637602\tTime: 0:00:03.853292\n",
      "Epoch: [293/300]\tSamples: [290656/297600]\tTrain Loss: 1607.3867581275201\tTime: 0:00:03.786059\n",
      "Epoch: [294/300]\tSamples: [291648/297600]\tTrain Loss: 1605.6382820375504\tTime: 0:00:03.902355\n",
      "Epoch: [295/300]\tSamples: [292640/297600]\tTrain Loss: 1603.0365068989415\tTime: 0:00:03.835871\n",
      "Epoch: [296/300]\tSamples: [293632/297600]\tTrain Loss: 1605.9270058908771\tTime: 0:00:03.817799\n",
      "Epoch: [297/300]\tSamples: [294624/297600]\tTrain Loss: 1605.8116061302924\tTime: 0:00:03.861833\n",
      "Epoch: [298/300]\tSamples: [295616/297600]\tTrain Loss: 1599.9355941280241\tTime: 0:00:03.800325\n",
      "Epoch: [299/300]\tSamples: [296608/297600]\tTrain Loss: 1605.7294449344759\tTime: 0:00:03.855259\n",
      "Epoch: [300/300]\tSamples: [297600/297600]\tTrain Loss: 1603.5516751197076\tTime: 0:00:03.900961\n"
     ]
    }
   ],
   "source": [
    "from contextualized_topic_models.models.ctm import CTM\n",
    "from contextualized_topic_models.utils.data_preparation import TextHandler\n",
    "from contextualized_topic_models.utils.data_preparation import bert_embeddings_from_file\n",
    "from contextualized_topic_models.datasets.dataset import CTMDataset\n",
    "\n",
    "handler = TextHandler(\"topic_tst.txt\")\n",
    "handler.prepare() # create vocabulary and training data\n",
    "\n",
    "# generate BERT data\n",
    "training_bert = bert_embeddings_from_file(\"topic_tst.txt\", \"./roberta-large-nli-mean-tokens\")#\"../rev_sig/codes/models/scibert_scivocab_uncased\")\n",
    "print(training_bert.shape)\n",
    "\n",
    "training_dataset = CTMDataset(handler.bow, training_bert, handler.idx2token)\n",
    "\n",
    "ctm = CTM(input_size=len(handler.vocab), bert_input_size=1024, num_epochs=300, inference_type=\"combined\", n_components=50)\n",
    "\n",
    "ctm.fit(training_dataset) # run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['meets', 'pay', 'review', 'strategy', 'policy'],\n",
       " ['back', 'action', 'self', 'consequentialist', 'complete'],\n",
       " ['following', 'many', 'player', 'imperfect', 'like'],\n",
       " ['work', 'nhowever', 'prosocial', 'uses', 'worthwhile'],\n",
       " ['points', 'based', 'nwe', 'gain', 'maximizes'],\n",
       " ['think', 'motivated', 'scores', 'make', 'perhaps'],\n",
       " ['approximate', 'alternative', 'strategies', 'risky', 'explanatory'],\n",
       " ['punish', 'opponent', 'concept', 'many', 'repeated'],\n",
       " ['would', 'adaptive', 'allow', 'accumulative', 'shows'],\n",
       " ['mechanism', 'considering', 'act', 'played', 'random'],\n",
       " ['independent', 'non', 'making', 'value', 'design'],\n",
       " ['self', 'number', 'page', 'expected', 'amtft'],\n",
       " ['nwe', 'noncooperation', 'games', 'coco', 'alter'],\n",
       " ['operate', 'agent', 'total', 'dilemma', 'number'],\n",
       " ['since', 'identically', 'policy', 'amtft', 'see'],\n",
       " ['whenever', 'fully', 'punish', 'tampuu', 'design'],\n",
       " ['tampuu', 'exploited', 'alter', 'illustrated', 'games'],\n",
       " ['last', 'noverall', 'future', 'additional', 'require'],\n",
       " ['dilemma', 'noncooperation', 'imperfect', 'general', 'play'],\n",
       " ['working', 'based', 'amtft', 'variation', 'making'],\n",
       " ['might', 'complex', 'find', 'maximizes', 'apporach'],\n",
       " ['act', 'findings', 'action', 'experimental', 'states'],\n",
       " ['tat', 'explicit', 'diverse', 'sized', 'minor'],\n",
       " ['hybrid', 'motivated', 'took', 'domains', 'clear'],\n",
       " ['see', 'policy', 'contrasted', 'rewards', 'worthwhile'],\n",
       " ['following', 'dilemma', 'games', 'folk', 'find'],\n",
       " ['fundamentally', 'policies', 'requires', 'choices', 'specific'],\n",
       " ['details', 'nhowever', 'nanother', 'contribution', 'bases'],\n",
       " ['stochasticity', 'ncomments', 'parameter', 'opposed', 'literature'],\n",
       " ['alter', 'prisoner', 'look', 'submission', 'play'],\n",
       " ['effectiveness', 'use', 'towards', 'considering', 'alternative'],\n",
       " ['view', 'stochastic', 'sodomka', 'agent', 'entitled'],\n",
       " ['contrast', 'information', 'move', 'submission', 'refer'],\n",
       " ['around', 'approximate', 'shifted', 'training', 'adaptive'],\n",
       " ['outcome', 'submission', 'policy', 'shifted', 'self'],\n",
       " ['fishing', 'intensive', 'relates', 'exploits', 'selection'],\n",
       " ['payments', 'generally', 'cooperate', 'two', 'opposed'],\n",
       " ['considering', 'parameterized', 'alternative', 'explained', 'rewards'],\n",
       " ['see', 'stochasticity', 'authors', 'improvement', 'operation'],\n",
       " ['nit', 'noncooperation', 'find', 'punish', 'begins'],\n",
       " ['larger', 'phase', 'proposes', 'imperfect', 'complexity'],\n",
       " ['points', 'alternative', 'training', 'choose', 'performance'],\n",
       " ['amazingly', 'deep', 'sum', 'nmove', 'solution'],\n",
       " ['many', 'cooperating', 'version', 'contrast', 'maximizes'],\n",
       " ['behavioural', 'paired', 'switches', 'function', 'would'],\n",
       " ['look', 'illustrated', 'repeated', 'cooperative', 'notions'],\n",
       " ['fully', 'nthis', 'motivated', 'findings', 'demonstrate'],\n",
       " ['requires', 'amtft', 'act', 'within', 'npresentation'],\n",
       " ['cooperative', 'submission', 'percent', 'sodomka', 'benefit'],\n",
       " ['like', 'new', 'dilemmas', 'u2019s', 'try']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctm.get_topic_lists(5) #[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.026520604267716408, 0.02834726870059967, 0.003427316201850772, 0.02080521732568741, 0.012079360894858837, 0.010290855541825294, 0.3212392330169678, 0.0027247986290603876, 0.002327259862795472, 0.05522018298506737, 0.005439192056655884, 0.0158783458173275, 0.011319664306938648, 0.001446626614779234, 0.026488233357667923, 0.0004579859087243676, 0.003788309870287776, 0.01808340474963188, 0.0016714358935132623, 0.019919145852327347, 0.0029042267706245184, 0.010641783475875854, 0.036067891865968704, 0.003450139192864299, 0.030135881155729294, 0.0032284685876220465, 0.00894432794302702, 0.05680284649133682, 0.026695912703871727, 0.004934509284794331, 0.01147447805851698, 0.0024149634409695864, 0.0006742439582012594, 0.10157182812690735, 0.0017547588795423508, 0.0025347573682665825, 0.0005235658027231693, 0.01220684964209795, 0.015467447228729725, 0.012259155511856079, 0.013225502334535122, 0.004706164356321096, 0.004573761485517025, 0.001405310002155602, 0.020185301080346107, 0.0015335209900513291, 0.0015105452621355653, 0.004435314796864986, 0.0027543476317077875, 0.013507802039384842]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['approximate',\n",
       " 'alternative',\n",
       " 'strategies',\n",
       " 'risky',\n",
       " 'explanatory',\n",
       " 'reduction',\n",
       " 'npresentation',\n",
       " 'variation',\n",
       " 'different',\n",
       " 'exploits']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "distribution = ctm.get_thetas(training_dataset)[1] # topic distribution for the eight document\n",
    "\n",
    "print(distribution)\n",
    "\n",
    "topic = np.argmax(distribution)\n",
    "\n",
    "ctm.get_topic_lists(10)[topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rajeev3",
   "language": "python",
   "name": "rajeev3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
