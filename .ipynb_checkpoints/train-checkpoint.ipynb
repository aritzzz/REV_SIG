{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils_ import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import logging\n",
    "from collections import OrderedDict\n",
    "import argparse\n",
    "import numpy as np\n",
    "from Models import Pipeline, MTLoss, Prediction #CrossAttention, Context\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device1 = \"cuda:7\"\n",
    "device2 = \"cuda:2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SimpleNamespace(dim = 768, upscale_dim = 256, codes='64,32,8', batch_size=4, learning_rate=0.01, weight_decay=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLoaders2(main_task_path = './Data/SignData/train_data', scaffold_task_path = './Data/2018/train_data', batch_size=8, slice=[-1, -1, -1], test_path='./Data/SignData/test_data'):\n",
    "\tprint('Reading the Main Task Dataset...')\n",
    "\tmain_task_dataset = RevSigData(main_task_path, mode='MAIN', slice_=slice[0], transform=Transform(), sigtx=ScaleSigScores())\n",
    "\t#main_task_dataset = dataset.readData(main_task_path, Transform(), mode='MAIN', n=slice[0])\n",
    "\tprint('Reading the Scaffolds Task Dataset...')\n",
    "\tscaffold_task_dataset = RevSigData(scaffold_task_path, mode='SCAFFOLDS', slice_=slice[1], transform=Transform())\n",
    "\t#scaffold_task_dataset = dataset.readData(scaffold_task_path, Transform(), mode='SCAFFOLDS', n=slice[1])\n",
    "\t\n",
    "\n",
    "\tif test_path:\n",
    "\t\tprint('Reading the test Dataset')\n",
    "\t\ttest_dataset = RevSigData(test_path, mode='TEST', slice_=slice[2], transform=Transform(), sigtx=ScaleSigScores())\n",
    "\t\t#test_dataset = dataset.readData(test_path, Transform(), mode='TEST', n=slice[2])\n",
    "\telse:\n",
    "\t\ttest_dataset = None\n",
    "\n",
    "\n",
    "\t#length of the both task datasets\n",
    "\tmain_task_len = len(main_task_dataset)\n",
    "\tscaffold_task_len = len(scaffold_task_dataset)\n",
    "\ttest_len = len(test_dataset)\n",
    "\n",
    "\t#inflate the smaller dataset to match the size of the larger one\n",
    "\tif main_task_len < scaffold_task_len:\n",
    "\t\tdifference = scaffold_task_len - main_task_len\n",
    "\t\tsample = [random.choice(main_task_dataset) for _ in range(difference)]\n",
    "\t\tmain_task_dataset = main_task_dataset + sample\n",
    "\t\n",
    "\t# print(len(main_task_dataset), len(scaffold_task_dataset))\n",
    "\t#print(main_task_len, scaffold_task_len)\n",
    "\treturn (main_task_dataset, scaffold_task_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the Main Task Dataset...\n",
      "Reading the Scaffolds Task Dataset...\n",
      "Reading the test Dataset\n"
     ]
    }
   ],
   "source": [
    "main_task_dataset, scaffold_task_dataset, test_dataset = getLoaders2(batch_size=args.batch_size, slice=[100,100,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_task_dataloader = DataLoader(main_task_dataset, batch_size = args.batch_size, shuffle = True, num_workers=4)\n",
    "scaffold_task_dataloader = DataLoader(scaffold_task_dataset, batch_size = args.batch_size, shuffle=True, num_workers=4)\n",
    "if test_dataset != None:\n",
    "    test_data_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4)\n",
    "else:\n",
    "    test_data_loader = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, main_task_predictor, scaffold_task_predictor, Criterion, test_loader):\n",
    "\twith torch.no_grad():\n",
    "\t\teval_loss = []\n",
    "\t\tfor i, d in enumerate(test_loader,0):\n",
    "\t\t\tscaffold_task_data = d\n",
    "\t\t\tpapers_sc, reviews_sc, recs_sc, confs_sc, sign_m = scaffold_task_data[0].transpose(1,2).float().to(device),\\\n",
    "\t\t\t\t\t\t\t scaffold_task_data[1].transpose(1,2).float().to(device), \\\n",
    "\t\t\t\t\t\t\t scaffold_task_data[2].float().to(device),\\\n",
    "\t\t\t\t\t\t\t scaffold_task_data[3].float().to(device),\\\n",
    "\t\t\t\t\t\t\t scaffold_task_data[4].float().to(device)\n",
    "\n",
    "\t\t\tex, subj, opine = sign_m[:,0], sign_m[:,1], sign_m[:,2]\n",
    "\t\t\tout, rec_codes, conf_codes = model(papers_sc, reviews_sc)\n",
    "\t\t\trec_preds, conf_preds = scaffold_task_predictor(rec_codes.view(out.shape[0], -1), conf_codes.view(out.shape[0], -1))\n",
    "\n",
    "\t\t\tout_m, rec_codes_m, conf_codes_m = model(papers_sc, reviews_sc)\n",
    "\t\t\tex_preds, subj_preds, intensity_preds = main_task_predictor(out, rec_codes_m, conf_codes_m)\n",
    "\n",
    "\n",
    "\t\t\tloss = Criterion([rec_preds.squeeze(1), conf_preds.squeeze(1), ex_preds.squeeze(1), subj_preds.squeeze(1), intensity_preds.squeeze(1)], [recs_sc, confs_sc, ex, subj, opine])\n",
    "\t\t\t\n",
    "\t\t\teval_loss.append(loss.item())\n",
    "\t\treturn np.average(eval_loss)\n",
    "\n",
    "\n",
    "\n",
    "def train(args, dataloaders):\n",
    "    main_task_loader, scaffold_task_loader, test_loader = dataloaders\n",
    "    model = Pipeline.Pipeline(args).to(device)\n",
    "    main_task_predictor = Prediction.MainPrediction(args.upscale_dim, args.upscale_dim, 16).to(device)\n",
    "    scaffold_task_predictor = Prediction.ScaffoldPrediction(args.upscale_dim, 8).to(device)\n",
    "\n",
    "    print(model)\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name, param.shape)\n",
    "    print(\"No. of Trainable parameters {}\".format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "\n",
    "    Criterion = MTLoss.MTLoss().to(device)\n",
    "    optimizer = torch.optim.Adam(list(model.parameters()) + list(Criterion.parameters()) + list(main_task_predictor.parameters()) + list(scaffold_task_predictor.parameters()), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "    optimizerMain = torch.optim.Adam(main_task_predictor.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "    epochs = 100\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = []\n",
    "        for i, d in enumerate(zip(scaffold_task_loader, main_task_loader),0):\n",
    "            #print(i)\n",
    "            main_task_data = d[1]\n",
    "            scaffold_task_data = d[0]\n",
    "            papers_sc, reviews_sc, recs_sc, confs_sc = scaffold_task_data[0].transpose(1,2).float().to(device),\\\n",
    "                                 scaffold_task_data[1].transpose(1,2).float().to(device), \\\n",
    "                                 scaffold_task_data[2].float().to(device),\\\n",
    "                                 scaffold_task_data[3].float().to(device)\n",
    "\n",
    "            #print(ex.shape, subj.shape, opine.shape, recs_sc.shape, confs_sc.shape)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out, rec_codes, conf_codes = model(papers_sc, reviews_sc)\n",
    "            rec_preds, conf_preds = scaffold_task_predictor(rec_codes.view(out.shape[0], -1), conf_codes.view(out.shape[0], -1))\n",
    "            \n",
    "            del papers_sc\n",
    "            del reviews_sc\n",
    "            \n",
    "            papers_m, reviews_m, sign_m = main_task_data[0].transpose(1,2).float().to(device),\\\n",
    "                                 main_task_data[1].transpose(1,2).float().to(device), \\\n",
    "                                 main_task_data[2].float().to(device)\n",
    "\n",
    "            ex, subj, opine = sign_m[:,0], sign_m[:,1], sign_m[:,2]\n",
    "\n",
    "            #do the for the main task\n",
    "            out_m, rec_codes_m, conf_codes_m = model(papers_m, reviews_m)\n",
    "            ex_preds, subj_preds, intensity_preds = main_task_predictor(out_m, rec_codes_m, conf_codes_m)\n",
    "            #print(ex_preds.shape, subj_preds.shape, intensity_preds.shape)\n",
    "\n",
    "\n",
    "            loss = Criterion([rec_preds.squeeze(1), conf_preds.squeeze(1), ex_preds.squeeze(1), subj_preds.squeeze(1), intensity_preds.squeeze(1)], [recs_sc, confs_sc, ex, subj, opine])\n",
    "            epoch_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        #print(\"Epoch {} Loss: {:.3f}\".format(epoch, np.average(epoch_loss)))\n",
    "            del papers_m\n",
    "            del reviews_m\n",
    "            gc.collect()\n",
    "        # \tbreak\n",
    "        # break\n",
    "\n",
    "        with torch.no_grad():\n",
    "            eval_loss = evaluate(model, main_task_predictor, scaffold_task_predictor, Criterion, test_loader)\n",
    "\n",
    "            print('Epoch: {} Train Loss: {:.6f}, Test Loss: {:.6f}'.format(epoch, np.average(epoch_loss),\\\n",
    "                            eval_loss))\n",
    "            # print(\"Exhaustive {}\".format(list(zip(ex_preds.data, ex.data))))\n",
    "            # print(\"Subjectivity {}\".format(list(zip(subj_preds.data, subj.data))))\n",
    "            # print(\"Intensity {}\".format(list(zip(intensity_preds.data, opine.data))))\n",
    "            # print(\"Recommendation {}\".format(list(zip(rec_preds.data, recs_sc.data))))\n",
    "            # print(\"Confidence {}\".format(list(zip(conf_preds.data, confs_sc.data))))\n",
    "\n",
    "            #logging.info('Predictions, Actual : {}'.format(str(list(zip(recs_preds_t, recs_sc_t)))))\n",
    "        #break\n",
    "\n",
    "\n",
    "def main(args, dataloaders=(main_task_dataloader, scaffold_task_dataloader, test_data_loader)):\n",
    "    train(args, dataloaders)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(\n",
      "  (cross_attention): CrossAttention(\n",
      "    (linear1): Linear(in_features=768, out_features=256, bias=True)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (contextor): Sequential(\n",
      "    (coder0): Context(\n",
      "      (linear): Linear(in_features=768, out_features=256, bias=True)\n",
      "      (codes): Linear(in_features=256, out_features=64, bias=False)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "    (coder1): Context(\n",
      "      (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (codes): Linear(in_features=256, out_features=32, bias=False)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "    (coder2): Context(\n",
      "      (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (codes): Linear(in_features=256, out_features=8, bias=False)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (rec_codes): Context(\n",
      "    (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (codes): Linear(in_features=256, out_features=8, bias=False)\n",
      "    (act): ReLU()\n",
      "  )\n",
      "  (conf_codes): Context(\n",
      "    (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (codes): Linear(in_features=256, out_features=8, bias=False)\n",
      "    (act): ReLU()\n",
      "  )\n",
      ")\n",
      "cross_attention.linear1.weight torch.Size([256, 768])\n",
      "cross_attention.linear1.bias torch.Size([256])\n",
      "contextor.coder0.linear.weight torch.Size([256, 768])\n",
      "contextor.coder0.linear.bias torch.Size([256])\n",
      "contextor.coder0.codes.weight torch.Size([64, 256])\n",
      "contextor.coder1.linear.weight torch.Size([256, 256])\n",
      "contextor.coder1.linear.bias torch.Size([256])\n",
      "contextor.coder1.codes.weight torch.Size([32, 256])\n",
      "contextor.coder2.linear.weight torch.Size([256, 256])\n",
      "contextor.coder2.linear.bias torch.Size([256])\n",
      "contextor.coder2.codes.weight torch.Size([8, 256])\n",
      "rec_codes.linear.weight torch.Size([256, 256])\n",
      "rec_codes.linear.bias torch.Size([256])\n",
      "rec_codes.codes.weight torch.Size([8, 256])\n",
      "conf_codes.linear.weight torch.Size([256, 256])\n",
      "conf_codes.linear.bias torch.Size([256])\n",
      "conf_codes.codes.weight torch.Size([8, 256])\n",
      "No. of Trainable parameters 687616\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 7.14 GiB (GPU 7; 10.91 GiB total capacity; 301.59 MiB already allocated; 3.10 GiB free; 7.00 GiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-aacc94af8ac2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_task_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaffold_task_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-34051c5dba89>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args, dataloaders)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_task_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaffold_task_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-34051c5dba89>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, dataloaders)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m#do the for the main task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mout_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_codes_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf_codes_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpapers_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreviews_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mex_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubj_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintensity_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain_task_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_codes_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf_codes_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m#print(ex_preds.shape, subj_preds.shape, intensity_preds.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3_1/envs/rajeev3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Rajeev/REVSIG/Models/Pipeline.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, paper, review)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mRp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mout_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3_1/envs/rajeev3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Rajeev/REVSIG/Models/CrossAttention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, paper, review)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mAffinity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_linear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaper_linear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#shape = (_, R, P)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAffinity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#normalized across columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mRp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0;31m#print(C.shape, paper.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mPr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 7.14 GiB (GPU 7; 10.91 GiB total capacity; 301.59 MiB already allocated; 3.10 GiB free; 7.00 GiB cached)"
     ]
    }
   ],
   "source": [
    "main(args, dataloaders=(main_task_dataloader, scaffold_task_dataloader, test_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(dim=768,\n",
       "          upscale_dim=256,\n",
       "          codes='64,32,8',\n",
       "          batch_size=4,\n",
       "          learning_rate=0.01)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rajeev3",
   "language": "python",
   "name": "rajeev3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
