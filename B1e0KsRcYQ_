Total sentences to be embedded: 265
Total sentences to be embedded: 275
Total sentences to be embedded: 236
Total sentences to be embedded: 263
{'Recommendation': 6.632, 'Confidence': 3.933, 'Exhaustive': 6.968, 'Aspectual Score': 8.837, 'Intensity': 4.59, 'Actual REC': '4', 'Actual CONF': '5', 'comments': "Summary : This paper presents a way to combine existing factorized second order representations with a codebook style hard assignment . The number of parameters required to produce this encoded representation is shown to be very low . Like other factorized representations , the number of computations as well as the size of any intermediate representations is low . The overall embedding is trained for retrieval using a triplet loss . Results are shown on Stanford online , CUB and Cars-196 datasets . Comments : Review of relevant works seems adequate . The results seem reproducible . The only contribution of this paper is combining the factorized second order representations of ( Kim et . al . 2017 ) with a codebook style assignment ( sec . 3.2 ) . Seems marginal . The scheme described in Sec . 3.2 needs clarification . The assignment is applied to x as h ( x ) \\kron x in ( 7 ) . Then the entire N^2 D^2 dimensional second order descriptor h ( x ) \\kron x \\kron h ( x ) \\kron x is projected on a N^2 D^2 dim w_i . The latter is factorized into p_i , q_i \\in \\mathbb { R } ^ { Nd } , which are further factorized into codebook specific projections u_ { i , j } , v_ { i , j } \\in \\mathbb { R } ^ { d } . Is this different from classical assignment , where x is hard assigned to one of the N codewords as h ( x ) , then projected using \\mathbb { R } ^d dimensional p_i , q_i specific to that codeword ? In section 4.1 and Table 2 , is the HPBP with codebook the same as the proposed CHPBP ? The wording in `` Then we re-implement ... naively to a codebook strategy '' seems confusing . The method denoted `` Margin '' in Table 4 seems to be better than the proposed approach on CUB . How does it compare in terms of efficiency , memory/computation ? Is it possible to see any classification results ? Most of the relevant second order embeddings have been evaluated in that setting . ===============After rebuttal =============================== After reading all reviews , considering author rebuttal and AC inputs , I believe my initial rating is a bit generous . I would like to downgrade it to 4 . It has been pointed out that many recent works that are of a similar flavor , published in CVPR 2018 and ECCV 2018 , have slightly better results on the same dataset . Further , the only novelty of this work is the proposed factorization and not the encoding scheme . This alone is not sufficient to merit acceptance ."}
{'Recommendation': 6.711, 'Confidence': 3.898, 'Exhaustive': 6.654, 'Aspectual Score': 8.473, 'Intensity': 4.595, 'Actual REC': '6', 'Actual CONF': '4', 'comments': "Summary : This paper proposes a novel bilinear representation based on a codebook model . The proposed method is build upon the form of Hadamard Product for efficient representation of a bilinear model . Through introducing the framework of codebook , it is naturally extended into a multiple-rank representation while the efficient pooling scheme is also derived from the ( sparse ) codeword assignment . In addition , the authors also present an efficient formulation in which the codebook-based projections are factorized via a shared projection to further reduce the parameter size . The experimental results on image retrieval tasks show that the proposed method produces better classification accuracy with a limited amount of parameters . Comments : Pros : + It is interesting that one-rank bilinear pooling is naturally extended to multiple-rank one via introducing codebooks . + Good performance in the image retrieval tasks . Cons : - This paper lacks important comparison for fairly evaluating the effectiveness of the proposed formulation . - It also lacks detailed description and discussion for the methods . Due to the above-mentioned weak points , the reviewer can not fully understand whether the performance improvement really comes from the proposed formulation or not . Thus , this manuscript is currently judged as border . The detailed comments are shown in the followings . - Comparison Eventually , the proposed method is closely related to the multiple-rank representation of a bilinear model ; z_i = x^T W_i x ( Eq.5 ) ~ x^T u_i v_i^T x ( one-rank , Eq.6 ) ~ x^T U_i V_i^T x ( multiple-rank ) , ... Eq . ( A ) which is a straightforward extension from the one-rank model . From this viewpoint , the proposed form in Eq.10 is regarded as an extension of ( A ) by introducing non-linearity as z_i = x^T U_i { h ( x ) h ( x ) ^T } V_i^T x . ... Eq . ( 10 ) Thus , the main technical contribution is found in the weighting by { h ( x ) h ( x ) ^T } , but its impact on the performance is not evaluated in the experiments . Furthermore , it is also possible to simply introduce such a non-linearity into the model ( A ) according to [ Kim et al.,2017 ] ; z_i = \\sigma ( x^T U_i ) \\sigma ( V_i^T x ) = 1^T { \\sigma ( U_i^T x ) . * \\sigma ( V_i^T x ) } , ... Eq . ( B ) where `` . * '' indicates Hadamard Product , and we can more directly apply the method of [ Kim et al. , 2017 ] to the multiple-rank model by z_i = p^T { \\sigma ( U_i^T x ) . * \\sigma ( V_i^T x ) } , ... Eq . ( C ) where p is a R-dimensional vector . On the other hand , it is also necessary to compare the proposed method with [ Kim et al.,2017 ] which is formulated by z = P^T { \\sigma ( U^T x ) . * \\sigma ( V^T x ) } , ... Eq . ( D ) where U and V are matrices of d x K and P is K x D. The parameter K ( shared rank ) should be determined so that the total parameter size of ( 2dK + KD ) is compatible to that of the proposed method , 2NdD . In summary , for demonstrating the effectiveness of the proposed method in Eq . ( 10 ) , it is inevitable to compare it with the models ( A , B , D ) and hopefully ( C ) . - Presentation In Section 4.2 , the performance results of the factorization model in Eq . ( 13 ) are merely shown without deep discussion nor analysis on them . In particular , it is unclear why the JCF of N=32 and R=32 outperforms the CHPBP of N=32 . Those two methods are different only in the form of U and V : ( CHPBP ) U_i - > U'_i A ( JCF ) , where U_i and U'_i have the same dimensionality of d x 32 , and thus we can say that JCF overly parameterizes the projection by redundantly introducing A of 32 x 32 . Thus , the projection capacity of JCF is completely the same as that of CHPBP . Therefore , it needs detailed discussion for the performance improvement shown in Figure 1 . Minor comments are : * There are lots of notations , and thus it would be better to show a summary of the notations . * In Section 4.1 , there is no clear description about the methods of BP and HPBP . Actually , the method of HPBP is different from the one presented in [ Kim et al. , 2017 ] ."}
{'Recommendation': 7.204, 'Confidence': 3.398, 'Exhaustive': 1.227, 'Aspectual Score': 1.444, 'Intensity': 6.021, 'Actual REC': 0, 'Actual CONF': 0, 'comments': ''}
{'Recommendation': 6.944, 'Confidence': 3.756, 'Exhaustive': 4.941, 'Aspectual Score': 6.351, 'Intensity': 4.719, 'Actual REC': '5', 'Actual CONF': '2', 'comments': 'The paper proposes a second order method to represent images . More exactly , multiple ( low-dimensional ) projections of Kronecker products of low-dimensional representations are used to represent a limited set of dimensions of second-order representations . It is an extension of HPBP ( Kim et al. , ICLR 2017 ) but with codebook assigment . The main advantage of the method is that , if the number of projection dimensions is small enough , the number of learned parameters is small and the learning process is fast . The method can be easily used as last layers of a neural network . Although the derivations of the method are straightforward , I think the paper is of interest for the computer vision community . Nonetheless , I think that the experimental evaluation is weak . Indeed , the article only considers the specific problem of transfer learning and considers only one evaluation metric ( recall @ k ) . However , recent papers that evaluate their method for that task also use the Normalized Mutual Information ( NMI ) ( e.g . [ A , B ] ) or the F1-score [ B ] as evaluation metrics . The paper does not compare the same task and datasets as ( Kim et al. , ICLR 2017 ) either . It is then difficult to evaluate whether the proposed representation is useful only for the considered task . Other tasks and evaluation metrics should be considered . Moreover , only the case where D=32 and R=8 are evaluated . It would be useful to observe the behavior of the approaches for different values of R. In Section 3.2 , it is mentioned that feature maps become rapidly intractable if the dimension of z is above 10 . Other Factorizations are then proposed . How do these factorizations affect the second order nature of the representation of z ? Is the proposed projection in Eq . ( 10 ) still a good approximation of the second order information induced by the features x ? The paper says that the method is efficient but does not mention training times . How does the method compare in terms of clockwork times compared to other approaches ( on machines with similar architecture ) ? In conclusion , the experimental evaluation of the method is currently too weak . [ A ] Hyun Oh Song , Stefanie Jegelka , Vivek Rathod , Kevin Murphy : Deep Metric Learning via Facility Location . CVPR 2017 [ B ] Wang et al. , Deep Metric Learning with Angular Loss , ICCV 2017 after rebuttal : The authors still did not address my concern about testing on only one task with only one evaluation metric .'}
