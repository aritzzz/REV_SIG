{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(input, only_char=True, lower=True, stop_remove=True, stemming=False):\n",
    "    input = re.sub(r'[^\\x00-\\x7F]+',' ', input)\n",
    "    if lower: input = input.lower()\n",
    "    if only_char:\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        tokens = tokenizer.tokenize(input)\n",
    "        input = ' '.join(tokens)\n",
    "    tokens = word_tokenize(input)\n",
    "    if stop_remove:\n",
    "        tokens = [w for w in tokens if not w in stopwords.words('english')]\n",
    "\n",
    "    # also remove one-length word\n",
    "    tokens = [w for w in tokens if len(w) > 1]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "columns = ['RECOMMENDATION', 'comments', 'CONFIDENCE', 'Layer 1', 'Layer 1 N', 'Layer 2', 'Layer 2 N', 'Layer 3',\n",
    "       'Layer 3 N']\n",
    "Treviews = pd.read_csv('Test_Reviews.csv', usecols=columns)\n",
    "Treviews_l = Treviews[Treviews['Layer 1 N'] < 2]\n",
    "TRreviews = pd.read_csv('Train_Reviews.csv', usecols=columns)\n",
    "TRreviews_l = TRreviews[TRreviews['Layer 1 N'] < 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 830)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Treviews), len(TRreviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 235)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Treviews_l), len(TRreviews_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('reviews_tst_l', 'w') as f:\n",
    "    for i in range(len(Treviews_l)):\n",
    "        rev_txt = Treviews_l.iloc[i]['comments']\n",
    "        f.write(preprocess(rev_txt) + '\\n')\n",
    "    for i in range(len(TRreviews_l)):\n",
    "        rev_txt = TRreviews_l.iloc[i]['comments']\n",
    "        f.write(preprocess(rev_txt) + '\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rev1 = json.load(open('R2.json'))['review']\n",
    "# rev2 = json.load(open('R1.json'))['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rev1, rev2 =  preprocess(rev1), preprocess(rev2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rev1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rev2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# reviews = []\n",
    "# for paper in os.listdir('./ScoreData'):\n",
    "#     print(paper)\n",
    "#     rev_data = json.load(open('./ScoreData/' + paper + '/reviews.json'))\n",
    "#     for r in rev_data['reviews']:\n",
    "#         reviews.append(preprocess(r['comments']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('topic_tst.txt', 'w') as f:\n",
    "#     for review in reviews:\n",
    "#         f.write(review + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/tirthankar/miniconda3_1/envs/rajeev3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/home2/tirthankar/miniconda3_1/envs/rajeev3/lib/python3.7/site-packages/contextualized_topic_models/utils/data_preparation.py:161: Warning: The vocab you are using has more than 2000 words, reconstructing high-dimensional vectors requiressignificantly more training epochs and training samples. Consider reducing the number of vocabulary items. See https://github.com/MilaNLProc/contextualized-topic-models#preprocessing and https://github.com/MilaNLProc/contextualized-topic-models#tldr\n",
      "  \"and https://github.com/MilaNLProc/contextualized-topic-models#tldr\", Warning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f193c734c8564884a8c0746020e27690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Batches'), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(259, 1024)\n",
      "Settings: \n",
      "                   N Components: 50\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.98\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/tirthankar/miniconda3_1/envs/rajeev3/lib/python3.7/site-packages/contextualized_topic_models/models/ctm.py:47: DeprecationWarning: Direct call to CTM is deprecated and will be removed in version 2, use CombinedTM or ZeroShotTM\n",
      "  warnings.warn(\"Direct call to CTM is deprecated and will be removed in version 2, use CombinedTM or ZeroShotTM\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/1000]\tSamples: [259/259000]\tTrain Loss: 892.3521563555744\tTime: 0:00:04.993397\n",
      "Epoch: [2/1000]\tSamples: [518/259000]\tTrain Loss: 889.2138992368484\tTime: 0:00:05.073728\n",
      "Epoch: [3/1000]\tSamples: [777/259000]\tTrain Loss: 887.608136386945\tTime: 0:00:05.256637\n",
      "Epoch: [4/1000]\tSamples: [1036/259000]\tTrain Loss: 886.4355242519305\tTime: 0:00:04.989182\n",
      "Epoch: [5/1000]\tSamples: [1295/259000]\tTrain Loss: 884.0136303993726\tTime: 0:00:04.760300\n",
      "Epoch: [6/1000]\tSamples: [1554/259000]\tTrain Loss: 887.217014622044\tTime: 0:00:04.835326\n",
      "Epoch: [7/1000]\tSamples: [1813/259000]\tTrain Loss: 885.8762273015203\tTime: 0:00:04.937217\n",
      "Epoch: [8/1000]\tSamples: [2072/259000]\tTrain Loss: 884.650109721887\tTime: 0:00:04.800740\n",
      "Epoch: [9/1000]\tSamples: [2331/259000]\tTrain Loss: 884.087184596706\tTime: 0:00:04.863586\n",
      "Epoch: [10/1000]\tSamples: [2590/259000]\tTrain Loss: 880.7504392645994\tTime: 0:00:04.809836\n",
      "Epoch: [11/1000]\tSamples: [2849/259000]\tTrain Loss: 880.8567950274494\tTime: 0:00:04.940811\n",
      "Epoch: [12/1000]\tSamples: [3108/259000]\tTrain Loss: 876.0498989502896\tTime: 0:00:06.115872\n",
      "Epoch: [13/1000]\tSamples: [3367/259000]\tTrain Loss: 874.1081401574565\tTime: 0:00:04.976826\n",
      "Epoch: [14/1000]\tSamples: [3626/259000]\tTrain Loss: 879.245478685298\tTime: 0:00:04.863846\n",
      "Epoch: [15/1000]\tSamples: [3885/259000]\tTrain Loss: 875.2519196617097\tTime: 0:00:04.637467\n",
      "Epoch: [16/1000]\tSamples: [4144/259000]\tTrain Loss: 879.4728617428813\tTime: 0:00:04.920275\n",
      "Epoch: [17/1000]\tSamples: [4403/259000]\tTrain Loss: 875.0178703396476\tTime: 0:00:04.824283\n",
      "Epoch: [18/1000]\tSamples: [4662/259000]\tTrain Loss: 870.1711746274734\tTime: 0:00:04.964392\n",
      "Epoch: [19/1000]\tSamples: [4921/259000]\tTrain Loss: 874.2719735988779\tTime: 0:00:05.093645\n",
      "Epoch: [20/1000]\tSamples: [5180/259000]\tTrain Loss: 871.9737657230334\tTime: 0:00:05.103427\n",
      "Epoch: [21/1000]\tSamples: [5439/259000]\tTrain Loss: 870.031675125181\tTime: 0:00:05.029763\n",
      "Epoch: [22/1000]\tSamples: [5698/259000]\tTrain Loss: 865.6971741900941\tTime: 0:00:05.372354\n",
      "Epoch: [23/1000]\tSamples: [5957/259000]\tTrain Loss: 870.0875098033301\tTime: 0:00:04.822964\n",
      "Epoch: [24/1000]\tSamples: [6216/259000]\tTrain Loss: 868.147072574807\tTime: 0:00:09.725372\n",
      "Epoch: [25/1000]\tSamples: [6475/259000]\tTrain Loss: 868.1469292953668\tTime: 0:00:06.112874\n",
      "Epoch: [26/1000]\tSamples: [6734/259000]\tTrain Loss: 862.4415938329513\tTime: 0:00:06.575479\n",
      "Epoch: [27/1000]\tSamples: [6993/259000]\tTrain Loss: 866.8849546218931\tTime: 0:00:08.144835\n",
      "Epoch: [28/1000]\tSamples: [7252/259000]\tTrain Loss: 864.4015038685449\tTime: 0:00:07.621075\n",
      "Epoch: [29/1000]\tSamples: [7511/259000]\tTrain Loss: 863.5321172176641\tTime: 0:00:06.013496\n",
      "Epoch: [30/1000]\tSamples: [7770/259000]\tTrain Loss: 857.8805294552365\tTime: 0:00:05.953762\n",
      "Epoch: [31/1000]\tSamples: [8029/259000]\tTrain Loss: 856.117558895391\tTime: 0:00:05.833738\n",
      "Epoch: [32/1000]\tSamples: [8288/259000]\tTrain Loss: 860.3280646718147\tTime: 0:00:08.123593\n",
      "Epoch: [33/1000]\tSamples: [8547/259000]\tTrain Loss: 860.1688816851171\tTime: 0:00:06.261809\n",
      "Epoch: [34/1000]\tSamples: [8806/259000]\tTrain Loss: 854.5257497662283\tTime: 0:00:06.162619\n",
      "Epoch: [35/1000]\tSamples: [9065/259000]\tTrain Loss: 859.3653380640685\tTime: 0:00:06.244853\n",
      "Epoch: [36/1000]\tSamples: [9324/259000]\tTrain Loss: 856.7914991931106\tTime: 0:00:06.454572\n",
      "Epoch: [37/1000]\tSamples: [9583/259000]\tTrain Loss: 856.4396859540902\tTime: 0:00:06.272643\n",
      "Epoch: [38/1000]\tSamples: [9842/259000]\tTrain Loss: 852.093595409025\tTime: 0:00:08.063401\n",
      "Epoch: [39/1000]\tSamples: [10101/259000]\tTrain Loss: 853.0613085183397\tTime: 0:00:06.106373\n",
      "Epoch: [40/1000]\tSamples: [10360/259000]\tTrain Loss: 849.5271712490951\tTime: 0:00:06.512087\n",
      "Epoch: [41/1000]\tSamples: [10619/259000]\tTrain Loss: 848.304985370415\tTime: 0:00:06.093343\n",
      "Epoch: [42/1000]\tSamples: [10878/259000]\tTrain Loss: 846.9098169039576\tTime: 0:00:06.359120\n",
      "Epoch: [43/1000]\tSamples: [11137/259000]\tTrain Loss: 850.01222494118\tTime: 0:00:06.213876\n",
      "Epoch: [44/1000]\tSamples: [11396/259000]\tTrain Loss: 846.9349596178209\tTime: 0:00:06.371512\n",
      "Epoch: [45/1000]\tSamples: [11655/259000]\tTrain Loss: 844.0115594458856\tTime: 0:00:06.507963\n",
      "Epoch: [46/1000]\tSamples: [11914/259000]\tTrain Loss: 842.8579695418074\tTime: 0:00:06.542822\n",
      "Epoch: [47/1000]\tSamples: [12173/259000]\tTrain Loss: 843.2815770918799\tTime: 0:00:06.312227\n",
      "Epoch: [48/1000]\tSamples: [12432/259000]\tTrain Loss: 844.843858873522\tTime: 0:00:06.398446\n",
      "Epoch: [49/1000]\tSamples: [12691/259000]\tTrain Loss: 842.4956290344473\tTime: 0:00:06.415936\n",
      "Epoch: [50/1000]\tSamples: [12950/259000]\tTrain Loss: 840.2303763724663\tTime: 0:00:06.151888\n",
      "Epoch: [51/1000]\tSamples: [13209/259000]\tTrain Loss: 839.9310863597973\tTime: 0:00:06.234793\n",
      "Epoch: [52/1000]\tSamples: [13468/259000]\tTrain Loss: 841.0531265082046\tTime: 0:00:06.479360\n",
      "Epoch: [53/1000]\tSamples: [13727/259000]\tTrain Loss: 839.3436199173503\tTime: 0:00:06.344187\n",
      "Epoch: [54/1000]\tSamples: [13986/259000]\tTrain Loss: 837.4067882405285\tTime: 0:00:06.237926\n",
      "Epoch: [55/1000]\tSamples: [14245/259000]\tTrain Loss: 835.4583292486125\tTime: 0:00:06.323947\n",
      "Epoch: [56/1000]\tSamples: [14504/259000]\tTrain Loss: 840.3173969519185\tTime: 0:00:06.378466\n",
      "Epoch: [57/1000]\tSamples: [14763/259000]\tTrain Loss: 834.7556684928511\tTime: 0:00:06.327548\n",
      "Epoch: [58/1000]\tSamples: [15022/259000]\tTrain Loss: 835.4046513030888\tTime: 0:00:06.207613\n",
      "Epoch: [59/1000]\tSamples: [15281/259000]\tTrain Loss: 836.1333799619932\tTime: 0:00:06.399723\n",
      "Epoch: [60/1000]\tSamples: [15540/259000]\tTrain Loss: 835.0742432583253\tTime: 0:00:06.263707\n",
      "Epoch: [61/1000]\tSamples: [15799/259000]\tTrain Loss: 830.5043794492036\tTime: 0:00:06.527207\n",
      "Epoch: [62/1000]\tSamples: [16058/259000]\tTrain Loss: 833.6504377563948\tTime: 0:00:06.331396\n",
      "Epoch: [63/1000]\tSamples: [16317/259000]\tTrain Loss: 830.295817371501\tTime: 0:00:06.321275\n",
      "Epoch: [64/1000]\tSamples: [16576/259000]\tTrain Loss: 831.4070983651062\tTime: 0:00:06.423153\n",
      "Epoch: [65/1000]\tSamples: [16835/259000]\tTrain Loss: 832.4108896145029\tTime: 0:00:06.283965\n",
      "Epoch: [66/1000]\tSamples: [17094/259000]\tTrain Loss: 831.718958320765\tTime: 0:00:06.275931\n",
      "Epoch: [67/1000]\tSamples: [17353/259000]\tTrain Loss: 827.8494255625603\tTime: 0:00:06.234057\n",
      "Epoch: [68/1000]\tSamples: [17612/259000]\tTrain Loss: 828.692636379404\tTime: 0:00:09.074711\n",
      "Epoch: [69/1000]\tSamples: [17871/259000]\tTrain Loss: 824.6995364156008\tTime: 0:00:06.522117\n",
      "Epoch: [70/1000]\tSamples: [18130/259000]\tTrain Loss: 826.3462526770633\tTime: 0:00:06.170820\n",
      "Epoch: [71/1000]\tSamples: [18389/259000]\tTrain Loss: 824.5403161951014\tTime: 0:00:06.201156\n",
      "Epoch: [72/1000]\tSamples: [18648/259000]\tTrain Loss: 825.7060575153837\tTime: 0:00:06.242751\n",
      "Epoch: [73/1000]\tSamples: [18907/259000]\tTrain Loss: 826.3136862972068\tTime: 0:00:06.034034\n",
      "Epoch: [74/1000]\tSamples: [19166/259000]\tTrain Loss: 825.6355673300253\tTime: 0:00:06.346679\n",
      "Epoch: [75/1000]\tSamples: [19425/259000]\tTrain Loss: 823.8534571820704\tTime: 0:00:06.426409\n",
      "Epoch: [76/1000]\tSamples: [19684/259000]\tTrain Loss: 821.477566398709\tTime: 0:00:06.330736\n",
      "Epoch: [77/1000]\tSamples: [19943/259000]\tTrain Loss: 819.681035457891\tTime: 0:00:06.205311\n",
      "Epoch: [78/1000]\tSamples: [20202/259000]\tTrain Loss: 825.2194673398286\tTime: 0:00:06.410184\n",
      "Epoch: [79/1000]\tSamples: [20461/259000]\tTrain Loss: 819.8545148105695\tTime: 0:00:06.559019\n",
      "Epoch: [80/1000]\tSamples: [20720/259000]\tTrain Loss: 820.0389474993967\tTime: 0:00:06.405964\n",
      "Epoch: [81/1000]\tSamples: [20979/259000]\tTrain Loss: 821.9690544688103\tTime: 0:00:06.349310\n",
      "Epoch: [82/1000]\tSamples: [21238/259000]\tTrain Loss: 819.5458117157336\tTime: 0:00:06.185255\n",
      "Epoch: [83/1000]\tSamples: [21497/259000]\tTrain Loss: 817.6556523739141\tTime: 0:00:06.035803\n",
      "Epoch: [84/1000]\tSamples: [21756/259000]\tTrain Loss: 818.4559773920125\tTime: 0:00:06.405738\n",
      "Epoch: [85/1000]\tSamples: [22015/259000]\tTrain Loss: 815.5826241629464\tTime: 0:00:06.442727\n",
      "Epoch: [86/1000]\tSamples: [22274/259000]\tTrain Loss: 817.9286308141288\tTime: 0:00:06.008007\n",
      "Epoch: [87/1000]\tSamples: [22533/259000]\tTrain Loss: 815.7539986275337\tTime: 0:00:06.266006\n",
      "Epoch: [88/1000]\tSamples: [22792/259000]\tTrain Loss: 814.8905557168497\tTime: 0:00:06.147918\n",
      "Epoch: [89/1000]\tSamples: [23051/259000]\tTrain Loss: 814.9545342287041\tTime: 0:00:06.556587\n",
      "Epoch: [90/1000]\tSamples: [23310/259000]\tTrain Loss: 813.2263947122345\tTime: 0:00:06.103487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [91/1000]\tSamples: [23569/259000]\tTrain Loss: 811.3590644041084\tTime: 0:00:06.413091\n",
      "Epoch: [92/1000]\tSamples: [23828/259000]\tTrain Loss: 810.3361222550676\tTime: 0:00:06.410732\n",
      "Epoch: [93/1000]\tSamples: [24087/259000]\tTrain Loss: 814.8144182477679\tTime: 0:00:06.324388\n",
      "Epoch: [94/1000]\tSamples: [24346/259000]\tTrain Loss: 812.3115724541506\tTime: 0:00:06.353556\n",
      "Epoch: [95/1000]\tSamples: [24605/259000]\tTrain Loss: 813.1506451345318\tTime: 0:00:06.338354\n",
      "Epoch: [96/1000]\tSamples: [24864/259000]\tTrain Loss: 809.3082534613296\tTime: 0:00:06.223201\n",
      "Epoch: [97/1000]\tSamples: [25123/259000]\tTrain Loss: 806.8359488115348\tTime: 0:00:06.586632\n",
      "Epoch: [98/1000]\tSamples: [25382/259000]\tTrain Loss: 810.2160041249397\tTime: 0:00:06.387899\n",
      "Epoch: [99/1000]\tSamples: [25641/259000]\tTrain Loss: 808.2517881651182\tTime: 0:00:06.326554\n",
      "Epoch: [100/1000]\tSamples: [25900/259000]\tTrain Loss: 810.3109295819256\tTime: 0:00:06.479745\n",
      "Epoch: [101/1000]\tSamples: [26159/259000]\tTrain Loss: 807.5959086178813\tTime: 0:00:06.493202\n",
      "Epoch: [102/1000]\tSamples: [26418/259000]\tTrain Loss: 807.7720933126207\tTime: 0:00:06.133918\n",
      "Epoch: [103/1000]\tSamples: [26677/259000]\tTrain Loss: 807.8650279394908\tTime: 0:00:07.883670\n",
      "Epoch: [104/1000]\tSamples: [26936/259000]\tTrain Loss: 806.4080362798625\tTime: 0:00:06.416443\n",
      "Epoch: [105/1000]\tSamples: [27195/259000]\tTrain Loss: 804.2848103055622\tTime: 0:00:06.283271\n",
      "Epoch: [106/1000]\tSamples: [27454/259000]\tTrain Loss: 803.5877878785593\tTime: 0:00:06.282317\n",
      "Epoch: [107/1000]\tSamples: [27713/259000]\tTrain Loss: 804.3838658866734\tTime: 0:00:06.009290\n",
      "Epoch: [108/1000]\tSamples: [27972/259000]\tTrain Loss: 805.4140464753258\tTime: 0:00:06.115143\n",
      "Epoch: [109/1000]\tSamples: [28231/259000]\tTrain Loss: 803.3802560931467\tTime: 0:00:06.307901\n",
      "Epoch: [110/1000]\tSamples: [28490/259000]\tTrain Loss: 801.4699452521718\tTime: 0:00:06.417448\n",
      "Epoch: [111/1000]\tSamples: [28749/259000]\tTrain Loss: 801.9429992911438\tTime: 0:00:07.168300\n",
      "Epoch: [112/1000]\tSamples: [29008/259000]\tTrain Loss: 801.2509200048263\tTime: 0:00:07.680807\n",
      "Epoch: [113/1000]\tSamples: [29267/259000]\tTrain Loss: 801.6924902720801\tTime: 0:00:06.547684\n",
      "Epoch: [114/1000]\tSamples: [29526/259000]\tTrain Loss: 800.3712803903234\tTime: 0:00:06.245956\n",
      "Epoch: [115/1000]\tSamples: [29785/259000]\tTrain Loss: 800.2008494962597\tTime: 0:00:06.278669\n",
      "Epoch: [116/1000]\tSamples: [30044/259000]\tTrain Loss: 798.2788679793074\tTime: 0:00:06.262017\n",
      "Epoch: [117/1000]\tSamples: [30303/259000]\tTrain Loss: 802.1180990211752\tTime: 0:00:06.410672\n",
      "Epoch: [118/1000]\tSamples: [30562/259000]\tTrain Loss: 801.3690708705357\tTime: 0:00:06.433764\n",
      "Epoch: [119/1000]\tSamples: [30821/259000]\tTrain Loss: 801.5375769184363\tTime: 0:00:06.329412\n",
      "Epoch: [120/1000]\tSamples: [31080/259000]\tTrain Loss: 799.0148581722068\tTime: 0:00:06.447315\n",
      "Epoch: [121/1000]\tSamples: [31339/259000]\tTrain Loss: 800.1126515745657\tTime: 0:00:06.352908\n",
      "Epoch: [122/1000]\tSamples: [31598/259000]\tTrain Loss: 797.2447891529923\tTime: 0:00:06.288264\n",
      "Epoch: [123/1000]\tSamples: [31857/259000]\tTrain Loss: 799.5654900156853\tTime: 0:00:06.367596\n",
      "Epoch: [124/1000]\tSamples: [32116/259000]\tTrain Loss: 800.3044744660956\tTime: 0:00:06.287038\n",
      "Epoch: [125/1000]\tSamples: [32375/259000]\tTrain Loss: 796.0963441119691\tTime: 0:00:06.022064\n",
      "Epoch: [126/1000]\tSamples: [32634/259000]\tTrain Loss: 797.5338497677365\tTime: 0:00:06.224345\n",
      "Epoch: [127/1000]\tSamples: [32893/259000]\tTrain Loss: 799.0086438978041\tTime: 0:00:06.255311\n",
      "Epoch: [128/1000]\tSamples: [33152/259000]\tTrain Loss: 796.4243013242036\tTime: 0:00:06.233761\n",
      "Epoch: [129/1000]\tSamples: [33411/259000]\tTrain Loss: 795.0309125392133\tTime: 0:00:06.256378\n",
      "Epoch: [130/1000]\tSamples: [33670/259000]\tTrain Loss: 797.8859401393581\tTime: 0:00:06.720186\n",
      "Epoch: [131/1000]\tSamples: [33929/259000]\tTrain Loss: 793.8629777238176\tTime: 0:00:06.376584\n",
      "Epoch: [132/1000]\tSamples: [34188/259000]\tTrain Loss: 794.8222675102558\tTime: 0:00:06.123068\n",
      "Epoch: [133/1000]\tSamples: [34447/259000]\tTrain Loss: 795.26215330146\tTime: 0:00:06.096644\n",
      "Epoch: [134/1000]\tSamples: [34706/259000]\tTrain Loss: 795.355812809182\tTime: 0:00:06.450329\n",
      "Epoch: [135/1000]\tSamples: [34965/259000]\tTrain Loss: 794.357060848516\tTime: 0:00:06.222191\n",
      "Epoch: [136/1000]\tSamples: [35224/259000]\tTrain Loss: 791.638445644305\tTime: 0:00:06.158872\n",
      "Epoch: [137/1000]\tSamples: [35483/259000]\tTrain Loss: 796.6788476185449\tTime: 0:00:06.601084\n",
      "Epoch: [138/1000]\tSamples: [35742/259000]\tTrain Loss: 789.274875950169\tTime: 0:00:06.153064\n",
      "Epoch: [139/1000]\tSamples: [36001/259000]\tTrain Loss: 790.3971974730032\tTime: 0:00:06.329544\n",
      "Epoch: [140/1000]\tSamples: [36260/259000]\tTrain Loss: 791.6003201164334\tTime: 0:00:06.551332\n",
      "Epoch: [141/1000]\tSamples: [36519/259000]\tTrain Loss: 791.8173526484073\tTime: 0:00:06.490439\n",
      "Epoch: [142/1000]\tSamples: [36778/259000]\tTrain Loss: 791.5147775775217\tTime: 0:00:06.130925\n",
      "Epoch: [143/1000]\tSamples: [37037/259000]\tTrain Loss: 793.7309315802968\tTime: 0:00:06.272905\n",
      "Epoch: [144/1000]\tSamples: [37296/259000]\tTrain Loss: 789.4571990377655\tTime: 0:00:06.118462\n",
      "Epoch: [145/1000]\tSamples: [37555/259000]\tTrain Loss: 791.3335441677726\tTime: 0:00:06.250015\n",
      "Epoch: [146/1000]\tSamples: [37814/259000]\tTrain Loss: 788.5286492896356\tTime: 0:00:06.179204\n",
      "Epoch: [147/1000]\tSamples: [38073/259000]\tTrain Loss: 791.42098798715\tTime: 0:00:06.276183\n",
      "Epoch: [148/1000]\tSamples: [38332/259000]\tTrain Loss: 789.2265813525579\tTime: 0:00:06.289852\n",
      "Epoch: [149/1000]\tSamples: [38591/259000]\tTrain Loss: 788.7169731464165\tTime: 0:00:06.424550\n",
      "Epoch: [150/1000]\tSamples: [38850/259000]\tTrain Loss: 788.7970239352076\tTime: 0:00:06.492344\n",
      "Epoch: [151/1000]\tSamples: [39109/259000]\tTrain Loss: 788.429661106419\tTime: 0:00:06.129235\n",
      "Epoch: [152/1000]\tSamples: [39368/259000]\tTrain Loss: 789.574327152208\tTime: 0:00:06.022124\n",
      "Epoch: [153/1000]\tSamples: [39627/259000]\tTrain Loss: 788.3301921829753\tTime: 0:00:06.446749\n",
      "Epoch: [154/1000]\tSamples: [39886/259000]\tTrain Loss: 785.5866784055261\tTime: 0:00:06.243520\n",
      "Epoch: [155/1000]\tSamples: [40145/259000]\tTrain Loss: 783.9797523527992\tTime: 0:00:06.461611\n",
      "Epoch: [156/1000]\tSamples: [40404/259000]\tTrain Loss: 785.681740543557\tTime: 0:00:06.161224\n",
      "Epoch: [157/1000]\tSamples: [40663/259000]\tTrain Loss: 789.479880550193\tTime: 0:00:06.442170\n",
      "Epoch: [158/1000]\tSamples: [40922/259000]\tTrain Loss: 785.6679291596283\tTime: 0:00:06.443532\n",
      "Epoch: [159/1000]\tSamples: [41181/259000]\tTrain Loss: 786.0442592075893\tTime: 0:00:06.170388\n",
      "Epoch: [160/1000]\tSamples: [41440/259000]\tTrain Loss: 784.5336046844836\tTime: 0:00:06.374550\n",
      "Epoch: [161/1000]\tSamples: [41699/259000]\tTrain Loss: 783.0200148181106\tTime: 0:00:06.291901\n",
      "Epoch: [162/1000]\tSamples: [41958/259000]\tTrain Loss: 787.5717660322152\tTime: 0:00:06.374495\n",
      "Epoch: [163/1000]\tSamples: [42217/259000]\tTrain Loss: 787.1833797734677\tTime: 0:00:06.308110\n",
      "Epoch: [164/1000]\tSamples: [42476/259000]\tTrain Loss: 783.6962862346163\tTime: 0:00:06.423079\n",
      "Epoch: [165/1000]\tSamples: [42735/259000]\tTrain Loss: 785.9075640232867\tTime: 0:00:06.057545\n",
      "Epoch: [166/1000]\tSamples: [42994/259000]\tTrain Loss: 783.0874457046332\tTime: 0:00:06.543062\n",
      "Epoch: [167/1000]\tSamples: [43253/259000]\tTrain Loss: 781.6409756575772\tTime: 0:00:06.225895\n",
      "Epoch: [168/1000]\tSamples: [43512/259000]\tTrain Loss: 782.0315054521598\tTime: 0:00:06.275364\n",
      "Epoch: [169/1000]\tSamples: [43771/259000]\tTrain Loss: 782.0102011190878\tTime: 0:00:06.389981\n",
      "Epoch: [170/1000]\tSamples: [44030/259000]\tTrain Loss: 785.3517048368122\tTime: 0:00:06.413177\n",
      "Epoch: [171/1000]\tSamples: [44289/259000]\tTrain Loss: 784.7492817175435\tTime: 0:00:06.233059\n",
      "Epoch: [172/1000]\tSamples: [44548/259000]\tTrain Loss: 781.6526265383687\tTime: 0:00:06.382127\n",
      "Epoch: [173/1000]\tSamples: [44807/259000]\tTrain Loss: 781.8973157728041\tTime: 0:00:06.263072\n",
      "Epoch: [174/1000]\tSamples: [45066/259000]\tTrain Loss: 781.0115396506998\tTime: 0:00:06.229840\n",
      "Epoch: [175/1000]\tSamples: [45325/259000]\tTrain Loss: 778.708161460847\tTime: 0:00:06.163875\n",
      "Epoch: [176/1000]\tSamples: [45584/259000]\tTrain Loss: 779.7416035420185\tTime: 0:00:06.448421\n",
      "Epoch: [177/1000]\tSamples: [45843/259000]\tTrain Loss: 779.7741077084339\tTime: 0:00:06.319698\n",
      "Epoch: [178/1000]\tSamples: [46102/259000]\tTrain Loss: 778.9837754886584\tTime: 0:00:06.595787\n",
      "Epoch: [179/1000]\tSamples: [46361/259000]\tTrain Loss: 779.4815923624517\tTime: 0:00:06.364724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [180/1000]\tSamples: [46620/259000]\tTrain Loss: 780.6041321036438\tTime: 0:00:06.254616\n",
      "Epoch: [181/1000]\tSamples: [46879/259000]\tTrain Loss: 781.2168110144185\tTime: 0:00:06.459658\n",
      "Epoch: [182/1000]\tSamples: [47138/259000]\tTrain Loss: 776.3717507616433\tTime: 0:00:06.263976\n",
      "Epoch: [183/1000]\tSamples: [47397/259000]\tTrain Loss: 781.2719604020873\tTime: 0:00:06.470172\n",
      "Epoch: [184/1000]\tSamples: [47656/259000]\tTrain Loss: 776.7126380007239\tTime: 0:00:06.400449\n",
      "Epoch: [185/1000]\tSamples: [47915/259000]\tTrain Loss: 774.799623702944\tTime: 0:00:06.415819\n",
      "Epoch: [186/1000]\tSamples: [48174/259000]\tTrain Loss: 777.5378578215492\tTime: 0:00:06.189175\n",
      "Epoch: [187/1000]\tSamples: [48433/259000]\tTrain Loss: 777.3516925826497\tTime: 0:00:06.517456\n",
      "Epoch: [188/1000]\tSamples: [48692/259000]\tTrain Loss: 778.1099056995054\tTime: 0:00:06.302222\n",
      "Epoch: [189/1000]\tSamples: [48951/259000]\tTrain Loss: 774.693702962868\tTime: 0:00:05.984638\n",
      "Epoch: [190/1000]\tSamples: [49210/259000]\tTrain Loss: 779.0830587144063\tTime: 0:00:06.301980\n",
      "Epoch: [191/1000]\tSamples: [49469/259000]\tTrain Loss: 780.1139533436897\tTime: 0:00:06.209428\n",
      "Epoch: [192/1000]\tSamples: [49728/259000]\tTrain Loss: 777.4010768581081\tTime: 0:00:06.429674\n",
      "Epoch: [193/1000]\tSamples: [49987/259000]\tTrain Loss: 775.3807825508266\tTime: 0:00:06.189920\n",
      "Epoch: [194/1000]\tSamples: [50246/259000]\tTrain Loss: 774.2699780556226\tTime: 0:00:06.337355\n",
      "Epoch: [195/1000]\tSamples: [50505/259000]\tTrain Loss: 772.5240568065275\tTime: 0:00:06.450761\n",
      "Epoch: [196/1000]\tSamples: [50764/259000]\tTrain Loss: 774.3674297553692\tTime: 0:00:06.371279\n",
      "Epoch: [197/1000]\tSamples: [51023/259000]\tTrain Loss: 774.9486173534025\tTime: 0:00:06.500034\n",
      "Epoch: [198/1000]\tSamples: [51282/259000]\tTrain Loss: 774.7757384546935\tTime: 0:00:06.271005\n",
      "Epoch: [199/1000]\tSamples: [51541/259000]\tTrain Loss: 774.8697241116674\tTime: 0:00:06.401148\n",
      "Epoch: [200/1000]\tSamples: [51800/259000]\tTrain Loss: 775.1761187107867\tTime: 0:00:06.114771\n",
      "Epoch: [201/1000]\tSamples: [52059/259000]\tTrain Loss: 775.1620415057915\tTime: 0:00:06.425086\n",
      "Epoch: [202/1000]\tSamples: [52318/259000]\tTrain Loss: 772.2754726336269\tTime: 0:00:06.366491\n",
      "Epoch: [203/1000]\tSamples: [52577/259000]\tTrain Loss: 771.5081188540661\tTime: 0:00:06.659622\n",
      "Epoch: [204/1000]\tSamples: [52836/259000]\tTrain Loss: 776.179777992278\tTime: 0:00:06.542900\n",
      "Epoch: [205/1000]\tSamples: [53095/259000]\tTrain Loss: 773.1816736169764\tTime: 0:00:06.464393\n",
      "Epoch: [206/1000]\tSamples: [53354/259000]\tTrain Loss: 770.6689792471043\tTime: 0:00:06.341447\n",
      "Epoch: [207/1000]\tSamples: [53613/259000]\tTrain Loss: 770.5784568050193\tTime: 0:00:06.211479\n",
      "Epoch: [208/1000]\tSamples: [53872/259000]\tTrain Loss: 766.7658069271839\tTime: 0:00:06.330099\n",
      "Epoch: [209/1000]\tSamples: [54131/259000]\tTrain Loss: 771.9554372662283\tTime: 0:00:06.538811\n",
      "Epoch: [210/1000]\tSamples: [54390/259000]\tTrain Loss: 771.8430731931709\tTime: 0:00:06.367589\n",
      "Epoch: [211/1000]\tSamples: [54649/259000]\tTrain Loss: 771.0672060697696\tTime: 0:00:06.373687\n",
      "Epoch: [212/1000]\tSamples: [54908/259000]\tTrain Loss: 770.3603477919884\tTime: 0:00:06.571847\n",
      "Epoch: [213/1000]\tSamples: [55167/259000]\tTrain Loss: 771.9327416143823\tTime: 0:00:06.193390\n",
      "Epoch: [214/1000]\tSamples: [55426/259000]\tTrain Loss: 766.0999543768098\tTime: 0:00:06.306327\n",
      "Epoch: [215/1000]\tSamples: [55685/259000]\tTrain Loss: 775.7945561353764\tTime: 0:00:06.401605\n",
      "Epoch: [216/1000]\tSamples: [55944/259000]\tTrain Loss: 767.956118786197\tTime: 0:00:06.912841\n",
      "Epoch: [217/1000]\tSamples: [56203/259000]\tTrain Loss: 773.308422191723\tTime: 0:00:06.075964\n",
      "Epoch: [218/1000]\tSamples: [56462/259000]\tTrain Loss: 770.1847767480092\tTime: 0:00:06.775186\n",
      "Epoch: [219/1000]\tSamples: [56721/259000]\tTrain Loss: 767.0049591653595\tTime: 0:00:06.608319\n",
      "Epoch: [220/1000]\tSamples: [56980/259000]\tTrain Loss: 773.061966472611\tTime: 0:00:06.505844\n",
      "Epoch: [221/1000]\tSamples: [57239/259000]\tTrain Loss: 764.3083307568171\tTime: 0:00:06.180941\n",
      "Epoch: [222/1000]\tSamples: [57498/259000]\tTrain Loss: 766.5233451224663\tTime: 0:00:06.373374\n",
      "Epoch: [223/1000]\tSamples: [57757/259000]\tTrain Loss: 770.3103743740951\tTime: 0:00:06.322866\n",
      "Epoch: [224/1000]\tSamples: [58016/259000]\tTrain Loss: 767.8064341894908\tTime: 0:00:06.598000\n",
      "Epoch: [225/1000]\tSamples: [58275/259000]\tTrain Loss: 763.2673509516771\tTime: 0:00:06.284538\n",
      "Epoch: [226/1000]\tSamples: [58534/259000]\tTrain Loss: 766.8202050404199\tTime: 0:00:06.581645\n",
      "Epoch: [227/1000]\tSamples: [58793/259000]\tTrain Loss: 772.0305260617761\tTime: 0:00:06.124536\n",
      "Epoch: [228/1000]\tSamples: [59052/259000]\tTrain Loss: 767.9304519712234\tTime: 0:00:06.197957\n",
      "Epoch: [229/1000]\tSamples: [59311/259000]\tTrain Loss: 766.3171971148046\tTime: 0:00:06.389061\n",
      "Epoch: [230/1000]\tSamples: [59570/259000]\tTrain Loss: 770.1131360853041\tTime: 0:00:06.255174\n",
      "Epoch: [231/1000]\tSamples: [59829/259000]\tTrain Loss: 764.5285060101954\tTime: 0:00:06.599738\n",
      "Epoch: [232/1000]\tSamples: [60088/259000]\tTrain Loss: 766.93706544854\tTime: 0:00:06.405114\n",
      "Epoch: [233/1000]\tSamples: [60347/259000]\tTrain Loss: 771.5679804385859\tTime: 0:00:06.543056\n",
      "Epoch: [234/1000]\tSamples: [60606/259000]\tTrain Loss: 762.354709934544\tTime: 0:00:06.456618\n",
      "Epoch: [235/1000]\tSamples: [60865/259000]\tTrain Loss: 768.5292667109073\tTime: 0:00:06.796301\n",
      "Epoch: [236/1000]\tSamples: [61124/259000]\tTrain Loss: 769.95171388604\tTime: 0:00:06.737497\n",
      "Epoch: [237/1000]\tSamples: [61383/259000]\tTrain Loss: 759.7459561263272\tTime: 0:00:06.620803\n",
      "Epoch: [238/1000]\tSamples: [61642/259000]\tTrain Loss: 766.946470047056\tTime: 0:00:06.317489\n",
      "Epoch: [239/1000]\tSamples: [61901/259000]\tTrain Loss: 769.14791339889\tTime: 0:00:06.425795\n",
      "Epoch: [240/1000]\tSamples: [62160/259000]\tTrain Loss: 765.3357357776304\tTime: 0:00:06.387924\n",
      "Epoch: [241/1000]\tSamples: [62419/259000]\tTrain Loss: 764.0193606343508\tTime: 0:00:06.597367\n",
      "Epoch: [242/1000]\tSamples: [62678/259000]\tTrain Loss: 765.2188800826497\tTime: 0:00:06.598131\n",
      "Epoch: [243/1000]\tSamples: [62937/259000]\tTrain Loss: 764.1133236682554\tTime: 0:00:06.509179\n",
      "Epoch: [244/1000]\tSamples: [63196/259000]\tTrain Loss: 767.5246666867761\tTime: 0:00:06.187669\n",
      "Epoch: [245/1000]\tSamples: [63455/259000]\tTrain Loss: 761.1742193155767\tTime: 0:00:06.739001\n",
      "Epoch: [246/1000]\tSamples: [63714/259000]\tTrain Loss: 760.3734635165299\tTime: 0:00:06.320127\n",
      "Epoch: [247/1000]\tSamples: [63973/259000]\tTrain Loss: 764.8684327114503\tTime: 0:00:06.334020\n",
      "Epoch: [248/1000]\tSamples: [64232/259000]\tTrain Loss: 765.0922267133204\tTime: 0:00:06.420670\n",
      "Epoch: [249/1000]\tSamples: [64491/259000]\tTrain Loss: 758.568513023347\tTime: 0:00:06.458099\n",
      "Epoch: [250/1000]\tSamples: [64750/259000]\tTrain Loss: 764.0613462234556\tTime: 0:00:06.413519\n",
      "Epoch: [251/1000]\tSamples: [65009/259000]\tTrain Loss: 767.7974778105394\tTime: 0:00:06.389245\n",
      "Epoch: [252/1000]\tSamples: [65268/259000]\tTrain Loss: 766.1969979186777\tTime: 0:00:06.540966\n",
      "Epoch: [253/1000]\tSamples: [65527/259000]\tTrain Loss: 761.2296665736607\tTime: 0:00:06.473055\n",
      "Epoch: [254/1000]\tSamples: [65786/259000]\tTrain Loss: 760.777279651303\tTime: 0:00:06.469806\n",
      "Epoch: [255/1000]\tSamples: [66045/259000]\tTrain Loss: 763.1485581563707\tTime: 0:00:06.319140\n",
      "Epoch: [256/1000]\tSamples: [66304/259000]\tTrain Loss: 765.8456706043376\tTime: 0:00:06.361323\n",
      "Epoch: [257/1000]\tSamples: [66563/259000]\tTrain Loss: 759.1511277600144\tTime: 0:00:06.238529\n",
      "Epoch: [258/1000]\tSamples: [66822/259000]\tTrain Loss: 764.537715484737\tTime: 0:00:06.243480\n",
      "Epoch: [259/1000]\tSamples: [67081/259000]\tTrain Loss: 763.654622081624\tTime: 0:00:06.194399\n",
      "Epoch: [260/1000]\tSamples: [67340/259000]\tTrain Loss: 758.5032445252172\tTime: 0:00:06.217579\n",
      "Epoch: [261/1000]\tSamples: [67599/259000]\tTrain Loss: 762.2604480875965\tTime: 0:00:06.002719\n",
      "Epoch: [262/1000]\tSamples: [67858/259000]\tTrain Loss: 757.7953875331805\tTime: 0:00:06.415098\n",
      "Epoch: [263/1000]\tSamples: [68117/259000]\tTrain Loss: 766.0528691707891\tTime: 0:00:06.425426\n",
      "Epoch: [264/1000]\tSamples: [68376/259000]\tTrain Loss: 764.8922086148649\tTime: 0:00:06.234601\n",
      "Epoch: [265/1000]\tSamples: [68635/259000]\tTrain Loss: 764.7236215009652\tTime: 0:00:06.261123\n",
      "Epoch: [266/1000]\tSamples: [68894/259000]\tTrain Loss: 759.5497387035473\tTime: 0:00:06.159162\n",
      "Epoch: [267/1000]\tSamples: [69153/259000]\tTrain Loss: 760.0720497632119\tTime: 0:00:06.401565\n",
      "Epoch: [268/1000]\tSamples: [69412/259000]\tTrain Loss: 754.3240632163972\tTime: 0:00:06.246814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [269/1000]\tSamples: [69671/259000]\tTrain Loss: 756.4515470409025\tTime: 0:00:06.349542\n",
      "Epoch: [270/1000]\tSamples: [69930/259000]\tTrain Loss: 757.402534160835\tTime: 0:00:06.396916\n",
      "Epoch: [271/1000]\tSamples: [70189/259000]\tTrain Loss: 762.1014757782336\tTime: 0:00:06.398382\n",
      "Epoch: [272/1000]\tSamples: [70448/259000]\tTrain Loss: 757.072401363417\tTime: 0:00:06.394080\n",
      "Epoch: [273/1000]\tSamples: [70707/259000]\tTrain Loss: 756.4361181075049\tTime: 0:00:06.059691\n",
      "Epoch: [274/1000]\tSamples: [70966/259000]\tTrain Loss: 754.6179359465492\tTime: 0:00:06.266809\n",
      "Epoch: [275/1000]\tSamples: [71225/259000]\tTrain Loss: 757.904015971887\tTime: 0:00:06.267196\n",
      "Epoch: [276/1000]\tSamples: [71484/259000]\tTrain Loss: 755.788465816542\tTime: 0:00:06.218064\n",
      "Epoch: [277/1000]\tSamples: [71743/259000]\tTrain Loss: 761.0039147336511\tTime: 0:00:06.195360\n",
      "Epoch: [278/1000]\tSamples: [72002/259000]\tTrain Loss: 758.9718022291264\tTime: 0:00:06.181548\n",
      "Epoch: [279/1000]\tSamples: [72261/259000]\tTrain Loss: 757.2380399372587\tTime: 0:00:09.583431\n",
      "Epoch: [280/1000]\tSamples: [72520/259000]\tTrain Loss: 758.8556186278354\tTime: 0:00:06.368795\n",
      "Epoch: [281/1000]\tSamples: [72779/259000]\tTrain Loss: 759.344781234918\tTime: 0:00:06.565814\n",
      "Epoch: [282/1000]\tSamples: [73038/259000]\tTrain Loss: 759.117956684363\tTime: 0:00:06.489841\n",
      "Epoch: [283/1000]\tSamples: [73297/259000]\tTrain Loss: 754.3404611712717\tTime: 0:00:06.164122\n",
      "Epoch: [284/1000]\tSamples: [73556/259000]\tTrain Loss: 755.1594445659387\tTime: 0:00:06.329309\n",
      "Epoch: [285/1000]\tSamples: [73815/259000]\tTrain Loss: 757.3811002164274\tTime: 0:00:06.343071\n",
      "Epoch: [286/1000]\tSamples: [74074/259000]\tTrain Loss: 757.0139631470198\tTime: 0:00:06.096104\n",
      "Epoch: [287/1000]\tSamples: [74333/259000]\tTrain Loss: 752.5887012849903\tTime: 0:00:06.375694\n",
      "Epoch: [288/1000]\tSamples: [74592/259000]\tTrain Loss: 758.5106865724541\tTime: 0:00:06.452495\n",
      "Epoch: [289/1000]\tSamples: [74851/259000]\tTrain Loss: 757.987728870053\tTime: 0:00:06.329917\n",
      "Epoch: [290/1000]\tSamples: [75110/259000]\tTrain Loss: 757.1471451571549\tTime: 0:00:06.149303\n",
      "Epoch: [291/1000]\tSamples: [75369/259000]\tTrain Loss: 758.6360909598214\tTime: 0:00:06.245530\n",
      "Epoch: [292/1000]\tSamples: [75628/259000]\tTrain Loss: 754.8811270813223\tTime: 0:00:06.428381\n",
      "Epoch: [293/1000]\tSamples: [75887/259000]\tTrain Loss: 755.3385287840854\tTime: 0:00:07.024041\n",
      "Epoch: [294/1000]\tSamples: [76146/259000]\tTrain Loss: 756.5104933337356\tTime: 0:00:06.112236\n",
      "Epoch: [295/1000]\tSamples: [76405/259000]\tTrain Loss: 753.2020032728041\tTime: 0:00:06.156586\n",
      "Epoch: [296/1000]\tSamples: [76664/259000]\tTrain Loss: 750.3442283836571\tTime: 0:00:06.394865\n",
      "Epoch: [297/1000]\tSamples: [76923/259000]\tTrain Loss: 751.1618341276544\tTime: 0:00:06.258801\n",
      "Epoch: [298/1000]\tSamples: [77182/259000]\tTrain Loss: 750.259621402932\tTime: 0:00:06.227510\n",
      "Epoch: [299/1000]\tSamples: [77441/259000]\tTrain Loss: 753.441722972973\tTime: 0:00:06.555134\n",
      "Epoch: [300/1000]\tSamples: [77700/259000]\tTrain Loss: 752.1302183880309\tTime: 0:00:06.314394\n",
      "Epoch: [301/1000]\tSamples: [77959/259000]\tTrain Loss: 754.7874883114141\tTime: 0:00:06.476603\n",
      "Epoch: [302/1000]\tSamples: [78218/259000]\tTrain Loss: 757.1916013739744\tTime: 0:00:06.486318\n",
      "Epoch: [303/1000]\tSamples: [78477/259000]\tTrain Loss: 754.7442292320222\tTime: 0:00:06.085776\n",
      "Epoch: [304/1000]\tSamples: [78736/259000]\tTrain Loss: 749.5713550464527\tTime: 0:00:06.417586\n",
      "Epoch: [305/1000]\tSamples: [78995/259000]\tTrain Loss: 757.3451582860763\tTime: 0:00:06.252301\n",
      "Epoch: [306/1000]\tSamples: [79254/259000]\tTrain Loss: 752.5055822423986\tTime: 0:00:05.967992\n",
      "Epoch: [307/1000]\tSamples: [79513/259000]\tTrain Loss: 756.1501153776544\tTime: 0:00:06.330109\n",
      "Epoch: [308/1000]\tSamples: [79772/259000]\tTrain Loss: 750.9012738673383\tTime: 0:00:06.360041\n",
      "Epoch: [309/1000]\tSamples: [80031/259000]\tTrain Loss: 749.0286445764962\tTime: 0:00:06.299780\n",
      "Epoch: [310/1000]\tSamples: [80290/259000]\tTrain Loss: 762.7626161317568\tTime: 0:00:06.214300\n",
      "Epoch: [311/1000]\tSamples: [80549/259000]\tTrain Loss: 747.8012110883204\tTime: 0:00:06.413450\n",
      "Epoch: [312/1000]\tSamples: [80808/259000]\tTrain Loss: 750.1112121817688\tTime: 0:00:06.400628\n",
      "Epoch: [313/1000]\tSamples: [81067/259000]\tTrain Loss: 749.8123058186535\tTime: 0:00:06.371537\n",
      "Epoch: [314/1000]\tSamples: [81326/259000]\tTrain Loss: 752.3523920125483\tTime: 0:00:06.003199\n",
      "Epoch: [315/1000]\tSamples: [81585/259000]\tTrain Loss: 753.5922295412041\tTime: 0:00:06.416276\n",
      "Epoch: [316/1000]\tSamples: [81844/259000]\tTrain Loss: 748.4539318894788\tTime: 0:00:06.347973\n",
      "Epoch: [317/1000]\tSamples: [82103/259000]\tTrain Loss: 753.8562926067809\tTime: 0:00:06.385361\n",
      "Epoch: [318/1000]\tSamples: [82362/259000]\tTrain Loss: 753.3214229156612\tTime: 0:00:06.077764\n",
      "Epoch: [319/1000]\tSamples: [82621/259000]\tTrain Loss: 749.6422095574927\tTime: 0:00:06.469345\n",
      "Epoch: [320/1000]\tSamples: [82880/259000]\tTrain Loss: 754.8028748265565\tTime: 0:00:06.408799\n",
      "Epoch: [321/1000]\tSamples: [83139/259000]\tTrain Loss: 749.785463546694\tTime: 0:00:06.254122\n",
      "Epoch: [322/1000]\tSamples: [83398/259000]\tTrain Loss: 751.9478519395511\tTime: 0:00:06.315172\n",
      "Epoch: [323/1000]\tSamples: [83657/259000]\tTrain Loss: 748.3518886492519\tTime: 0:00:06.521007\n",
      "Epoch: [324/1000]\tSamples: [83916/259000]\tTrain Loss: 751.1388094986728\tTime: 0:00:06.244001\n",
      "Epoch: [325/1000]\tSamples: [84175/259000]\tTrain Loss: 747.821071315456\tTime: 0:00:06.149047\n",
      "Epoch: [326/1000]\tSamples: [84434/259000]\tTrain Loss: 755.3385259562017\tTime: 0:00:06.216554\n",
      "Epoch: [327/1000]\tSamples: [84693/259000]\tTrain Loss: 751.4178367820946\tTime: 0:00:06.156360\n",
      "Epoch: [328/1000]\tSamples: [84952/259000]\tTrain Loss: 749.376944170035\tTime: 0:00:06.661197\n",
      "Epoch: [329/1000]\tSamples: [85211/259000]\tTrain Loss: 750.8213484480574\tTime: 0:00:06.334762\n",
      "Epoch: [330/1000]\tSamples: [85470/259000]\tTrain Loss: 747.5983080771899\tTime: 0:00:06.249585\n",
      "Epoch: [331/1000]\tSamples: [85729/259000]\tTrain Loss: 751.0951205809604\tTime: 0:00:06.347804\n",
      "Epoch: [332/1000]\tSamples: [85988/259000]\tTrain Loss: 750.2987074686293\tTime: 0:00:06.086781\n",
      "Epoch: [333/1000]\tSamples: [86247/259000]\tTrain Loss: 751.2196247586872\tTime: 0:00:06.161958\n",
      "Epoch: [334/1000]\tSamples: [86506/259000]\tTrain Loss: 748.7841730891047\tTime: 0:00:06.236451\n",
      "Epoch: [335/1000]\tSamples: [86765/259000]\tTrain Loss: 751.7401118333736\tTime: 0:00:06.317558\n",
      "Epoch: [336/1000]\tSamples: [87024/259000]\tTrain Loss: 747.7565804853402\tTime: 0:00:06.039323\n",
      "Epoch: [337/1000]\tSamples: [87283/259000]\tTrain Loss: 749.773871108832\tTime: 0:00:05.781547\n",
      "Epoch: [338/1000]\tSamples: [87542/259000]\tTrain Loss: 749.7530979465794\tTime: 0:00:06.232901\n",
      "Epoch: [339/1000]\tSamples: [87801/259000]\tTrain Loss: 745.7807876410171\tTime: 0:00:09.981759\n",
      "Epoch: [340/1000]\tSamples: [88060/259000]\tTrain Loss: 748.4376677877655\tTime: 0:00:08.346903\n",
      "Epoch: [341/1000]\tSamples: [88319/259000]\tTrain Loss: 752.8028361788128\tTime: 0:00:08.218784\n",
      "Epoch: [342/1000]\tSamples: [88578/259000]\tTrain Loss: 747.2447420215975\tTime: 0:00:05.824299\n",
      "Epoch: [343/1000]\tSamples: [88837/259000]\tTrain Loss: 749.3970933126207\tTime: 0:00:07.042501\n",
      "Epoch: [344/1000]\tSamples: [89096/259000]\tTrain Loss: 745.3854198087597\tTime: 0:00:05.894954\n",
      "Epoch: [345/1000]\tSamples: [89355/259000]\tTrain Loss: 750.2653770888634\tTime: 0:00:06.193757\n",
      "Epoch: [346/1000]\tSamples: [89614/259000]\tTrain Loss: 747.640217784749\tTime: 0:00:06.001091\n",
      "Epoch: [347/1000]\tSamples: [89873/259000]\tTrain Loss: 748.8858553028475\tTime: 0:00:06.169947\n",
      "Epoch: [348/1000]\tSamples: [90132/259000]\tTrain Loss: 743.1688953532215\tTime: 0:00:06.314210\n",
      "Epoch: [349/1000]\tSamples: [90391/259000]\tTrain Loss: 750.2060754253137\tTime: 0:00:06.916859\n",
      "Epoch: [350/1000]\tSamples: [90650/259000]\tTrain Loss: 749.0030776800796\tTime: 0:00:06.484132\n",
      "Epoch: [351/1000]\tSamples: [90909/259000]\tTrain Loss: 747.8988965597853\tTime: 0:00:06.115419\n",
      "Epoch: [352/1000]\tSamples: [91168/259000]\tTrain Loss: 745.8099171995657\tTime: 0:00:10.012880\n",
      "Epoch: [353/1000]\tSamples: [91427/259000]\tTrain Loss: 750.6017915585786\tTime: 0:00:09.168464\n",
      "Epoch: [354/1000]\tSamples: [91686/259000]\tTrain Loss: 747.2030137699084\tTime: 0:00:06.402849\n",
      "Epoch: [355/1000]\tSamples: [91945/259000]\tTrain Loss: 752.1677264946308\tTime: 0:00:06.218988\n",
      "Epoch: [356/1000]\tSamples: [92204/259000]\tTrain Loss: 749.821767917471\tTime: 0:00:06.420242\n",
      "Epoch: [357/1000]\tSamples: [92463/259000]\tTrain Loss: 751.5040353900217\tTime: 0:00:06.303153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [358/1000]\tSamples: [92722/259000]\tTrain Loss: 741.8415998657698\tTime: 0:00:06.014905\n",
      "Epoch: [359/1000]\tSamples: [92981/259000]\tTrain Loss: 748.29287920035\tTime: 0:00:06.253549\n",
      "Epoch: [360/1000]\tSamples: [93240/259000]\tTrain Loss: 742.664198709731\tTime: 0:00:06.161614\n",
      "Epoch: [361/1000]\tSamples: [93499/259000]\tTrain Loss: 742.8328419099903\tTime: 0:00:06.466260\n",
      "Epoch: [362/1000]\tSamples: [93758/259000]\tTrain Loss: 743.1347463011282\tTime: 0:00:06.262043\n",
      "Epoch: [363/1000]\tSamples: [94017/259000]\tTrain Loss: 748.8651853583494\tTime: 0:00:06.358870\n",
      "Epoch: [364/1000]\tSamples: [94276/259000]\tTrain Loss: 742.7626180170125\tTime: 0:00:06.326756\n",
      "Epoch: [365/1000]\tSamples: [94535/259000]\tTrain Loss: 746.8189815094112\tTime: 0:00:06.408554\n",
      "Epoch: [366/1000]\tSamples: [94794/259000]\tTrain Loss: 743.6612129358712\tTime: 0:00:06.139673\n",
      "Epoch: [367/1000]\tSamples: [95053/259000]\tTrain Loss: 743.505181625543\tTime: 0:00:06.364373\n",
      "Epoch: [368/1000]\tSamples: [95312/259000]\tTrain Loss: 750.7368032094595\tTime: 0:00:06.324212\n",
      "Epoch: [369/1000]\tSamples: [95571/259000]\tTrain Loss: 740.966353368575\tTime: 0:00:06.323415\n",
      "Epoch: [370/1000]\tSamples: [95830/259000]\tTrain Loss: 747.6431946036438\tTime: 0:00:06.129611\n",
      "Epoch: [371/1000]\tSamples: [96089/259000]\tTrain Loss: 744.335666023166\tTime: 0:00:06.104047\n",
      "Epoch: [372/1000]\tSamples: [96348/259000]\tTrain Loss: 736.4900948660714\tTime: 0:00:06.400366\n",
      "Epoch: [373/1000]\tSamples: [96607/259000]\tTrain Loss: 750.4307130791506\tTime: 0:00:06.429338\n",
      "Epoch: [374/1000]\tSamples: [96866/259000]\tTrain Loss: 738.0997074083011\tTime: 0:00:06.180570\n",
      "Epoch: [375/1000]\tSamples: [97125/259000]\tTrain Loss: 740.105486188616\tTime: 0:00:06.686869\n",
      "Epoch: [376/1000]\tSamples: [97384/259000]\tTrain Loss: 741.9791358741554\tTime: 0:00:06.267288\n",
      "Epoch: [377/1000]\tSamples: [97643/259000]\tTrain Loss: 750.6194276551943\tTime: 0:00:06.475216\n",
      "Epoch: [378/1000]\tSamples: [97902/259000]\tTrain Loss: 739.6651182432432\tTime: 0:00:06.273753\n",
      "Epoch: [379/1000]\tSamples: [98161/259000]\tTrain Loss: 742.5737870264237\tTime: 0:00:06.200586\n",
      "Epoch: [380/1000]\tSamples: [98420/259000]\tTrain Loss: 742.5443892902389\tTime: 0:00:06.342138\n",
      "Epoch: [381/1000]\tSamples: [98679/259000]\tTrain Loss: 736.3103112180261\tTime: 0:00:06.138542\n",
      "Epoch: [382/1000]\tSamples: [98938/259000]\tTrain Loss: 745.4753790306769\tTime: 0:00:06.407140\n",
      "Epoch: [383/1000]\tSamples: [99197/259000]\tTrain Loss: 742.9086989472731\tTime: 0:00:06.235184\n",
      "Epoch: [384/1000]\tSamples: [99456/259000]\tTrain Loss: 740.9094549348456\tTime: 0:00:06.366462\n",
      "Epoch: [385/1000]\tSamples: [99715/259000]\tTrain Loss: 739.3348082317809\tTime: 0:00:06.439062\n",
      "Epoch: [386/1000]\tSamples: [99974/259000]\tTrain Loss: 741.9403816134774\tTime: 0:00:06.049066\n",
      "Epoch: [387/1000]\tSamples: [100233/259000]\tTrain Loss: 740.2693040766771\tTime: 0:00:06.224518\n",
      "Epoch: [388/1000]\tSamples: [100492/259000]\tTrain Loss: 747.8869515790902\tTime: 0:00:06.283176\n",
      "Epoch: [389/1000]\tSamples: [100751/259000]\tTrain Loss: 742.2659511492519\tTime: 0:00:06.114413\n",
      "Epoch: [390/1000]\tSamples: [101010/259000]\tTrain Loss: 742.4955036649372\tTime: 0:00:06.390137\n",
      "Epoch: [391/1000]\tSamples: [101269/259000]\tTrain Loss: 744.7361848455598\tTime: 0:00:06.300130\n",
      "Epoch: [392/1000]\tSamples: [101528/259000]\tTrain Loss: 743.5075890971887\tTime: 0:00:06.075071\n",
      "Epoch: [393/1000]\tSamples: [101787/259000]\tTrain Loss: 739.7503204934845\tTime: 0:00:06.335359\n",
      "Epoch: [394/1000]\tSamples: [102046/259000]\tTrain Loss: 744.34756670035\tTime: 0:00:06.463544\n",
      "Epoch: [395/1000]\tSamples: [102305/259000]\tTrain Loss: 747.7423175826497\tTime: 0:00:06.511297\n",
      "Epoch: [396/1000]\tSamples: [102564/259000]\tTrain Loss: 741.8617051761584\tTime: 0:00:06.236717\n",
      "Epoch: [397/1000]\tSamples: [102823/259000]\tTrain Loss: 744.8763097814611\tTime: 0:00:06.342259\n",
      "Epoch: [398/1000]\tSamples: [103082/259000]\tTrain Loss: 742.4189764192206\tTime: 0:00:06.278717\n",
      "Epoch: [399/1000]\tSamples: [103341/259000]\tTrain Loss: 733.8688352135617\tTime: 0:00:06.364011\n",
      "Epoch: [400/1000]\tSamples: [103600/259000]\tTrain Loss: 739.9903899086028\tTime: 0:00:06.111356\n",
      "Epoch: [401/1000]\tSamples: [103859/259000]\tTrain Loss: 743.1946092995897\tTime: 0:00:06.458427\n",
      "Epoch: [402/1000]\tSamples: [104118/259000]\tTrain Loss: 736.2189375829513\tTime: 0:00:06.469463\n",
      "Epoch: [403/1000]\tSamples: [104377/259000]\tTrain Loss: 735.0439222181166\tTime: 0:00:06.508096\n",
      "Epoch: [404/1000]\tSamples: [104636/259000]\tTrain Loss: 744.6240290932674\tTime: 0:00:06.402982\n",
      "Epoch: [405/1000]\tSamples: [104895/259000]\tTrain Loss: 739.0808030058519\tTime: 0:00:06.265773\n",
      "Epoch: [406/1000]\tSamples: [105154/259000]\tTrain Loss: 734.8092498190155\tTime: 0:00:06.473903\n",
      "Epoch: [407/1000]\tSamples: [105413/259000]\tTrain Loss: 742.6440552229127\tTime: 0:00:06.249242\n",
      "Epoch: [408/1000]\tSamples: [105672/259000]\tTrain Loss: 738.9751692959701\tTime: 0:00:06.035184\n",
      "Epoch: [409/1000]\tSamples: [105931/259000]\tTrain Loss: 740.1448724812983\tTime: 0:00:06.218162\n",
      "Epoch: [410/1000]\tSamples: [106190/259000]\tTrain Loss: 735.5105498914093\tTime: 0:00:06.324489\n",
      "Epoch: [411/1000]\tSamples: [106449/259000]\tTrain Loss: 737.979880550193\tTime: 0:00:06.186982\n",
      "Epoch: [412/1000]\tSamples: [106708/259000]\tTrain Loss: 736.8020358877293\tTime: 0:00:06.257682\n",
      "Epoch: [413/1000]\tSamples: [106967/259000]\tTrain Loss: 742.6283331322394\tTime: 0:00:06.422213\n",
      "Epoch: [414/1000]\tSamples: [107226/259000]\tTrain Loss: 735.6174146733229\tTime: 0:00:06.697413\n",
      "Epoch: [415/1000]\tSamples: [107485/259000]\tTrain Loss: 742.2811745897683\tTime: 0:00:06.244680\n",
      "Epoch: [416/1000]\tSamples: [107744/259000]\tTrain Loss: 738.4402138257119\tTime: 0:00:06.198799\n",
      "Epoch: [417/1000]\tSamples: [108003/259000]\tTrain Loss: 745.9086687831805\tTime: 0:00:06.866337\n",
      "Epoch: [418/1000]\tSamples: [108262/259000]\tTrain Loss: 736.9769084444378\tTime: 0:00:06.325950\n",
      "Epoch: [419/1000]\tSamples: [108521/259000]\tTrain Loss: 733.9753012638755\tTime: 0:00:06.259248\n",
      "Epoch: [420/1000]\tSamples: [108780/259000]\tTrain Loss: 736.1371862934363\tTime: 0:00:06.269733\n",
      "Epoch: [421/1000]\tSamples: [109039/259000]\tTrain Loss: 742.5567000105574\tTime: 0:00:06.187490\n",
      "Epoch: [422/1000]\tSamples: [109298/259000]\tTrain Loss: 736.8070912011342\tTime: 0:00:06.332771\n",
      "Epoch: [423/1000]\tSamples: [109557/259000]\tTrain Loss: 736.5455025337837\tTime: 0:00:06.221471\n",
      "Epoch: [424/1000]\tSamples: [109816/259000]\tTrain Loss: 742.2167893339769\tTime: 0:00:06.281210\n",
      "Epoch: [425/1000]\tSamples: [110075/259000]\tTrain Loss: 739.3207150021115\tTime: 0:00:06.434889\n",
      "Epoch: [426/1000]\tSamples: [110334/259000]\tTrain Loss: 732.9648663730695\tTime: 0:00:06.195724\n",
      "Epoch: [427/1000]\tSamples: [110593/259000]\tTrain Loss: 737.123074211209\tTime: 0:00:06.406529\n",
      "Epoch: [428/1000]\tSamples: [110852/259000]\tTrain Loss: 738.5772304461269\tTime: 0:00:06.362581\n",
      "Epoch: [429/1000]\tSamples: [111111/259000]\tTrain Loss: 730.404215809001\tTime: 0:00:06.612658\n",
      "Epoch: [430/1000]\tSamples: [111370/259000]\tTrain Loss: 738.7883366765203\tTime: 0:00:06.278951\n",
      "Epoch: [431/1000]\tSamples: [111629/259000]\tTrain Loss: 743.8319035239201\tTime: 0:00:06.414711\n",
      "Epoch: [432/1000]\tSamples: [111888/259000]\tTrain Loss: 739.2212201564008\tTime: 0:00:06.560314\n",
      "Epoch: [433/1000]\tSamples: [112147/259000]\tTrain Loss: 739.0156410246742\tTime: 0:00:06.404563\n",
      "Epoch: [434/1000]\tSamples: [112406/259000]\tTrain Loss: 737.1491802907818\tTime: 0:00:06.391312\n",
      "Epoch: [435/1000]\tSamples: [112665/259000]\tTrain Loss: 740.288728809725\tTime: 0:00:06.223549\n",
      "Epoch: [436/1000]\tSamples: [112924/259000]\tTrain Loss: 735.7593866885859\tTime: 0:00:06.202535\n",
      "Epoch: [437/1000]\tSamples: [113183/259000]\tTrain Loss: 733.1589100959218\tTime: 0:00:06.320572\n",
      "Epoch: [438/1000]\tSamples: [113442/259000]\tTrain Loss: 736.0930741357987\tTime: 0:00:06.423406\n",
      "Epoch: [439/1000]\tSamples: [113701/259000]\tTrain Loss: 736.4923609435328\tTime: 0:00:06.243764\n",
      "Epoch: [440/1000]\tSamples: [113960/259000]\tTrain Loss: 740.4179989140927\tTime: 0:00:06.162293\n",
      "Epoch: [441/1000]\tSamples: [114219/259000]\tTrain Loss: 743.2458731750723\tTime: 0:00:06.398130\n",
      "Epoch: [442/1000]\tSamples: [114478/259000]\tTrain Loss: 737.794876157547\tTime: 0:00:06.403479\n",
      "Epoch: [443/1000]\tSamples: [114737/259000]\tTrain Loss: 740.1081213048986\tTime: 0:00:06.373788\n",
      "Epoch: [444/1000]\tSamples: [114996/259000]\tTrain Loss: 733.287417614322\tTime: 0:00:06.279230\n",
      "Epoch: [445/1000]\tSamples: [115255/259000]\tTrain Loss: 744.2002876900337\tTime: 0:00:06.146888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [446/1000]\tSamples: [115514/259000]\tTrain Loss: 734.5797218116554\tTime: 0:00:06.139424\n",
      "Epoch: [447/1000]\tSamples: [115773/259000]\tTrain Loss: 744.7899872179657\tTime: 0:00:06.318236\n",
      "Epoch: [448/1000]\tSamples: [116032/259000]\tTrain Loss: 735.3280316798383\tTime: 0:00:06.412676\n",
      "Epoch: [449/1000]\tSamples: [116291/259000]\tTrain Loss: 736.941650390625\tTime: 0:00:06.281289\n",
      "Epoch: [450/1000]\tSamples: [116550/259000]\tTrain Loss: 737.0122485068774\tTime: 0:00:06.549547\n",
      "Epoch: [451/1000]\tSamples: [116809/259000]\tTrain Loss: 736.505542652027\tTime: 0:00:06.466291\n",
      "Epoch: [452/1000]\tSamples: [117068/259000]\tTrain Loss: 744.1807488990106\tTime: 0:00:06.299389\n",
      "Epoch: [453/1000]\tSamples: [117327/259000]\tTrain Loss: 738.5365456835183\tTime: 0:00:06.373075\n",
      "Epoch: [454/1000]\tSamples: [117586/259000]\tTrain Loss: 735.285978221525\tTime: 0:00:06.170872\n",
      "Epoch: [455/1000]\tSamples: [117845/259000]\tTrain Loss: 731.9986553413067\tTime: 0:00:06.274718\n",
      "Epoch: [456/1000]\tSamples: [118104/259000]\tTrain Loss: 729.637740558639\tTime: 0:00:06.470435\n",
      "Epoch: [457/1000]\tSamples: [118363/259000]\tTrain Loss: 734.2821832016168\tTime: 0:00:06.334685\n",
      "Epoch: [458/1000]\tSamples: [118622/259000]\tTrain Loss: 734.3388389086631\tTime: 0:00:06.435508\n",
      "Epoch: [459/1000]\tSamples: [118881/259000]\tTrain Loss: 734.8023257458071\tTime: 0:00:06.344226\n",
      "Epoch: [460/1000]\tSamples: [119140/259000]\tTrain Loss: 734.2656306557674\tTime: 0:00:06.223232\n",
      "Epoch: [461/1000]\tSamples: [119399/259000]\tTrain Loss: 738.2012963018823\tTime: 0:00:06.494334\n",
      "Epoch: [462/1000]\tSamples: [119658/259000]\tTrain Loss: 740.228506198721\tTime: 0:00:06.158469\n",
      "Epoch: [463/1000]\tSamples: [119917/259000]\tTrain Loss: 733.3520630354127\tTime: 0:00:06.293060\n",
      "Epoch: [464/1000]\tSamples: [120176/259000]\tTrain Loss: 740.9809287524131\tTime: 0:00:06.278276\n",
      "Epoch: [465/1000]\tSamples: [120435/259000]\tTrain Loss: 733.6195610370415\tTime: 0:00:06.363995\n",
      "Epoch: [466/1000]\tSamples: [120694/259000]\tTrain Loss: 733.3845205417471\tTime: 0:00:06.173765\n",
      "Epoch: [467/1000]\tSamples: [120953/259000]\tTrain Loss: 729.4062820493484\tTime: 0:00:06.337726\n",
      "Epoch: [468/1000]\tSamples: [121212/259000]\tTrain Loss: 742.2630497405888\tTime: 0:00:06.816460\n",
      "Epoch: [469/1000]\tSamples: [121471/259000]\tTrain Loss: 732.802101871682\tTime: 0:00:06.234336\n",
      "Epoch: [470/1000]\tSamples: [121730/259000]\tTrain Loss: 739.8249342045729\tTime: 0:00:06.435783\n",
      "Epoch: [471/1000]\tSamples: [121989/259000]\tTrain Loss: 734.4926333629946\tTime: 0:00:06.191808\n",
      "Epoch: [472/1000]\tSamples: [122248/259000]\tTrain Loss: 735.7846481735642\tTime: 0:00:06.281241\n",
      "Epoch: [473/1000]\tSamples: [122507/259000]\tTrain Loss: 733.5700523347008\tTime: 0:00:06.256643\n",
      "Epoch: [474/1000]\tSamples: [122766/259000]\tTrain Loss: 736.5865191014117\tTime: 0:00:06.014609\n",
      "Epoch: [475/1000]\tSamples: [123025/259000]\tTrain Loss: 731.8306220212959\tTime: 0:00:06.303017\n",
      "Epoch: [476/1000]\tSamples: [123284/259000]\tTrain Loss: 739.292669936957\tTime: 0:00:06.510895\n",
      "Epoch: [477/1000]\tSamples: [123543/259000]\tTrain Loss: 729.9051047071067\tTime: 0:00:06.218629\n",
      "Epoch: [478/1000]\tSamples: [123802/259000]\tTrain Loss: 740.330937801641\tTime: 0:00:06.495567\n",
      "Epoch: [479/1000]\tSamples: [124061/259000]\tTrain Loss: 745.2493920050073\tTime: 0:00:06.082580\n",
      "Epoch: [480/1000]\tSamples: [124320/259000]\tTrain Loss: 734.0942986094353\tTime: 0:00:06.706116\n",
      "Epoch: [481/1000]\tSamples: [124579/259000]\tTrain Loss: 740.912479827763\tTime: 0:00:06.273683\n",
      "Epoch: [482/1000]\tSamples: [124838/259000]\tTrain Loss: 733.1995656370657\tTime: 0:00:06.433872\n",
      "Epoch: [483/1000]\tSamples: [125097/259000]\tTrain Loss: 730.2728106524494\tTime: 0:00:06.313235\n",
      "Epoch: [484/1000]\tSamples: [125356/259000]\tTrain Loss: 727.6664049303209\tTime: 0:00:06.403482\n",
      "Epoch: [485/1000]\tSamples: [125615/259000]\tTrain Loss: 738.2553296181226\tTime: 0:00:06.184771\n",
      "Epoch: [486/1000]\tSamples: [125874/259000]\tTrain Loss: 739.464518543376\tTime: 0:00:06.314179\n",
      "Epoch: [487/1000]\tSamples: [126133/259000]\tTrain Loss: 727.5962950953185\tTime: 0:00:06.085000\n",
      "Epoch: [488/1000]\tSamples: [126392/259000]\tTrain Loss: 734.8964344157215\tTime: 0:00:06.139855\n",
      "Epoch: [489/1000]\tSamples: [126651/259000]\tTrain Loss: 735.5946191029199\tTime: 0:00:06.303595\n",
      "Epoch: [490/1000]\tSamples: [126910/259000]\tTrain Loss: 732.6050389116796\tTime: 0:00:06.708648\n",
      "Epoch: [491/1000]\tSamples: [127169/259000]\tTrain Loss: 731.2661976464467\tTime: 0:00:06.417619\n",
      "Epoch: [492/1000]\tSamples: [127428/259000]\tTrain Loss: 735.2614548141892\tTime: 0:00:06.026173\n",
      "Epoch: [493/1000]\tSamples: [127687/259000]\tTrain Loss: 727.1068930607505\tTime: 0:00:06.435217\n",
      "Epoch: [494/1000]\tSamples: [127946/259000]\tTrain Loss: 732.6211894267315\tTime: 0:00:06.227277\n",
      "Epoch: [495/1000]\tSamples: [128205/259000]\tTrain Loss: 734.3637544492036\tTime: 0:00:06.486087\n",
      "Epoch: [496/1000]\tSamples: [128464/259000]\tTrain Loss: 733.5012065637065\tTime: 0:00:06.284563\n",
      "Epoch: [497/1000]\tSamples: [128723/259000]\tTrain Loss: 734.7062413278234\tTime: 0:00:06.119202\n",
      "Epoch: [498/1000]\tSamples: [128982/259000]\tTrain Loss: 731.014458026665\tTime: 0:00:06.153325\n",
      "Epoch: [499/1000]\tSamples: [129241/259000]\tTrain Loss: 735.2127379192809\tTime: 0:00:06.239125\n",
      "Epoch: [500/1000]\tSamples: [129500/259000]\tTrain Loss: 731.8645396582408\tTime: 0:00:06.674513\n",
      "Epoch: [501/1000]\tSamples: [129759/259000]\tTrain Loss: 730.7455969850989\tTime: 0:00:06.088206\n",
      "Epoch: [502/1000]\tSamples: [130018/259000]\tTrain Loss: 729.1587932100628\tTime: 0:00:06.124822\n",
      "Epoch: [503/1000]\tSamples: [130277/259000]\tTrain Loss: 737.2893924197635\tTime: 0:00:06.360338\n",
      "Epoch: [504/1000]\tSamples: [130536/259000]\tTrain Loss: 735.8361029311957\tTime: 0:00:06.159679\n",
      "Epoch: [505/1000]\tSamples: [130795/259000]\tTrain Loss: 732.7852071519063\tTime: 0:00:06.132919\n",
      "Epoch: [506/1000]\tSamples: [131054/259000]\tTrain Loss: 735.873906551641\tTime: 0:00:06.210856\n",
      "Epoch: [507/1000]\tSamples: [131313/259000]\tTrain Loss: 733.0793268505671\tTime: 0:00:06.320302\n",
      "Epoch: [508/1000]\tSamples: [131572/259000]\tTrain Loss: 728.866519176822\tTime: 0:00:06.225678\n",
      "Epoch: [509/1000]\tSamples: [131831/259000]\tTrain Loss: 734.6829763287283\tTime: 0:00:06.321421\n",
      "Epoch: [510/1000]\tSamples: [132090/259000]\tTrain Loss: 732.8412435524252\tTime: 0:00:06.046144\n",
      "Epoch: [511/1000]\tSamples: [132349/259000]\tTrain Loss: 732.6897660774614\tTime: 0:00:06.326649\n",
      "Epoch: [512/1000]\tSamples: [132608/259000]\tTrain Loss: 730.926405269667\tTime: 0:00:06.592241\n",
      "Epoch: [513/1000]\tSamples: [132867/259000]\tTrain Loss: 735.948468418195\tTime: 0:00:06.382607\n",
      "Epoch: [514/1000]\tSamples: [133126/259000]\tTrain Loss: 731.8909907396236\tTime: 0:00:06.630498\n",
      "Epoch: [515/1000]\tSamples: [133385/259000]\tTrain Loss: 733.8954333448962\tTime: 0:00:06.233613\n",
      "Epoch: [516/1000]\tSamples: [133644/259000]\tTrain Loss: 729.4494515790902\tTime: 0:00:06.302980\n",
      "Epoch: [517/1000]\tSamples: [133903/259000]\tTrain Loss: 736.6659684936052\tTime: 0:00:06.041266\n",
      "Epoch: [518/1000]\tSamples: [134162/259000]\tTrain Loss: 733.25737794854\tTime: 0:00:06.652184\n",
      "Epoch: [519/1000]\tSamples: [134421/259000]\tTrain Loss: 732.7900550871742\tTime: 0:00:06.285135\n",
      "Epoch: [520/1000]\tSamples: [134680/259000]\tTrain Loss: 740.8215812771476\tTime: 0:00:06.257542\n",
      "Epoch: [521/1000]\tSamples: [134939/259000]\tTrain Loss: 734.3638034658543\tTime: 0:00:06.260447\n",
      "Epoch: [522/1000]\tSamples: [135198/259000]\tTrain Loss: 730.6159262638755\tTime: 0:00:06.219903\n",
      "Epoch: [523/1000]\tSamples: [135457/259000]\tTrain Loss: 728.2462681361607\tTime: 0:00:06.205445\n",
      "Epoch: [524/1000]\tSamples: [135716/259000]\tTrain Loss: 737.7790810132119\tTime: 0:00:05.956869\n",
      "Epoch: [525/1000]\tSamples: [135975/259000]\tTrain Loss: 729.0755855604489\tTime: 0:00:06.104422\n",
      "Epoch: [526/1000]\tSamples: [136234/259000]\tTrain Loss: 737.1567910684122\tTime: 0:00:06.280731\n",
      "Epoch: [527/1000]\tSamples: [136493/259000]\tTrain Loss: 736.2327244585546\tTime: 0:00:06.224948\n",
      "Epoch: [528/1000]\tSamples: [136752/259000]\tTrain Loss: 726.2924766982384\tTime: 0:00:06.220901\n",
      "Epoch: [529/1000]\tSamples: [137011/259000]\tTrain Loss: 730.420771182734\tTime: 0:00:06.539079\n",
      "Epoch: [530/1000]\tSamples: [137270/259000]\tTrain Loss: 740.5660565350506\tTime: 0:00:06.540321\n",
      "Epoch: [531/1000]\tSamples: [137529/259000]\tTrain Loss: 725.7534674567145\tTime: 0:00:06.055416\n",
      "Epoch: [532/1000]\tSamples: [137788/259000]\tTrain Loss: 734.7064298534025\tTime: 0:00:10.423392\n",
      "Epoch: [533/1000]\tSamples: [138047/259000]\tTrain Loss: 726.8520375844595\tTime: 0:00:06.118343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [534/1000]\tSamples: [138306/259000]\tTrain Loss: 732.0700787282818\tTime: 0:00:06.353893\n",
      "Epoch: [535/1000]\tSamples: [138565/259000]\tTrain Loss: 734.1623389048926\tTime: 0:00:06.426185\n",
      "Epoch: [536/1000]\tSamples: [138824/259000]\tTrain Loss: 736.5982840401786\tTime: 0:00:05.780182\n",
      "Epoch: [537/1000]\tSamples: [139083/259000]\tTrain Loss: 733.3822827431226\tTime: 0:00:05.669889\n",
      "Epoch: [538/1000]\tSamples: [139342/259000]\tTrain Loss: 735.4373340974903\tTime: 0:00:05.917966\n",
      "Epoch: [539/1000]\tSamples: [139601/259000]\tTrain Loss: 730.9587996199324\tTime: 0:00:06.087583\n",
      "Epoch: [540/1000]\tSamples: [139860/259000]\tTrain Loss: 737.5436625241313\tTime: 0:00:05.784675\n",
      "Epoch: [541/1000]\tSamples: [140119/259000]\tTrain Loss: 733.6743352588079\tTime: 0:00:05.019871\n",
      "Epoch: [542/1000]\tSamples: [140378/259000]\tTrain Loss: 737.22240315441\tTime: 0:00:05.144245\n",
      "Epoch: [543/1000]\tSamples: [140637/259000]\tTrain Loss: 741.7126851321187\tTime: 0:00:05.370529\n",
      "Epoch: [544/1000]\tSamples: [140896/259000]\tTrain Loss: 730.0518728131033\tTime: 0:00:05.429546\n",
      "Epoch: [545/1000]\tSamples: [141155/259000]\tTrain Loss: 727.5490326752533\tTime: 0:00:05.303253\n",
      "Epoch: [546/1000]\tSamples: [141414/259000]\tTrain Loss: 731.0987374441964\tTime: 0:00:05.588859\n",
      "Epoch: [547/1000]\tSamples: [141673/259000]\tTrain Loss: 737.3272558970801\tTime: 0:00:05.696907\n",
      "Epoch: [548/1000]\tSamples: [141932/259000]\tTrain Loss: 730.064055336028\tTime: 0:00:05.581015\n",
      "Epoch: [549/1000]\tSamples: [142191/259000]\tTrain Loss: 732.9578645330598\tTime: 0:00:05.465315\n",
      "Epoch: [550/1000]\tSamples: [142450/259000]\tTrain Loss: 726.0989382239383\tTime: 0:00:05.253726\n",
      "Epoch: [551/1000]\tSamples: [142709/259000]\tTrain Loss: 732.516040698902\tTime: 0:00:05.395294\n",
      "Epoch: [552/1000]\tSamples: [142968/259000]\tTrain Loss: 726.4227648407336\tTime: 0:00:05.375485\n",
      "Epoch: [553/1000]\tSamples: [143227/259000]\tTrain Loss: 738.3482840401786\tTime: 0:00:05.651392\n",
      "Epoch: [554/1000]\tSamples: [143486/259000]\tTrain Loss: 731.5720657878861\tTime: 0:00:05.829405\n",
      "Epoch: [555/1000]\tSamples: [143745/259000]\tTrain Loss: 729.8409984691723\tTime: 0:00:05.767447\n",
      "Epoch: [556/1000]\tSamples: [144004/259000]\tTrain Loss: 728.9410735023528\tTime: 0:00:05.522052\n",
      "Epoch: [557/1000]\tSamples: [144263/259000]\tTrain Loss: 730.3553499788851\tTime: 0:00:05.492014\n",
      "Epoch: [558/1000]\tSamples: [144522/259000]\tTrain Loss: 730.5038657170005\tTime: 0:00:05.269083\n",
      "Epoch: [559/1000]\tSamples: [144781/259000]\tTrain Loss: 727.3265809755068\tTime: 0:00:05.294720\n",
      "Epoch: [560/1000]\tSamples: [145040/259000]\tTrain Loss: 735.509829723697\tTime: 0:00:05.450118\n",
      "Epoch: [561/1000]\tSamples: [145299/259000]\tTrain Loss: 739.0270204286318\tTime: 0:00:05.522145\n",
      "Epoch: [562/1000]\tSamples: [145558/259000]\tTrain Loss: 732.6426902977196\tTime: 0:00:05.539957\n",
      "Epoch: [563/1000]\tSamples: [145817/259000]\tTrain Loss: 731.7346106569739\tTime: 0:00:05.303799\n",
      "Epoch: [564/1000]\tSamples: [146076/259000]\tTrain Loss: 728.2541781981479\tTime: 0:00:05.343822\n",
      "Epoch: [565/1000]\tSamples: [146335/259000]\tTrain Loss: 730.7261081533543\tTime: 0:00:05.557701\n",
      "Epoch: [566/1000]\tSamples: [146594/259000]\tTrain Loss: 726.7707802319619\tTime: 0:00:05.344848\n",
      "Epoch: [567/1000]\tSamples: [146853/259000]\tTrain Loss: 727.9873386221043\tTime: 0:00:05.526694\n",
      "Epoch: [568/1000]\tSamples: [147112/259000]\tTrain Loss: 726.8819763890565\tTime: 0:00:05.303997\n",
      "Epoch: [569/1000]\tSamples: [147371/259000]\tTrain Loss: 735.4619197182674\tTime: 0:00:05.281479\n",
      "Epoch: [570/1000]\tSamples: [147630/259000]\tTrain Loss: 724.7315056406853\tTime: 0:00:05.358759\n",
      "Epoch: [571/1000]\tSamples: [147889/259000]\tTrain Loss: 724.7568651589647\tTime: 0:00:05.237380\n",
      "Epoch: [572/1000]\tSamples: [148148/259000]\tTrain Loss: 726.121465145391\tTime: 0:00:05.373465\n",
      "Epoch: [573/1000]\tSamples: [148407/259000]\tTrain Loss: 732.832574203668\tTime: 0:00:05.580039\n",
      "Epoch: [574/1000]\tSamples: [148666/259000]\tTrain Loss: 724.8833290600869\tTime: 0:00:05.275016\n",
      "Epoch: [575/1000]\tSamples: [148925/259000]\tTrain Loss: 725.478036298715\tTime: 0:00:05.184734\n",
      "Epoch: [576/1000]\tSamples: [149184/259000]\tTrain Loss: 728.6469792546453\tTime: 0:00:05.530928\n",
      "Epoch: [577/1000]\tSamples: [149443/259000]\tTrain Loss: 728.1279155480815\tTime: 0:00:05.650403\n",
      "Epoch: [578/1000]\tSamples: [149702/259000]\tTrain Loss: 727.5466977859556\tTime: 0:00:05.304037\n",
      "Epoch: [579/1000]\tSamples: [149961/259000]\tTrain Loss: 723.4529685237693\tTime: 0:00:05.345197\n",
      "Epoch: [580/1000]\tSamples: [150220/259000]\tTrain Loss: 730.3055924227799\tTime: 0:00:05.530379\n",
      "Epoch: [581/1000]\tSamples: [150479/259000]\tTrain Loss: 727.0531340492278\tTime: 0:00:05.583403\n",
      "Epoch: [582/1000]\tSamples: [150738/259000]\tTrain Loss: 730.2340922116313\tTime: 0:00:05.359159\n",
      "Epoch: [583/1000]\tSamples: [150997/259000]\tTrain Loss: 733.8444381183639\tTime: 0:00:05.244777\n",
      "Epoch: [584/1000]\tSamples: [151256/259000]\tTrain Loss: 725.099021175193\tTime: 0:00:05.268803\n",
      "Epoch: [585/1000]\tSamples: [151515/259000]\tTrain Loss: 722.1383438404923\tTime: 0:00:05.286907\n",
      "Epoch: [586/1000]\tSamples: [151774/259000]\tTrain Loss: 724.2971521326014\tTime: 0:00:05.345343\n",
      "Epoch: [587/1000]\tSamples: [152033/259000]\tTrain Loss: 721.7188348365106\tTime: 0:00:05.302413\n",
      "Epoch: [588/1000]\tSamples: [152292/259000]\tTrain Loss: 728.5477629554778\tTime: 0:00:05.431686\n",
      "Epoch: [589/1000]\tSamples: [152551/259000]\tTrain Loss: 723.6719193035111\tTime: 0:00:05.207977\n",
      "Epoch: [590/1000]\tSamples: [152810/259000]\tTrain Loss: 729.5182982927123\tTime: 0:00:05.462415\n",
      "Epoch: [591/1000]\tSamples: [153069/259000]\tTrain Loss: 728.7251768369932\tTime: 0:00:05.266546\n",
      "Epoch: [592/1000]\tSamples: [153328/259000]\tTrain Loss: 723.2179958976834\tTime: 0:00:05.643821\n",
      "Epoch: [593/1000]\tSamples: [153587/259000]\tTrain Loss: 733.7878031491313\tTime: 0:00:05.635523\n",
      "Epoch: [594/1000]\tSamples: [153846/259000]\tTrain Loss: 727.2140406310328\tTime: 0:00:05.384558\n",
      "Epoch: [595/1000]\tSamples: [154105/259000]\tTrain Loss: 731.8260851532336\tTime: 0:00:05.361760\n",
      "Epoch: [596/1000]\tSamples: [154364/259000]\tTrain Loss: 732.0964034975266\tTime: 0:00:05.654354\n",
      "Epoch: [597/1000]\tSamples: [154623/259000]\tTrain Loss: 724.6963324233832\tTime: 0:00:05.132096\n",
      "Epoch: [598/1000]\tSamples: [154882/259000]\tTrain Loss: 729.873525729971\tTime: 0:00:05.402751\n",
      "Epoch: [599/1000]\tSamples: [155141/259000]\tTrain Loss: 731.2509049227799\tTime: 0:00:05.099818\n",
      "Epoch: [600/1000]\tSamples: [155400/259000]\tTrain Loss: 729.2350475650036\tTime: 0:00:05.326217\n",
      "Epoch: [601/1000]\tSamples: [155659/259000]\tTrain Loss: 733.6413404545729\tTime: 0:00:05.463503\n",
      "Epoch: [602/1000]\tSamples: [155918/259000]\tTrain Loss: 729.348741686022\tTime: 0:00:05.268868\n",
      "Epoch: [603/1000]\tSamples: [156177/259000]\tTrain Loss: 738.961553036016\tTime: 0:00:05.307494\n",
      "Epoch: [604/1000]\tSamples: [156436/259000]\tTrain Loss: 729.6389471223456\tTime: 0:00:05.115013\n",
      "Epoch: [605/1000]\tSamples: [156695/259000]\tTrain Loss: 732.0073110219595\tTime: 0:00:05.388085\n",
      "Epoch: [606/1000]\tSamples: [156954/259000]\tTrain Loss: 732.1931227753981\tTime: 0:00:05.160765\n",
      "Epoch: [607/1000]\tSamples: [157213/259000]\tTrain Loss: 726.224943065275\tTime: 0:00:05.362346\n",
      "Epoch: [608/1000]\tSamples: [157472/259000]\tTrain Loss: 725.7167195795125\tTime: 0:00:05.502073\n",
      "Epoch: [609/1000]\tSamples: [157731/259000]\tTrain Loss: 728.2681550132722\tTime: 0:00:05.364491\n",
      "Epoch: [610/1000]\tSamples: [157990/259000]\tTrain Loss: 724.2718972460183\tTime: 0:00:05.565501\n",
      "Epoch: [611/1000]\tSamples: [158249/259000]\tTrain Loss: 727.2269923383204\tTime: 0:00:05.221175\n",
      "Epoch: [612/1000]\tSamples: [158508/259000]\tTrain Loss: 723.9157205824687\tTime: 0:00:05.310230\n",
      "Epoch: [613/1000]\tSamples: [158767/259000]\tTrain Loss: 732.3430618816361\tTime: 0:00:05.332049\n",
      "Epoch: [614/1000]\tSamples: [159026/259000]\tTrain Loss: 727.6450775028655\tTime: 0:00:05.333024\n",
      "Epoch: [615/1000]\tSamples: [159285/259000]\tTrain Loss: 732.873273105695\tTime: 0:00:05.357307\n",
      "Epoch: [616/1000]\tSamples: [159544/259000]\tTrain Loss: 720.985632465613\tTime: 0:00:05.468195\n",
      "Epoch: [617/1000]\tSamples: [159803/259000]\tTrain Loss: 725.1795885240709\tTime: 0:00:05.324221\n",
      "Epoch: [618/1000]\tSamples: [160062/259000]\tTrain Loss: 724.098822280707\tTime: 0:00:05.319644\n",
      "Epoch: [619/1000]\tSamples: [160321/259000]\tTrain Loss: 725.36722331986\tTime: 0:00:05.309879\n",
      "Epoch: [620/1000]\tSamples: [160580/259000]\tTrain Loss: 723.9511143746984\tTime: 0:00:05.404360\n",
      "Epoch: [621/1000]\tSamples: [160839/259000]\tTrain Loss: 722.9532984435328\tTime: 0:00:05.565079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [622/1000]\tSamples: [161098/259000]\tTrain Loss: 728.7263230725144\tTime: 0:00:05.368607\n",
      "Epoch: [623/1000]\tSamples: [161357/259000]\tTrain Loss: 728.9892455583373\tTime: 0:00:05.373966\n",
      "Epoch: [624/1000]\tSamples: [161616/259000]\tTrain Loss: 725.0665344473938\tTime: 0:00:05.433064\n",
      "Epoch: [625/1000]\tSamples: [161875/259000]\tTrain Loss: 719.5263737858953\tTime: 0:00:05.289619\n",
      "Epoch: [626/1000]\tSamples: [162134/259000]\tTrain Loss: 722.3139332657155\tTime: 0:00:05.270239\n",
      "Epoch: [627/1000]\tSamples: [162393/259000]\tTrain Loss: 734.2395325885316\tTime: 0:00:05.504879\n",
      "Epoch: [628/1000]\tSamples: [162652/259000]\tTrain Loss: 728.8670932372104\tTime: 0:00:05.307357\n",
      "Epoch: [629/1000]\tSamples: [162911/259000]\tTrain Loss: 720.3016211314551\tTime: 0:00:05.358367\n",
      "Epoch: [630/1000]\tSamples: [163170/259000]\tTrain Loss: 724.3255440848214\tTime: 0:00:05.231309\n",
      "Epoch: [631/1000]\tSamples: [163429/259000]\tTrain Loss: 724.8172225657577\tTime: 0:00:05.299260\n",
      "Epoch: [632/1000]\tSamples: [163688/259000]\tTrain Loss: 726.2738909040179\tTime: 0:00:05.449134\n",
      "Epoch: [633/1000]\tSamples: [163947/259000]\tTrain Loss: 729.9893775262427\tTime: 0:00:05.315092\n",
      "Epoch: [634/1000]\tSamples: [164206/259000]\tTrain Loss: 725.0401125874758\tTime: 0:00:05.529384\n",
      "Epoch: [635/1000]\tSamples: [164465/259000]\tTrain Loss: 732.3033810177365\tTime: 0:00:05.356042\n",
      "Epoch: [636/1000]\tSamples: [164724/259000]\tTrain Loss: 727.3630757571187\tTime: 0:00:05.494609\n",
      "Epoch: [637/1000]\tSamples: [164983/259000]\tTrain Loss: 729.4041479397924\tTime: 0:00:05.300031\n",
      "Epoch: [638/1000]\tSamples: [165242/259000]\tTrain Loss: 734.9471525096525\tTime: 0:00:05.636551\n",
      "Epoch: [639/1000]\tSamples: [165501/259000]\tTrain Loss: 722.6622828185328\tTime: 0:00:05.550591\n",
      "Epoch: [640/1000]\tSamples: [165760/259000]\tTrain Loss: 734.071018528294\tTime: 0:00:05.243328\n",
      "Epoch: [641/1000]\tSamples: [166019/259000]\tTrain Loss: 728.0954900910956\tTime: 0:00:07.575726\n",
      "Epoch: [642/1000]\tSamples: [166278/259000]\tTrain Loss: 719.2381605936293\tTime: 0:00:05.507730\n",
      "Epoch: [643/1000]\tSamples: [166537/259000]\tTrain Loss: 729.276212596525\tTime: 0:00:05.296078\n",
      "Epoch: [644/1000]\tSamples: [166796/259000]\tTrain Loss: 737.2712147834218\tTime: 0:00:05.366699\n",
      "Epoch: [645/1000]\tSamples: [167055/259000]\tTrain Loss: 724.7641125535413\tTime: 0:00:05.385453\n",
      "Epoch: [646/1000]\tSamples: [167314/259000]\tTrain Loss: 726.6936883521356\tTime: 0:00:05.157029\n",
      "Epoch: [647/1000]\tSamples: [167573/259000]\tTrain Loss: 721.5840399900459\tTime: 0:00:05.383332\n",
      "Epoch: [648/1000]\tSamples: [167832/259000]\tTrain Loss: 725.172290698902\tTime: 0:00:04.964970\n",
      "Epoch: [649/1000]\tSamples: [168091/259000]\tTrain Loss: 727.8816596660835\tTime: 0:00:05.257389\n",
      "Epoch: [650/1000]\tSamples: [168350/259000]\tTrain Loss: 722.7652338094233\tTime: 0:00:06.072545\n",
      "Epoch: [651/1000]\tSamples: [168609/259000]\tTrain Loss: 727.815104009562\tTime: 0:00:05.441319\n",
      "Epoch: [652/1000]\tSamples: [168868/259000]\tTrain Loss: 718.6053443231177\tTime: 0:00:05.426846\n",
      "Epoch: [653/1000]\tSamples: [169127/259000]\tTrain Loss: 729.7253333132239\tTime: 0:00:05.289940\n",
      "Epoch: [654/1000]\tSamples: [169386/259000]\tTrain Loss: 722.4729107595318\tTime: 0:00:05.304344\n",
      "Epoch: [655/1000]\tSamples: [169645/259000]\tTrain Loss: 720.2821398407336\tTime: 0:00:04.968808\n",
      "Epoch: [656/1000]\tSamples: [169904/259000]\tTrain Loss: 724.274205741735\tTime: 0:00:05.265589\n",
      "Epoch: [657/1000]\tSamples: [170163/259000]\tTrain Loss: 719.5641166068413\tTime: 0:00:05.127977\n",
      "Epoch: [658/1000]\tSamples: [170422/259000]\tTrain Loss: 730.6074812605574\tTime: 0:00:05.445710\n",
      "Epoch: [659/1000]\tSamples: [170681/259000]\tTrain Loss: 723.368471359194\tTime: 0:00:05.530983\n",
      "Epoch: [660/1000]\tSamples: [170940/259000]\tTrain Loss: 729.4127842965734\tTime: 0:00:05.536190\n",
      "Epoch: [661/1000]\tSamples: [171199/259000]\tTrain Loss: 725.7374460816843\tTime: 0:00:05.538121\n",
      "Epoch: [662/1000]\tSamples: [171458/259000]\tTrain Loss: 724.3937154055562\tTime: 0:00:05.407512\n",
      "Epoch: [663/1000]\tSamples: [171717/259000]\tTrain Loss: 722.4706380836752\tTime: 0:00:06.002296\n",
      "Epoch: [664/1000]\tSamples: [171976/259000]\tTrain Loss: 723.2957749532457\tTime: 0:00:04.807755\n",
      "Epoch: [665/1000]\tSamples: [172235/259000]\tTrain Loss: 721.8317126417712\tTime: 0:00:05.382007\n",
      "Epoch: [666/1000]\tSamples: [172494/259000]\tTrain Loss: 727.7680532094595\tTime: 0:00:05.407912\n",
      "Epoch: [667/1000]\tSamples: [172753/259000]\tTrain Loss: 728.75242349632\tTime: 0:00:05.491091\n",
      "Epoch: [668/1000]\tSamples: [173012/259000]\tTrain Loss: 722.168701171875\tTime: 0:00:05.312201\n",
      "Epoch: [669/1000]\tSamples: [173271/259000]\tTrain Loss: 724.7883970047056\tTime: 0:00:05.407666\n",
      "Epoch: [670/1000]\tSamples: [173530/259000]\tTrain Loss: 724.2730811866554\tTime: 0:00:05.613695\n",
      "Epoch: [671/1000]\tSamples: [173789/259000]\tTrain Loss: 717.1893550916989\tTime: 0:00:05.154922\n",
      "Epoch: [672/1000]\tSamples: [174048/259000]\tTrain Loss: 726.2169062198359\tTime: 0:00:05.270990\n",
      "Epoch: [673/1000]\tSamples: [174307/259000]\tTrain Loss: 721.6975031672297\tTime: 0:00:05.431719\n",
      "Epoch: [674/1000]\tSamples: [174566/259000]\tTrain Loss: 734.1544585356842\tTime: 0:00:05.215201\n",
      "Epoch: [675/1000]\tSamples: [174825/259000]\tTrain Loss: 719.5814402223093\tTime: 0:00:05.283693\n",
      "Epoch: [676/1000]\tSamples: [175084/259000]\tTrain Loss: 718.6662286589044\tTime: 0:00:05.395371\n",
      "Epoch: [677/1000]\tSamples: [175343/259000]\tTrain Loss: 724.4043703999758\tTime: 0:00:05.487234\n",
      "Epoch: [678/1000]\tSamples: [175602/259000]\tTrain Loss: 723.9910148708976\tTime: 0:00:05.284122\n",
      "Epoch: [679/1000]\tSamples: [175861/259000]\tTrain Loss: 724.4549122224903\tTime: 0:00:05.264011\n",
      "Epoch: [680/1000]\tSamples: [176120/259000]\tTrain Loss: 723.4615388965975\tTime: 0:00:05.098987\n",
      "Epoch: [681/1000]\tSamples: [176379/259000]\tTrain Loss: 727.1312232293677\tTime: 0:00:05.293136\n",
      "Epoch: [682/1000]\tSamples: [176638/259000]\tTrain Loss: 730.2830409930019\tTime: 0:00:05.293518\n",
      "Epoch: [683/1000]\tSamples: [176897/259000]\tTrain Loss: 727.0855406536559\tTime: 0:00:05.175839\n",
      "Epoch: [684/1000]\tSamples: [177156/259000]\tTrain Loss: 720.7258706111245\tTime: 0:00:05.067775\n",
      "Epoch: [685/1000]\tSamples: [177415/259000]\tTrain Loss: 727.2574382767253\tTime: 0:00:07.116998\n",
      "Epoch: [686/1000]\tSamples: [177674/259000]\tTrain Loss: 723.9243918164817\tTime: 0:00:06.015013\n",
      "Epoch: [687/1000]\tSamples: [177933/259000]\tTrain Loss: 716.5520330598456\tTime: 0:00:04.625548\n",
      "Epoch: [688/1000]\tSamples: [178192/259000]\tTrain Loss: 723.3607239005188\tTime: 0:00:05.520182\n",
      "Epoch: [689/1000]\tSamples: [178451/259000]\tTrain Loss: 738.775581035835\tTime: 0:00:04.921615\n",
      "Epoch: [690/1000]\tSamples: [178710/259000]\tTrain Loss: 726.4209314294764\tTime: 0:00:07.173206\n",
      "Epoch: [691/1000]\tSamples: [178969/259000]\tTrain Loss: 719.6407117217664\tTime: 0:00:07.842545\n",
      "Epoch: [692/1000]\tSamples: [179228/259000]\tTrain Loss: 724.6128721494932\tTime: 0:00:09.422769\n",
      "Epoch: [693/1000]\tSamples: [179487/259000]\tTrain Loss: 726.6308405224421\tTime: 0:00:07.265774\n",
      "Epoch: [694/1000]\tSamples: [179746/259000]\tTrain Loss: 720.320393565999\tTime: 0:00:05.473757\n",
      "Epoch: [695/1000]\tSamples: [180005/259000]\tTrain Loss: 721.9570067416747\tTime: 0:00:04.768828\n",
      "Epoch: [696/1000]\tSamples: [180264/259000]\tTrain Loss: 722.5279903927365\tTime: 0:00:05.167163\n",
      "Epoch: [697/1000]\tSamples: [180523/259000]\tTrain Loss: 722.7233990407818\tTime: 0:00:04.810164\n",
      "Epoch: [698/1000]\tSamples: [180782/259000]\tTrain Loss: 722.9701733681226\tTime: 0:00:05.252601\n",
      "Epoch: [699/1000]\tSamples: [181041/259000]\tTrain Loss: 718.8644058050796\tTime: 0:00:05.410792\n",
      "Epoch: [700/1000]\tSamples: [181300/259000]\tTrain Loss: 724.6788532743122\tTime: 0:00:05.242185\n",
      "Epoch: [701/1000]\tSamples: [181559/259000]\tTrain Loss: 723.1057543662524\tTime: 0:00:05.599512\n",
      "Epoch: [702/1000]\tSamples: [181818/259000]\tTrain Loss: 732.2139765323359\tTime: 0:00:05.489031\n",
      "Epoch: [703/1000]\tSamples: [182077/259000]\tTrain Loss: 728.4618179144546\tTime: 0:00:05.467166\n",
      "Epoch: [704/1000]\tSamples: [182336/259000]\tTrain Loss: 729.1338361938948\tTime: 0:00:05.133869\n",
      "Epoch: [705/1000]\tSamples: [182595/259000]\tTrain Loss: 731.0907496154078\tTime: 0:00:05.217504\n",
      "Epoch: [706/1000]\tSamples: [182854/259000]\tTrain Loss: 732.1985480702522\tTime: 0:00:05.189642\n",
      "Epoch: [707/1000]\tSamples: [183113/259000]\tTrain Loss: 720.3907324595801\tTime: 0:00:05.519049\n",
      "Epoch: [708/1000]\tSamples: [183372/259000]\tTrain Loss: 725.0094790661196\tTime: 0:00:05.266578\n",
      "Epoch: [709/1000]\tSamples: [183631/259000]\tTrain Loss: 722.4259594066723\tTime: 0:00:05.291334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [710/1000]\tSamples: [183890/259000]\tTrain Loss: 729.572455093207\tTime: 0:00:05.386126\n",
      "Epoch: [711/1000]\tSamples: [184149/259000]\tTrain Loss: 721.452229974813\tTime: 0:00:05.658437\n",
      "Epoch: [712/1000]\tSamples: [184408/259000]\tTrain Loss: 721.4583584700772\tTime: 0:00:05.250595\n",
      "Epoch: [713/1000]\tSamples: [184667/259000]\tTrain Loss: 714.6997626462959\tTime: 0:00:05.302958\n",
      "Epoch: [714/1000]\tSamples: [184926/259000]\tTrain Loss: 725.7844219428692\tTime: 0:00:05.306774\n",
      "Epoch: [715/1000]\tSamples: [185185/259000]\tTrain Loss: 727.6408851652992\tTime: 0:00:05.406651\n",
      "Epoch: [716/1000]\tSamples: [185444/259000]\tTrain Loss: 727.1248953683036\tTime: 0:00:05.323119\n",
      "Epoch: [717/1000]\tSamples: [185703/259000]\tTrain Loss: 726.480748710485\tTime: 0:00:05.165044\n",
      "Epoch: [718/1000]\tSamples: [185962/259000]\tTrain Loss: 734.4175728462837\tTime: 0:00:05.345925\n",
      "Epoch: [719/1000]\tSamples: [186221/259000]\tTrain Loss: 722.4680378446247\tTime: 0:00:05.617500\n",
      "Epoch: [720/1000]\tSamples: [186480/259000]\tTrain Loss: 724.8663570448239\tTime: 0:00:05.340575\n",
      "Epoch: [721/1000]\tSamples: [186739/259000]\tTrain Loss: 720.1448253499035\tTime: 0:00:05.852332\n",
      "Epoch: [722/1000]\tSamples: [186998/259000]\tTrain Loss: 720.558982112693\tTime: 0:00:05.547770\n",
      "Epoch: [723/1000]\tSamples: [187257/259000]\tTrain Loss: 729.79106935479\tTime: 0:00:05.375477\n",
      "Epoch: [724/1000]\tSamples: [187516/259000]\tTrain Loss: 724.5692576993847\tTime: 0:00:04.957960\n",
      "Epoch: [725/1000]\tSamples: [187775/259000]\tTrain Loss: 722.6667942356419\tTime: 0:00:05.269099\n",
      "Epoch: [726/1000]\tSamples: [188034/259000]\tTrain Loss: 722.2641516725989\tTime: 0:00:05.507308\n",
      "Epoch: [727/1000]\tSamples: [188293/259000]\tTrain Loss: 722.8849437816723\tTime: 0:00:05.070010\n",
      "Epoch: [728/1000]\tSamples: [188552/259000]\tTrain Loss: 728.640570327582\tTime: 0:00:05.603595\n",
      "Epoch: [729/1000]\tSamples: [188811/259000]\tTrain Loss: 719.1978590092604\tTime: 0:00:05.470636\n",
      "Epoch: [730/1000]\tSamples: [189070/259000]\tTrain Loss: 728.0531067130188\tTime: 0:00:05.349114\n",
      "Epoch: [731/1000]\tSamples: [189329/259000]\tTrain Loss: 723.4098018219112\tTime: 0:00:10.134265\n",
      "Epoch: [732/1000]\tSamples: [189588/259000]\tTrain Loss: 717.173041973335\tTime: 0:00:05.320984\n",
      "Epoch: [733/1000]\tSamples: [189847/259000]\tTrain Loss: 731.5515805984556\tTime: 0:00:05.440932\n",
      "Epoch: [734/1000]\tSamples: [190106/259000]\tTrain Loss: 729.212411770029\tTime: 0:00:05.260873\n",
      "Epoch: [735/1000]\tSamples: [190365/259000]\tTrain Loss: 726.2503261492519\tTime: 0:00:05.490304\n",
      "Epoch: [736/1000]\tSamples: [190624/259000]\tTrain Loss: 721.912977535292\tTime: 0:00:05.377298\n",
      "Epoch: [737/1000]\tSamples: [190883/259000]\tTrain Loss: 727.3778231705478\tTime: 0:00:05.517758\n",
      "Epoch: [738/1000]\tSamples: [191142/259000]\tTrain Loss: 719.3592175811414\tTime: 0:00:05.504272\n",
      "Epoch: [739/1000]\tSamples: [191401/259000]\tTrain Loss: 722.632432149644\tTime: 0:00:05.471721\n",
      "Epoch: [740/1000]\tSamples: [191660/259000]\tTrain Loss: 724.5582393219112\tTime: 0:00:05.379698\n",
      "Epoch: [741/1000]\tSamples: [191919/259000]\tTrain Loss: 725.3132710696187\tTime: 0:00:05.233275\n",
      "Epoch: [742/1000]\tSamples: [192178/259000]\tTrain Loss: 728.1529508023649\tTime: 0:00:05.123941\n",
      "Epoch: [743/1000]\tSamples: [192437/259000]\tTrain Loss: 728.0389399583736\tTime: 0:00:05.469295\n",
      "Epoch: [744/1000]\tSamples: [192696/259000]\tTrain Loss: 718.3644962973576\tTime: 0:00:05.661314\n",
      "Epoch: [745/1000]\tSamples: [192955/259000]\tTrain Loss: 732.474429333072\tTime: 0:00:05.438453\n",
      "Epoch: [746/1000]\tSamples: [193214/259000]\tTrain Loss: 719.4512303179296\tTime: 0:00:05.464884\n",
      "Epoch: [747/1000]\tSamples: [193473/259000]\tTrain Loss: 715.6565921739261\tTime: 0:00:05.004210\n",
      "Epoch: [748/1000]\tSamples: [193732/259000]\tTrain Loss: 723.7365760361366\tTime: 0:00:05.449956\n",
      "Epoch: [749/1000]\tSamples: [193991/259000]\tTrain Loss: 723.9402769817809\tTime: 0:00:05.570385\n",
      "Epoch: [750/1000]\tSamples: [194250/259000]\tTrain Loss: 721.7860885089889\tTime: 0:00:05.447719\n",
      "Epoch: [751/1000]\tSamples: [194509/259000]\tTrain Loss: 723.7204193940033\tTime: 0:00:08.242558\n",
      "Epoch: [752/1000]\tSamples: [194768/259000]\tTrain Loss: 718.9421155774916\tTime: 0:00:05.551865\n",
      "Epoch: [753/1000]\tSamples: [195027/259000]\tTrain Loss: 720.3403999004585\tTime: 0:00:05.270790\n",
      "Epoch: [754/1000]\tSamples: [195286/259000]\tTrain Loss: 725.1172633815456\tTime: 0:00:07.776462\n",
      "Epoch: [755/1000]\tSamples: [195545/259000]\tTrain Loss: 721.0888784990348\tTime: 0:00:05.030067\n",
      "Epoch: [756/1000]\tSamples: [195804/259000]\tTrain Loss: 726.3966427364865\tTime: 0:00:05.269869\n",
      "Epoch: [757/1000]\tSamples: [196063/259000]\tTrain Loss: 716.9656355574324\tTime: 0:00:05.107855\n",
      "Epoch: [758/1000]\tSamples: [196322/259000]\tTrain Loss: 726.6294595725748\tTime: 0:00:05.281811\n",
      "Epoch: [759/1000]\tSamples: [196581/259000]\tTrain Loss: 719.9209554664877\tTime: 0:00:05.069383\n",
      "Epoch: [760/1000]\tSamples: [196840/259000]\tTrain Loss: 723.001772140444\tTime: 0:00:05.696835\n",
      "Epoch: [761/1000]\tSamples: [197099/259000]\tTrain Loss: 725.9857512367278\tTime: 0:00:05.395585\n",
      "Epoch: [762/1000]\tSamples: [197358/259000]\tTrain Loss: 722.5878284115589\tTime: 0:00:05.564889\n",
      "Epoch: [763/1000]\tSamples: [197617/259000]\tTrain Loss: 729.3355001206563\tTime: 0:00:05.497135\n",
      "Epoch: [764/1000]\tSamples: [197876/259000]\tTrain Loss: 719.562038112331\tTime: 0:00:05.187817\n",
      "Epoch: [765/1000]\tSamples: [198135/259000]\tTrain Loss: 725.813376643943\tTime: 0:00:07.000486\n",
      "Epoch: [766/1000]\tSamples: [198394/259000]\tTrain Loss: 715.3530122617036\tTime: 0:00:07.548924\n",
      "Epoch: [767/1000]\tSamples: [198653/259000]\tTrain Loss: 726.799958335847\tTime: 0:00:05.477879\n",
      "Epoch: [768/1000]\tSamples: [198912/259000]\tTrain Loss: 729.1425649282095\tTime: 0:00:05.509466\n",
      "Epoch: [769/1000]\tSamples: [199171/259000]\tTrain Loss: 720.5122503921332\tTime: 0:00:07.815154\n",
      "Epoch: [770/1000]\tSamples: [199430/259000]\tTrain Loss: 726.9003793134652\tTime: 0:00:07.689651\n",
      "Epoch: [771/1000]\tSamples: [199689/259000]\tTrain Loss: 722.9414185041627\tTime: 0:00:05.449578\n",
      "Epoch: [772/1000]\tSamples: [199948/259000]\tTrain Loss: 714.4901825304657\tTime: 0:00:04.714470\n",
      "Epoch: [773/1000]\tSamples: [200207/259000]\tTrain Loss: 721.3948602271356\tTime: 0:00:05.284082\n",
      "Epoch: [774/1000]\tSamples: [200466/259000]\tTrain Loss: 715.6757774794884\tTime: 0:00:04.792926\n",
      "Epoch: [775/1000]\tSamples: [200725/259000]\tTrain Loss: 720.2573930305864\tTime: 0:00:05.303431\n",
      "Epoch: [776/1000]\tSamples: [200984/259000]\tTrain Loss: 730.3566677726834\tTime: 0:00:08.361563\n",
      "Epoch: [777/1000]\tSamples: [201243/259000]\tTrain Loss: 721.7652375799348\tTime: 0:00:07.185338\n",
      "Epoch: [778/1000]\tSamples: [201502/259000]\tTrain Loss: 724.8730280224421\tTime: 0:00:05.252345\n",
      "Epoch: [779/1000]\tSamples: [201761/259000]\tTrain Loss: 724.5181682100628\tTime: 0:00:04.811328\n",
      "Epoch: [780/1000]\tSamples: [202020/259000]\tTrain Loss: 717.5149406521476\tTime: 0:00:13.326913\n",
      "Epoch: [781/1000]\tSamples: [202279/259000]\tTrain Loss: 721.7898717460484\tTime: 0:00:05.221062\n",
      "Epoch: [782/1000]\tSamples: [202538/259000]\tTrain Loss: 726.4113929777992\tTime: 0:00:08.873012\n",
      "Epoch: [783/1000]\tSamples: [202797/259000]\tTrain Loss: 717.8361467633929\tTime: 0:00:10.265864\n",
      "Epoch: [784/1000]\tSamples: [203056/259000]\tTrain Loss: 724.2886892193533\tTime: 0:00:07.632929\n",
      "Epoch: [785/1000]\tSamples: [203315/259000]\tTrain Loss: 725.406991848154\tTime: 0:00:08.680325\n",
      "Epoch: [786/1000]\tSamples: [203574/259000]\tTrain Loss: 720.9078380923473\tTime: 0:00:09.879782\n",
      "Epoch: [787/1000]\tSamples: [203833/259000]\tTrain Loss: 720.5630561504585\tTime: 0:00:08.875520\n",
      "Epoch: [788/1000]\tSamples: [204092/259000]\tTrain Loss: 722.73193359375\tTime: 0:00:08.509628\n",
      "Epoch: [789/1000]\tSamples: [204351/259000]\tTrain Loss: 724.282037094293\tTime: 0:00:05.364912\n",
      "Epoch: [790/1000]\tSamples: [204610/259000]\tTrain Loss: 719.2641535578547\tTime: 0:00:05.791272\n",
      "Epoch: [791/1000]\tSamples: [204869/259000]\tTrain Loss: 720.5251238613055\tTime: 0:00:05.129311\n",
      "Epoch: [792/1000]\tSamples: [205128/259000]\tTrain Loss: 717.9278300517315\tTime: 0:00:09.737080\n",
      "Epoch: [793/1000]\tSamples: [205387/259000]\tTrain Loss: 714.8352126191481\tTime: 0:00:07.568283\n",
      "Epoch: [794/1000]\tSamples: [205646/259000]\tTrain Loss: 720.8688814023286\tTime: 0:00:05.262247\n",
      "Epoch: [795/1000]\tSamples: [205905/259000]\tTrain Loss: 725.8264876553451\tTime: 0:00:04.972196\n",
      "Epoch: [796/1000]\tSamples: [206164/259000]\tTrain Loss: 728.261167312681\tTime: 0:00:04.911021\n",
      "Epoch: [797/1000]\tSamples: [206423/259000]\tTrain Loss: 725.6261443502655\tTime: 0:00:05.034941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [798/1000]\tSamples: [206682/259000]\tTrain Loss: 725.5025215296212\tTime: 0:00:04.790859\n",
      "Epoch: [799/1000]\tSamples: [206941/259000]\tTrain Loss: 726.2183126206563\tTime: 0:00:04.936615\n",
      "Epoch: [800/1000]\tSamples: [207200/259000]\tTrain Loss: 721.6780826760075\tTime: 0:00:05.290313\n",
      "Epoch: [801/1000]\tSamples: [207459/259000]\tTrain Loss: 718.3060024659146\tTime: 0:00:07.629044\n",
      "Epoch: [802/1000]\tSamples: [207718/259000]\tTrain Loss: 715.7501828698117\tTime: 0:00:07.155111\n",
      "Epoch: [803/1000]\tSamples: [207977/259000]\tTrain Loss: 720.8638194905285\tTime: 0:00:09.783854\n",
      "Epoch: [804/1000]\tSamples: [208236/259000]\tTrain Loss: 717.4467028761462\tTime: 0:00:04.986994\n",
      "Epoch: [805/1000]\tSamples: [208495/259000]\tTrain Loss: 714.7444724300193\tTime: 0:00:04.993695\n",
      "Epoch: [806/1000]\tSamples: [208754/259000]\tTrain Loss: 726.369474315275\tTime: 0:00:04.954935\n",
      "Epoch: [807/1000]\tSamples: [209013/259000]\tTrain Loss: 729.0889793602196\tTime: 0:00:04.695680\n",
      "Epoch: [808/1000]\tSamples: [209272/259000]\tTrain Loss: 727.016483734013\tTime: 0:00:05.142136\n",
      "Epoch: [809/1000]\tSamples: [209531/259000]\tTrain Loss: 728.0177996425555\tTime: 0:00:04.946479\n",
      "Epoch: [810/1000]\tSamples: [209790/259000]\tTrain Loss: 722.1813474677244\tTime: 0:00:06.552492\n",
      "Epoch: [811/1000]\tSamples: [210049/259000]\tTrain Loss: 719.5467863929778\tTime: 0:00:04.967124\n",
      "Epoch: [812/1000]\tSamples: [210308/259000]\tTrain Loss: 723.4840884411196\tTime: 0:00:07.465707\n",
      "Epoch: [813/1000]\tSamples: [210567/259000]\tTrain Loss: 721.8914059672117\tTime: 0:00:09.914390\n",
      "Epoch: [814/1000]\tSamples: [210826/259000]\tTrain Loss: 723.7496172930744\tTime: 0:00:04.854713\n",
      "Epoch: [815/1000]\tSamples: [211085/259000]\tTrain Loss: 722.5069075772201\tTime: 0:00:05.016760\n",
      "Epoch: [816/1000]\tSamples: [211344/259000]\tTrain Loss: 721.6412509049228\tTime: 0:00:04.915639\n",
      "Epoch: [817/1000]\tSamples: [211603/259000]\tTrain Loss: 720.4462777509652\tTime: 0:00:04.855998\n",
      "Epoch: [818/1000]\tSamples: [211862/259000]\tTrain Loss: 725.812689939521\tTime: 0:00:04.894811\n",
      "Epoch: [819/1000]\tSamples: [212121/259000]\tTrain Loss: 721.9958562077703\tTime: 0:00:05.095266\n",
      "Epoch: [820/1000]\tSamples: [212380/259000]\tTrain Loss: 718.5928620445222\tTime: 0:00:06.206059\n",
      "Epoch: [821/1000]\tSamples: [212639/259000]\tTrain Loss: 725.154450523347\tTime: 0:00:05.199230\n",
      "Epoch: [822/1000]\tSamples: [212898/259000]\tTrain Loss: 720.0040928903234\tTime: 0:00:07.766258\n",
      "Epoch: [823/1000]\tSamples: [213157/259000]\tTrain Loss: 721.8872871546212\tTime: 0:00:08.196267\n",
      "Epoch: [824/1000]\tSamples: [213416/259000]\tTrain Loss: 725.9763834006998\tTime: 0:00:04.911545\n",
      "Epoch: [825/1000]\tSamples: [213675/259000]\tTrain Loss: 715.2971200832529\tTime: 0:00:05.227102\n",
      "Epoch: [826/1000]\tSamples: [213934/259000]\tTrain Loss: 719.9337728493002\tTime: 0:00:04.963477\n",
      "Epoch: [827/1000]\tSamples: [214193/259000]\tTrain Loss: 721.453739593388\tTime: 0:00:04.916402\n",
      "Epoch: [828/1000]\tSamples: [214452/259000]\tTrain Loss: 716.6950829701074\tTime: 0:00:05.228626\n",
      "Epoch: [829/1000]\tSamples: [214711/259000]\tTrain Loss: 721.6336787750362\tTime: 0:00:05.094599\n",
      "Epoch: [830/1000]\tSamples: [214970/259000]\tTrain Loss: 721.6606228508084\tTime: 0:00:06.489442\n",
      "Epoch: [831/1000]\tSamples: [215229/259000]\tTrain Loss: 721.1146730400881\tTime: 0:00:05.446954\n",
      "Epoch: [832/1000]\tSamples: [215488/259000]\tTrain Loss: 723.3572352346766\tTime: 0:00:08.115848\n",
      "Epoch: [833/1000]\tSamples: [215747/259000]\tTrain Loss: 722.7613614940275\tTime: 0:00:06.769789\n",
      "Epoch: [834/1000]\tSamples: [216006/259000]\tTrain Loss: 721.480541332348\tTime: 0:00:04.912732\n",
      "Epoch: [835/1000]\tSamples: [216265/259000]\tTrain Loss: 723.5367304385859\tTime: 0:00:05.077481\n",
      "Epoch: [836/1000]\tSamples: [216524/259000]\tTrain Loss: 722.9881709625362\tTime: 0:00:04.828786\n",
      "Epoch: [837/1000]\tSamples: [216783/259000]\tTrain Loss: 716.7548601894305\tTime: 0:00:05.159772\n",
      "Epoch: [838/1000]\tSamples: [217042/259000]\tTrain Loss: 723.4203526559484\tTime: 0:00:05.109636\n",
      "Epoch: [839/1000]\tSamples: [217301/259000]\tTrain Loss: 723.297055984556\tTime: 0:00:04.864229\n",
      "Epoch: [840/1000]\tSamples: [217560/259000]\tTrain Loss: 721.9003793134652\tTime: 0:00:04.912609\n",
      "Epoch: [841/1000]\tSamples: [217819/259000]\tTrain Loss: 721.8181774478161\tTime: 0:00:06.532725\n",
      "Epoch: [842/1000]\tSamples: [218078/259000]\tTrain Loss: 720.0999854835304\tTime: 0:00:05.124831\n",
      "Epoch: [843/1000]\tSamples: [218337/259000]\tTrain Loss: 715.1054696926279\tTime: 0:00:07.239971\n",
      "Epoch: [844/1000]\tSamples: [218596/259000]\tTrain Loss: 718.3414235943533\tTime: 0:00:08.048565\n",
      "Epoch: [845/1000]\tSamples: [218855/259000]\tTrain Loss: 720.311812824264\tTime: 0:00:14.243492\n",
      "Epoch: [846/1000]\tSamples: [219114/259000]\tTrain Loss: 718.3098606418919\tTime: 0:00:04.522535\n",
      "Epoch: [847/1000]\tSamples: [219373/259000]\tTrain Loss: 723.726418277932\tTime: 0:00:04.751029\n",
      "Epoch: [848/1000]\tSamples: [219632/259000]\tTrain Loss: 725.0434853100869\tTime: 0:00:04.929521\n",
      "Epoch: [849/1000]\tSamples: [219891/259000]\tTrain Loss: 719.0508792833011\tTime: 0:00:05.217089\n",
      "Epoch: [850/1000]\tSamples: [220150/259000]\tTrain Loss: 723.6754796090734\tTime: 0:00:06.917198\n",
      "Epoch: [851/1000]\tSamples: [220409/259000]\tTrain Loss: 719.9284828215492\tTime: 0:00:04.989380\n",
      "Epoch: [852/1000]\tSamples: [220668/259000]\tTrain Loss: 716.1395112851411\tTime: 0:00:10.609044\n",
      "Epoch: [853/1000]\tSamples: [220927/259000]\tTrain Loss: 722.8558877480997\tTime: 0:00:11.672939\n",
      "Epoch: [854/1000]\tSamples: [221186/259000]\tTrain Loss: 723.567499698359\tTime: 0:00:05.026535\n",
      "Epoch: [855/1000]\tSamples: [221445/259000]\tTrain Loss: 729.3453270164696\tTime: 0:00:04.597723\n",
      "Epoch: [856/1000]\tSamples: [221704/259000]\tTrain Loss: 728.0990635934484\tTime: 0:00:04.987352\n",
      "Epoch: [857/1000]\tSamples: [221963/259000]\tTrain Loss: 720.141320659387\tTime: 0:00:05.071254\n",
      "Epoch: [858/1000]\tSamples: [222222/259000]\tTrain Loss: 721.7073319482987\tTime: 0:00:05.155201\n",
      "Epoch: [859/1000]\tSamples: [222481/259000]\tTrain Loss: 727.7337047915661\tTime: 0:00:05.115069\n",
      "Epoch: [860/1000]\tSamples: [222740/259000]\tTrain Loss: 723.8559108424831\tTime: 0:00:05.758835\n",
      "Epoch: [861/1000]\tSamples: [222999/259000]\tTrain Loss: 727.5305090944739\tTime: 0:00:04.973491\n",
      "Epoch: [862/1000]\tSamples: [223258/259000]\tTrain Loss: 716.053972988055\tTime: 0:00:07.672686\n",
      "Epoch: [863/1000]\tSamples: [223517/259000]\tTrain Loss: 722.3697033738538\tTime: 0:00:06.782602\n",
      "Epoch: [864/1000]\tSamples: [223776/259000]\tTrain Loss: 721.0420666551038\tTime: 0:00:05.108619\n",
      "Epoch: [865/1000]\tSamples: [224035/259000]\tTrain Loss: 715.7504741418315\tTime: 0:00:05.114145\n",
      "Epoch: [866/1000]\tSamples: [224294/259000]\tTrain Loss: 719.9235764433519\tTime: 0:00:05.063446\n",
      "Epoch: [867/1000]\tSamples: [224553/259000]\tTrain Loss: 716.9994457347973\tTime: 0:00:04.928965\n",
      "Epoch: [868/1000]\tSamples: [224812/259000]\tTrain Loss: 721.3232007118726\tTime: 0:00:04.965892\n",
      "Epoch: [869/1000]\tSamples: [225071/259000]\tTrain Loss: 725.6659826330236\tTime: 0:00:05.155392\n",
      "Epoch: [870/1000]\tSamples: [225330/259000]\tTrain Loss: 723.5016627956081\tTime: 0:00:05.167725\n",
      "Epoch: [871/1000]\tSamples: [225589/259000]\tTrain Loss: 714.3897247903595\tTime: 0:00:05.598821\n",
      "Epoch: [872/1000]\tSamples: [225848/259000]\tTrain Loss: 729.067255557734\tTime: 0:00:04.993797\n",
      "Epoch: [873/1000]\tSamples: [226107/259000]\tTrain Loss: 725.2575070885617\tTime: 0:00:07.737427\n",
      "Epoch: [874/1000]\tSamples: [226366/259000]\tTrain Loss: 724.1835833810932\tTime: 0:00:10.031624\n",
      "Epoch: [875/1000]\tSamples: [226625/259000]\tTrain Loss: 717.8500194181347\tTime: 0:00:09.239586\n",
      "Epoch: [876/1000]\tSamples: [226884/259000]\tTrain Loss: 723.314915012669\tTime: 0:00:04.909688\n",
      "Epoch: [877/1000]\tSamples: [227143/259000]\tTrain Loss: 718.483190116735\tTime: 0:00:06.370995\n",
      "Epoch: [878/1000]\tSamples: [227402/259000]\tTrain Loss: 720.6323751206563\tTime: 0:00:04.942468\n",
      "Epoch: [879/1000]\tSamples: [227661/259000]\tTrain Loss: 722.4640180079633\tTime: 0:00:07.973415\n",
      "Epoch: [880/1000]\tSamples: [227920/259000]\tTrain Loss: 715.1665604639237\tTime: 0:00:09.802309\n",
      "Epoch: [881/1000]\tSamples: [228179/259000]\tTrain Loss: 727.892080417471\tTime: 0:00:05.020099\n",
      "Epoch: [882/1000]\tSamples: [228438/259000]\tTrain Loss: 717.1687888362693\tTime: 0:00:05.143852\n",
      "Epoch: [883/1000]\tSamples: [228697/259000]\tTrain Loss: 728.9876619434725\tTime: 0:00:04.700319\n",
      "Epoch: [884/1000]\tSamples: [228956/259000]\tTrain Loss: 718.9609954716155\tTime: 0:00:05.708448\n",
      "Epoch: [885/1000]\tSamples: [229215/259000]\tTrain Loss: 717.2594423036318\tTime: 0:00:05.049973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [886/1000]\tSamples: [229474/259000]\tTrain Loss: 721.8482114578306\tTime: 0:00:08.318350\n",
      "Epoch: [887/1000]\tSamples: [229733/259000]\tTrain Loss: 722.8644831005671\tTime: 0:00:11.989679\n",
      "Epoch: [888/1000]\tSamples: [229992/259000]\tTrain Loss: 729.2783862964527\tTime: 0:00:10.074340\n",
      "Epoch: [889/1000]\tSamples: [230251/259000]\tTrain Loss: 714.7746073012187\tTime: 0:00:05.200138\n",
      "Epoch: [890/1000]\tSamples: [230510/259000]\tTrain Loss: 720.4403674740589\tTime: 0:00:04.926407\n",
      "Epoch: [891/1000]\tSamples: [230769/259000]\tTrain Loss: 724.7265756967905\tTime: 0:00:04.890239\n",
      "Epoch: [892/1000]\tSamples: [231028/259000]\tTrain Loss: 724.466191707891\tTime: 0:00:04.837686\n",
      "Epoch: [893/1000]\tSamples: [231287/259000]\tTrain Loss: 724.2206098048383\tTime: 0:00:06.065225\n",
      "Epoch: [894/1000]\tSamples: [231546/259000]\tTrain Loss: 721.2141396069619\tTime: 0:00:05.084499\n",
      "Epoch: [895/1000]\tSamples: [231805/259000]\tTrain Loss: 719.0246704572877\tTime: 0:00:07.616690\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 32095) is killed by signal: Terminated. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-24639aeca856>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mctm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_input_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"combined\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mctm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_dataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# run the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3_1/envs/rajeev3/lib/python3.7/site-packages/contextualized_topic_models/models/ctm.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_dataset, save_dir, verbose)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;31m# train epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0msp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m             \u001b[0msamples_processed\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3_1/envs/rajeev3/lib/python3.7/site-packages/contextualized_topic_models/models/ctm.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0msamples_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_samples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;31m# batch_size x vocab_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3_1/envs/rajeev3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3_1/envs/rajeev3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                 \u001b[0;31m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3_1/envs/rajeev3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1073\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m                     \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMP_STATUS_CHECK_INTERVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1076\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m                         \u001b[0;31m# Existing mechanisms try to make the workers exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3_1/envs/rajeev3/lib/python3.7/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3_1/envs/rajeev3/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3_1/envs/rajeev3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3_1/envs/rajeev3/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3_1/envs/rajeev3/lib/python3.7/site-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mprevious_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 32095) is killed by signal: Terminated. "
     ]
    }
   ],
   "source": [
    "from contextualized_topic_models.models.ctm import CTM\n",
    "from contextualized_topic_models.utils.data_preparation import TextHandler\n",
    "from contextualized_topic_models.utils.data_preparation import bert_embeddings_from_file\n",
    "from contextualized_topic_models.datasets.dataset import CTMDataset\n",
    "\n",
    "handler = TextHandler(\"reviews_tst_l\")\n",
    "handler.prepare() # create vocabulary and training data\n",
    "\n",
    "# generate BERT data\n",
    "training_bert = bert_embeddings_from_file(\"reviews_tst_l\", \"./roberta-large-nli-mean-tokens\")#\"../rev_sig/codes/models/scibert_scivocab_uncased\")\n",
    "print(training_bert.shape)\n",
    "\n",
    "training_dataset = CTMDataset(handler.bow, training_bert, handler.idx2token)\n",
    "\n",
    "ctm = CTM(input_size=len(handler.vocab), bert_input_size=1024, num_epochs=1000, inference_type=\"combined\", n_components=50)\n",
    "\n",
    "ctm.fit(training_dataset) # run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/tirthankar/miniconda3_1/envs/rajeev3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['u201cdecipering', 'argument', 'u201cmixed', 'nmt', 'lesser'],\n",
       " ['valued', 'complex', 'networks', 'decomposition', 'convacs'],\n",
       " ['wide', 'swan', 'beta_i', 'brnn', 'swap'],\n",
       " ['theta_t', 'theta_', 'nabla', 'authors', 'think'],\n",
       " ['en', 'good', 'bleu', 'total', 'wmt14'],\n",
       " ['learning', 'confidence', 'maximin', 'returns', 'case'],\n",
       " ['precision', 'three', 'student', 'act', 'predictor'],\n",
       " ['state', 'subgraph', 'neighbor', 'adjacency', 'environments'],\n",
       " ['network', 'time', 'energy', 'loss', 'using'],\n",
       " ['decision', 'universal', 'curved', 'perturbations', 'boundary'],\n",
       " ['images', 'np3', 'vaes', 'decoder', 'level'],\n",
       " ['singularities', 'layers', 'observations', 'last', 'eq'],\n",
       " ['crossover', 'shot', 'physics', 'evolutionary', 'cloning'],\n",
       " ['zero', 'distribution', 'lcw', 'activation', 'angle'],\n",
       " ['exs', 'major', 'readability', 'dramatically', 'contribute'],\n",
       " ['word', 'affect', 'different', 'text', 'nthe'],\n",
       " ['starting', 'please', 'variate', 'also', 'stein'],\n",
       " ['particular', 'specific', 'model', 'idea', 'units'],\n",
       " ['linear', 'deep', 'regression', 'logistic', 'risk'],\n",
       " ['bn', 'linearity', 'pdf', 'existing', 'convolutions'],\n",
       " ['toefl', 'esl', 'elaborate', 'vectors', 'development'],\n",
       " ['useful', 'sentence', 'coreference', 'rnns', 'oov'],\n",
       " ['metrics', 'preferred', 'drelu', 'result', 'noverall'],\n",
       " ['ape', 'u2022', 'nice', 'android', 'perceptual'],\n",
       " ['proposed', 'block', 'paper', 'originality', 'written'],\n",
       " ['channel', 'neural', 'well', 'networks', 'complex'],\n",
       " ['gpu', 'a2', 'a1', 'resources', 'new'],\n",
       " ['depthwise', 'vbp', 'presented', 'track', 'fba'],\n",
       " ['value', 'hidden', 'upper', 'sampled', 'flow'],\n",
       " ['medical', 'found', 'sparseness', '14', 'choice'],\n",
       " ['analysis', 'practical', 'algorithm', 'quantization', 'hou'],\n",
       " ['meta', 'cyclical', 'ba', 'detect', 'super'],\n",
       " ['sgd', 'algorithms', 'considerably', 'vis', 'numerical'],\n",
       " ['gradient', 'techniques', 'framework', 'unified', 'classification'],\n",
       " ['robust', 'weighting', 'transformations', 'shift', 'clear'],\n",
       " ['task', 'tasks', 'novelty', 'agent', 'section'],\n",
       " ['predictive', 'coding', 'hierarchy', 'checked', 'nclarity'],\n",
       " ['mix', 'smooth', 'svm', 'sampler', 'first'],\n",
       " ['ternatization', 'considerations', 'computer', 'originally', 'twn'],\n",
       " ['survival', 'naturally', 'thereby', 'trees', 'distributed'],\n",
       " ['point', 'gan', '3d', 'approaches', 'experiments'],\n",
       " ['baseline', 'method', 'bc', 'sbt', 'activity'],\n",
       " ['ijk', 'masking', 'trust', 'nin', 'distractor'],\n",
       " ['convergence', 'pg', 'results', 'policy', 'cascades'],\n",
       " ['approach', 'memory', 'class', 'interesting', 'representations'],\n",
       " ['measurement', 'linear', 'training', 'differentially', 'privacy'],\n",
       " ['paper', 'proposed', 'layer', 'technique', 'standard'],\n",
       " ['impacts', 'pact', 'sculpting', 'extrapolate', 'claiming'],\n",
       " ['models', 'new', 'proceedings', 'language', 'gutmann10a'],\n",
       " ['model', 'dcn', 'coattention', 'improvement', 'mixed']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctm.get_topic_lists(5) #[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/tirthankar/miniconda3_1/envs/rajeev3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/home2/tirthankar/miniconda3_1/envs/rajeev3/lib/python3.7/site-packages/contextualized_topic_models/models/ctm.py:254: DeprecationWarning: Call to `get_thetas` is deprecated and will be removed in version 2, use `get_doc_topic_distribution` instead\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.10980436e-04 1.62897324e-03 3.98529510e-04 9.48254379e-04\n",
      " 3.94401594e-04 2.06332653e-04 2.48435562e-03 2.95336597e-03\n",
      " 5.14506845e-03 1.36826900e-03 4.68691640e-02 2.01619504e-03\n",
      " 2.28624130e-04 8.89956229e-04 4.14607395e-04 1.52585578e-03\n",
      " 9.39152134e-04 1.24961914e-03 3.21718086e-04 3.81750645e-04\n",
      " 1.03304391e-03 6.23064031e-04 1.62250473e-03 1.11184901e-03\n",
      " 1.64760521e-03 1.21673859e-03 5.63679983e-04 8.40867978e-04\n",
      " 1.48199542e-03 1.37966381e-04 6.71870853e-04 7.66457272e-04\n",
      " 3.12873931e-04 4.30998740e-04 5.59187497e-04 9.03200305e-01\n",
      " 5.91522881e-04 4.92627318e-04 3.88521448e-04 5.38432093e-04\n",
      " 7.97445071e-04 7.02753582e-04 7.05526935e-04 1.16624888e-03\n",
      " 4.58874659e-04 1.03766033e-03 8.23515578e-04 4.12564249e-04\n",
      " 4.14724097e-03 4.40911944e-04]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['task',\n",
       " 'tasks',\n",
       " 'novelty',\n",
       " 'agent',\n",
       " 'section',\n",
       " 'known',\n",
       " 'good',\n",
       " 'fokker',\n",
       " 'planck',\n",
       " 'theory']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "distribution = ctm.get_thetas(training_dataset)[1] # topic distribution for the eight document\n",
    "\n",
    "print(distribution)\n",
    "\n",
    "topic = np.argmax(distribution)\n",
    "\n",
    "ctm.get_topic_lists(10)[topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rajeev3",
   "language": "python",
   "name": "rajeev3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
