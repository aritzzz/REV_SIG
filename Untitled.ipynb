{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class jsonEncoder(object):\n",
    "\tdef __init__(self, json_obj=None, mode = None):\n",
    "\t\tself.json_obj = json_obj\n",
    "\t\tself.mode = mode\n",
    "\n",
    "\t@classmethod\n",
    "\tdef from_json(cls, path, review_filename, mode):\n",
    "\t\ttry:\n",
    "\t\t\treturn cls(open(os.path.join(path, 'Embeddings', review_filename)), mode=mode)\n",
    "\t\texcept FileNotFoundError:\n",
    "\t\t\treturn cls(None)\n",
    "\n",
    "\tdef __call__(self):\n",
    "\t\tif not self.json_obj == None:\n",
    "\t\t\tencoded = json.load(self.json_obj)\n",
    "\t\t\tpaper = np.asarray(encoded['paper'])\n",
    "\t\t\treviews = []\n",
    "\t\t\tif self.mode == 'SCAFFOLDS':\n",
    "\t\t\t\trec_score = []\n",
    "\t\t\t\tconf_score = []\n",
    "\t\t\t\tfor i, review in enumerate(encoded['reviews']):\n",
    "\t\t\t\t\treviews.append(np.asarray(review.get('review_text')))\n",
    "\t\t\t\t\trec_score.append(review.get('RECOMMENDATION'))\n",
    "\t\t\t\t\tconf_score.append(review.get('CONFIDENCE'))\t\t\n",
    "\t\t\t\treturn paper, reviews, rec_score, conf_score\n",
    "\t\t\telif self.mode == 'MAIN':\n",
    "\t\t\t\tsignificance_score = []\n",
    "\t\t\t\tfor i, review in enumerate(encoded['reviews']):\n",
    "\t\t\t\t\treviews.append(np.asarray(review.get('review_text')))\n",
    "\t\t\t\t\tsignificance_score.append([float(i) for i in review.get('SIGNIFICANCE')])\n",
    "\t\t\t\treturn paper, reviews, significance_score\n",
    "\t\t\telse:\n",
    "\t\t\t\trec_score = []\n",
    "\t\t\t\tconf_score = []\n",
    "\t\t\t\tsignificance_score = []\n",
    "\t\t\t\tfor i, review in enumerate(encoded['reviews']):\n",
    "\t\t\t\t\treviews.append(np.asarray(review.get('review_text')))\n",
    "\t\t\t\t\trec_score.append(review.get('RECOMMENDATION'))\n",
    "\t\t\t\t\tconf_score.append(review.get('CONFIDENCE'))\t\n",
    "\t\t\t\t\tsignificance_score.append([float(i) for i in review.get('SIGNIFICANCE')])\n",
    "\t\t\t\treturn paper, reviews, rec_score, conf_score, significance_score\n",
    "\t\telse:\n",
    "\t\t\treturn None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(path, mode=None):\n",
    "    reviews_dir = os.listdir(os.path.join(path, 'reviews'))#[:n]\n",
    "    for review_dir in reviews_dir:\n",
    "        ret = jsonEncoder.from_json(path, review_dir, mode=mode)()\n",
    "        if ret == None:\n",
    "            continue\n",
    "        for i, rev in enumerate(ret[1],0):\n",
    "            json_obj = {}\n",
    "            json_obj['paper'] = ret[0]\n",
    "            json_obj['review'] = rev\n",
    "            if mode == 'SCAFFOLDS':\n",
    "                json_obj['recommendation'] = int(ret[2][i])\n",
    "                json_obj['confidence'] = int(ret[3][i])\n",
    "            elif mode == 'MAIN':\n",
    "                json_obj['significance'] = ret[2][i]\n",
    "            else:\n",
    "                json_obj['recommendation'] = int(ret[2][i])\n",
    "                json_obj['confidence'] = int(ret[3][i])\n",
    "                json_obj['significance'] = ret[4][i]\n",
    "            filename = '../test_data/' + review_dir + '_' + str(i)\n",
    "            with open(os.path.join(path, filename), 'w') as f:\n",
    "                f.write(json.dumps(json_obj, indent=8, ensure_ascii=False, cls=NumpyEncoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "write('./Data/SignData/test', mode='TEST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class Transform(object):\n",
    "\tdef __init__(self):\n",
    "\t\tpass\n",
    "\tdef __call__(self, array, max_sents):\n",
    "\t\treturn torch.from_numpy(np.pad(array, [(0, max_sents - array.shape[0]), (0,0)], mode = 'constant', constant_values = 0.0))\n",
    "    \n",
    "class ScaleSigScores(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, array, min_, max_):\n",
    "        sent = array[2]\n",
    "        array = (array-min_)/(max_ - min_)\n",
    "        array = (array*9) + 1\n",
    "        array[2] = (((sent - (-1))*9)/2) + 1\n",
    "        return array\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, path, mode = 'SCAFFOLDS', transform = None, sigtx = None):\n",
    "        self.path = path\n",
    "        self.data = os.listdir(path)\n",
    "        self.mode = mode\n",
    "        if self.mode == 'SCAFFOLDS':\n",
    "            self.max_paper_sentences, self.max_review_sentences = self.forTransform()\n",
    "        else:\n",
    "            self.max_paper_sentences, self.max_review_sentences, self.sig_min, self.sig_max = self.forTransform()\n",
    "            #790, 790, np.array([0.05428571,0.93013972,-0.99966815]), np.array([33.26288336,252.25067107,0.99966679])\n",
    "        self.transform = transform\n",
    "        self.SigTransform = sigtx\n",
    "        \n",
    "    def forTransform(self):\n",
    "        max_paper_sents = 0\n",
    "        max_review_sents = 0\n",
    "        if self.mode != 'SCAFFOLDS':\n",
    "            sig_scores = []\n",
    "            \n",
    "        for file in self.data:\n",
    "            json_obj = open(os.path.join(self.path, file))\n",
    "            ret = json.load(json_obj)\n",
    "            if len(ret['paper']) > max_paper_sents:\n",
    "                max_paper_sents = len(ret['paper'])\n",
    "            if len(ret['review']) > max_review_sents:\n",
    "                max_review_sents = len(ret['review'])\n",
    "            if self.mode != 'SCAFFOLDS':\n",
    "                sig_scores.append(ret['significance'])\n",
    "        if self.mode != 'SCAFFOLDS':            \n",
    "            return max_paper_sents, max_review_sents,np.asarray(sig_scores).min(axis=0),np.asarray(sig_scores).max(axis=0)\n",
    "        else:\n",
    "            return max_paper_sents, max_review_sents\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        file = self.data[index]\n",
    "        json_obj = open(os.path.join(self.path, file))\n",
    "        json_data = json.load(json_obj)\n",
    "\n",
    "        if self.mode == 'SCAFFOLDS':\n",
    "            if self.transform:\n",
    "                return self.transform(np.asarray(json_data['paper']), self.max_paper_sentences), \\\n",
    "                    self.transform(np.asarray(json_data['review']), self.max_review_sentences), \\\n",
    "                    json_data['recommendation'], json_data['confidence']\n",
    "            else:\n",
    "                return json_data['paper'], json_data['review'], json_data['recommendation'], json_data['confidence']\n",
    "        elif self.mode == 'MAIN':\n",
    "            if self.transform:\n",
    "                return self.transform(np.asarray(json_data['paper']), self.max_paper_sentences), \\\n",
    "                    self.transform(np.asarray(json_data['review']), self.max_review_sentences), \\\n",
    "                    self.SigTransform(np.asarray(json_data['significance']), self.sig_min, self.sig_max)\n",
    "            else:\n",
    "                return json_data['paper'],json_data['review'],json_data['significance']\n",
    "        else:\n",
    "            if self.transform:\n",
    "                return self.transform(np.asarray(json_data['paper']), self.max_paper_sentences), \\\n",
    "                    self.transform(np.asarray(json_data['review']), self.max_review_sentences), \\\n",
    "                    json_data['recommendation'], json_data['confidence'], self.SigTransform(np.asarray(json_data['significance']), self.sig_min, self.sig_max)\n",
    "            else:\n",
    "                return json_data['paper'], json_data['review'],json_data['recommendation'], json_data['confidence'],json_data['significance'] \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dataset('./Data/SignData/test_data', mode = 'TEST', transform=Transform(), sigtx = ScaleSigScores())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.85428571,  9.56806387, -0.99761351])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.sig_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 28.76591667, 328.43497006,   0.68505453])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.sig_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05428571,  0.93013972, -0.99966815])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.sig_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 33.26288336, 252.25067107,   0.99966679])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.sig_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "index can't contain negative values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-b41cae771af5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-6b958cd78b97>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'MAIN'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'paper'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_paper_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_review_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'significance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msig_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msig_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-b20b8168e80b>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, array, max_sents)\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_sents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_sents\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstant_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mScaleSigScores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpad\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3_1/envs/rajeev3/lib/python3.7/site-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0;31m# Broadcast to shape (array.ndim, 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m     \u001b[0mpad_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3_1/envs/rajeev3/lib/python3.7/site-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36m_as_pairs\u001b[0;34m(x, ndim, as_index)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mas_index\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"index can't contain negative values\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0;31m# Converting the array with `tolist` seems to improve performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: index can't contain negative values"
     ]
    }
   ],
   "source": [
    "d[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(d, batch_size = 2, shuffle = True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 790, 768]) torch.Size([2, 790, 768]) torch.Size([2]) torch.Size([2]) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(dl):\n",
    "    paper, review, rec, conf, sig = d\n",
    "    print(paper.shape, review.shape, rec.shape, conf.shape, sig.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rajeev3",
   "language": "python",
   "name": "rajeev3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
