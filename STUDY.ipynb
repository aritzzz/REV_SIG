{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/tirthankar/miniconda3_1/envs/rajeev3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['RECOMMENDATION', 'comments', 'CONFIDENCE', 'Layer 1', 'Layer 1 N', 'Layer 2', 'Layer 2 N', 'Layer 3',\n",
    "       'Layer 3 N']\n",
    "reviews = pd.read_csv('Test_Reviews.csv', usecols=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECOMMENDATION</th>\n",
       "      <th>comments</th>\n",
       "      <th>CONFIDENCE</th>\n",
       "      <th>Layer 1</th>\n",
       "      <th>Layer 1 N</th>\n",
       "      <th>Layer 2</th>\n",
       "      <th>Layer 2 N</th>\n",
       "      <th>Layer 3</th>\n",
       "      <th>Layer 3 N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>\"Summary: \\nThe authors present a simple variation of vanilla recurrent neural networks, which use ReLU hiddens and a fixed identity matrix that is added to the hidden-to-hidden weight matrix. This identity connection acts as a \\u201csurrogate memory\\u201d component, preserving hidden activations over time steps. \\nThe experiments demonstrate that this architecture reliably solves the addition task for up to 400 input frames. It also achieves a very good performance on sequential and permuted MNIST and achieves SOTA performance on bAbI.\\nThe authors observe that the proposed recurrent identity network (RIN) is relatively robust to hyperparameter choices. After Le et al. (2015), the paper presents another convincing case for the application of ReLUs in RNNs.\\n\\nReview: \\nI very much like the paper. The motivation and architecture is presented very clearly and I am happy to also see explorations of simpler recurrent architectures in parallel to research of gated architectures!\\nI have a few comments and questions:\\n1) Clarification: In Section 2.2, do you really mean bit-wise multiplication or element-wise? If bit-wise, can you elaborate why? I might have missed something.\\n2) Why does the learning curve of the IRNN stop around epoch 270 in Figure 2c? Also some curves in the appendix stop abruptly without visible explosions. Were these experiments run until completion? If so, would it be possible to plot the complete curves?\\n3) I think for a fair comparison with LSTMs and IRNNs a limited hyperparameter search should be performed separately on all three architectures at least for the addition task. Optimal hyperparameters are usually model-specific. Admittedly, the authors mention that they do not intend to make claims about superior performance to LSTMs, however the competitive performance of small RINs is mentioned a couple of times in the manuscript.\\nLe et al. (2015) for instance perform a coarse grid search for each model.\\n4) I wouldn't say that ResNets are Gated Neural Networks, as the branches are just summed up. There is no (multiplicative) gating as in Highway Networks.\\n5) I think what enables the training of very deep networks or LSTMs on long sequences is the presence of a (close-to-)identity component in forward/backward propagation, not the gating. The use of ReLU activations in IRNNs (with identity initialization of the hidden-to-hidden weights) and RINs (effectively initialized with identity plus some noise) makes the recurrence more linear than with squashing activation functions.\\n6) Regarding the absence of gating in RINs: What is your intuition on how the model would perform in tasks for which conditional forgetting is useful. Consider for example a task with long sequences, outputs at every time step and hidden activations not necessarily being encouraged to estimate last step hidden activations. Would RINs readily learn to reset parts of the hidden state?\\n7) Henaff et al. (2016) might be related, as they are also looking into the addition task with long sequences.\\n\\nOverall, the presented idea is novel to the best of my knowledge and the manuscript is well-written. I would recommend it for acceptance, but would like to see the above points addressed (especially 1-3 and some comments on 4-6). After a revision I would consider to increase the score.\\n\\nReferences:\\nHenaff, Mikael, Arthur Szlam, and Yann LeCun. \\\"Recurrent orthogonal networks and long-memory tasks.\\\" In International Conference on Machine Learning, pp. 2034-2042. 2016.\\nLe, Quoc V., Navdeep Jaitly, and Geoffrey E. Hinton. \\\"A simple way to initialize recurrent networks of rectified linear units.\\\" arXiv preprint arXiv:1504.00941 (2015).\"</td>\n",
       "      <td>4</td>\n",
       "      <td>16.587</td>\n",
       "      <td>5.481</td>\n",
       "      <td>142.202</td>\n",
       "      <td>6.059</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>\"The paper entitled 'Siamese Survival Analysis' reports an application of a deep learning to three cases of competing risk survival analysis. The author follow the reasoning that '... these ideas were not explored in the context of survival analysis', thereby disregarding the significant published literature based on the Concordance Index (CI). \\n\\nBesides this deficit, the paper does not present a proper statistical setup (e.g. 'Is censoring assumed to be at random? ...) , and numerical results are only referring to some standard implementations, thereby again neglecting the state-of-the-art solution. That being said, this particular use of deep learning in this context might be novel.\"</td>\n",
       "      <td>5</td>\n",
       "      <td>1.280</td>\n",
       "      <td>1.332</td>\n",
       "      <td>9.568</td>\n",
       "      <td>1.309</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>-0.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"In this paper, the authors define a simulated, multi-agent \\u201ctaxi pickup\\u201d task in a GridWorld environment. In the task, there are multiple taxi agents that a model must learn to control. \\u201cCustomers\\u201d randomly appear throughout the task and the taxi agents receive reward for moving to the same square as a customer. Since there are multiple customer and taxi agents, there is a multi-agent coordination problem. Further, the taxi agents have \\u201cbatteries\\u201d, which starts at a positive number, ticks down by one on each time step and a large negative reward is given if this number reaches zero. The battery can be \\u201crecharged\\u201d by moving to a \\u201ccharge\\u201d tile.\\n\\nCooperative multi-agent problem solving is an important problem in machine learning, artificial intelligence, and cognitive science. This paper defines and examines an interesting cooperative problem: Assignment and control of agents to move to certain squares under \\u201cphysical\\u201d constraints. The authors propose a centralized solution to the problem by adapting the Deep Q-learning Network model. I do not know whether using a centralized network where each agent has a window of observations is a novel algorithm. The manuscript itself makes it difficult to assess (more on this later). If it were novel, it would be an incremental development. They assess their solution quantitatively, demonstrating their model performs better than first, a simple heuristic model (I believe de-centralized Dijkstra\\u2019s for each agent, but there is not enough description in the manuscript to know for sure), and then, two other baselines that I could not figure out from the manuscript (I believe it was Dijkstra\\u2019s with two added rules for when to recharge).\\n\\nAlthough the manuscript has many positive aspects to it, I do not believe it should be accepted for the following reasons. First, the manuscript is poorly written, to the point where it has inhibited my ability to assess it. Second, given its contribution, the manuscript is better suited for a conference specific to multi-agent decision-making. There are a few reasons for this. 1) I was not convinced that deep Q-learning was necessary to solve this problem. The manuscript would be much stronger if the authors compared their method to a more sophisticated baseline, for example having each agent be a simple Q-learner with no centralization or \\u201cdeepness\\u201d. This would solve another issue, which is the weakness of their baseline measure. There are many multi-agent techniques that can be applied to the problem that would have served as a better baseline. 2) Although the problem itself is interesting, it is a bit too applied and specific to the particular task they studied than is appropriate for a conference with as broad interests as ICLR. It also is a bit simplistic (I had expected the agents to at least need to learn to move the customer to some square rather than get reward and move to the next job from just getting to the customer\\u2019s square). Can you apply this method to other multi-agent problems? How would it compare to other methods on those problems? \\n\\nI encourage the authors to develop the problem and method further, as well as the analysis and evaluation. \\n\"</td>\n",
       "      <td>3</td>\n",
       "      <td>11.172</td>\n",
       "      <td>4.013</td>\n",
       "      <td>160.306</td>\n",
       "      <td>6.707</td>\n",
       "      <td>-0.672</td>\n",
       "      <td>-0.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>\"Summary:\\n The paper presents an unsupervised method for detecting adversarial examples of neural networks. The method includes two independent components: an \\u2018input defender\\u2019 which tried to inspect the input, and a \\u2018latent defender\\u2019 trying to inspect a hidden representation. Both are based on the claim that adversarial examples lie outside a certain sub-space occupied by the natural image examples, and modeling this sub-space hence enables their detection. The input defender is based on sparse coding, and the latent defender on modeling the latent activity as a mixture of Gaussians. Experiments are presented on MInst, Cifar10, and ImageNet.\\n \\n-\\tIntroduction: The motivation for detecting adversarial examples is not stated clearly enough. How can such examples be used by a malicious agent to cause damage to a system? Sketching some such scenarios would help the reader understand why the issue is practically important. I was not convinced it is. \\nPage 4: \\n-\\tStep 3 of the algorithm is not clear:\\no\\tHow exactly does HDDA model the data (formally) and how does it estimate the parameters? In the current version, the paper does not explain the HDDA formalism and learning algorithm, which is a main building block in the proposed system (as it provides the density score used for adversarial examples detection). Hence the paper cannot be read as a standalone document. I went on to read the relevant HDDA paper, but it is also not clear which of the model variants presented there is used in this paper.\\no\\tWhat is the relation between the model learned at stage 2 (the centers c^i) and the model learnt by HDDA? Are they completely different models? Or are the C^I used when learning the HDDA model (and how)? \\nIf these are separate models, how are they used in conjunction to give a final density score? If I understand correctly, only the HDDA model is used to get the final score, and the C^i are only used to make the \\\\phy(x) representation more class-seperable. Is that right?\\n-\\tFigure 4, b and c: it is not clear what the (x,y,z) measurements plotted in these 3D drawings are (what are the axis).\\nPage 5:\\n-\\tSection 2: the risk analysis is done in a standard Bayesian way and leads to a ratio of PDFs in equation 5. However, this form is not appropriate for the case presented at this paper, since the method presented only models one of these PDFs (Specifically p(x | W1)  - there is not generative model of p(x|W2)).  \\n-\\tThe authors claim in the last sentence of the section that p(x|W2) is equivalent to 1-p(x|W1), but this is not true: these are two continuous densities, they do not sum to 1, and a model of p(x|W2) is not available (as far as I understand the method)\\nPage 6:\\n-\\tHow is equation 7) optimized?\\n-\\tWhich patchs are extracted from images, for training and at inference time? Are these patchs a dense coverage of the image? Sparsely sampled? Densely sampled with overlaps?\\n-\\tIts not clear enough what exactly is the \\u2018PSNR\\u2019 value which is used for the adversarial example detection, and what exactly is \\u2018profile the PSNR of legitimate samples within each class\\u2019. A formal definition of PSNR and\\u2019profiling\\u2019 is missing (does profiling simply mean finding a threshold for filtering?)\\nPage 7:\\n-\\tFigure 7 is not very informative. Given the ROC curves in figure 8  and table 1 it is redundant. \\n\\nPage 8:\\n-\\tThe results in general indicate that the method is much better than chance, but it is not clear if it is practical, because the false alarm rates for high detection are quite high. For example on ImageNet, 14.2% of the innocent images are mistakenly rejected as malicious to get 90% detection rate. I do not think this working point is useful for a real application\\n-\\tGiven the high flares alarm rate, it is surprising that experiments with multiple checkpoints are not presented (specifically as this case of multiple checkpoints is discussed explicitly in previous sections of the paper).  Experiments with multiple checkpoints are clear required to complete the picture regarding the empirical performance of this method\\n-\\tThe experiments show that essentially, the latent defenders are stronger than the input defender in most cases. However, an ablation study of the latent defender is missing: Specifcially, it is not clear a) how much does stage 2 (model refinement with clusters)  contribute to the accuracy (how does the model do without it? And 3) how important is the HDDA and the specific variant used (which is not clear) important: is it important to model the Gaussians using a sub-space? Of which dimension?\\n\\nOverall:\\nPros:\\n-\\t A nice idea with some novelty,  based on a non-trivial observation\\n-\\tThe experimental results how the idea holds some promise\\nCons\\n-\\tThe method is not presented clearly enough: the main component modeling the network activity is not explained (the HDDA module used)\\n-\\tThe results presented show that the method is probably not suitable for a practical application yet (high false alarm rate for good detection rate)\\n-\\tExperimental results are partial: results are not presented for multiple defenders, no ablation experiments\\n\\n\\nAfter revision:\\nSome of my comments were addressed, and some were not.\\nSpecifically, results were presented for multiple defenders and some ablation experiments were highlihgted\\nThings not addressed:\\n - The risk analysis is still not relevant. The authors removed a clearly flawed sentence, but the analysis still assumes that two densities (of 'good' and 'bad' examples) are modeled, while in the work presented only one of them is. Hence this analysis does not add anything to the paper-  it states a general case which does not fit the current scenario and its relation to the work is not clear. It would have been better to omit it and use the space to describe HDDA and the specific variant used in this work, as this is the main tool doing the distinction.\\n\\nI believe the paper should be accepted.\\n\"</td>\n",
       "      <td>3</td>\n",
       "      <td>28.766</td>\n",
       "      <td>8.781</td>\n",
       "      <td>328.435</td>\n",
       "      <td>12.728</td>\n",
       "      <td>-0.933</td>\n",
       "      <td>-0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>\"The paper introduces a new memory mechanism specifically tailored for agent navigation in 2D environments. The memory consists of a 2D array and includes trainable read/write mechanisms. The RL agent's policy is a function of the context read, read, and next step write vectors (which are functions of the observation). The effectiveness of the proposed architecture is evaluated via reinforcement learning (% of mazes solved). The evaluation included 1000 test mazes--which sets a good precedent for evaluation in this subfield. \\n\\nMy main concern is the lack of experiments to test whether the agent really learned to localize and plan routes using it's memory architecture. The downsampling experiment in Section 5.1 seems to indicate the contrary: downsampling the memory should lead to position aliasing which seems to indicate that the agent is not using its memory to store the map and its own location. I'm concerned whether the proposed agent is actually employing a navigation strategy, as seems to be suggested, or is simply a good agent architecture for this task (e.g. for optimization reasons). The short experiment in Appendix E seems to try and answer this question, but it's results are anecdotal at best. \\n\\nIf good RL performance on navigation tasks is the ultimate goal then one can imagine an agent that directly copies the raw map observation (world centric) into memory and use something like a value iteration network or shortest path planning to plan routes. My point is that there are classical algorithms to solve navigation even in partially observable 2D grid worlds, why bother with deep RL here? \"</td>\n",
       "      <td>4</td>\n",
       "      <td>3.718</td>\n",
       "      <td>1.993</td>\n",
       "      <td>42.942</td>\n",
       "      <td>2.504</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>-0.455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RECOMMENDATION  \\\n",
       "0  7                \n",
       "1  4                \n",
       "2  3                \n",
       "3  7                \n",
       "4  7                \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              comments  \\\n",
       "0  \"Summary: \\nThe authors present a simple variation of vanilla recurrent neural networks, which use ReLU hiddens and a fixed identity matrix that is added to the hidden-to-hidden weight matrix. This identity connection acts as a \\u201csurrogate memory\\u201d component, preserving hidden activations over time steps. \\nThe experiments demonstrate that this architecture reliably solves the addition task for up to 400 input frames. It also achieves a very good performance on sequential and permuted MNIST and achieves SOTA performance on bAbI.\\nThe authors observe that the proposed recurrent identity network (RIN) is relatively robust to hyperparameter choices. After Le et al. (2015), the paper presents another convincing case for the application of ReLUs in RNNs.\\n\\nReview: \\nI very much like the paper. The motivation and architecture is presented very clearly and I am happy to also see explorations of simpler recurrent architectures in parallel to research of gated architectures!\\nI have a few comments and questions:\\n1) Clarification: In Section 2.2, do you really mean bit-wise multiplication or element-wise? If bit-wise, can you elaborate why? I might have missed something.\\n2) Why does the learning curve of the IRNN stop around epoch 270 in Figure 2c? Also some curves in the appendix stop abruptly without visible explosions. Were these experiments run until completion? If so, would it be possible to plot the complete curves?\\n3) I think for a fair comparison with LSTMs and IRNNs a limited hyperparameter search should be performed separately on all three architectures at least for the addition task. Optimal hyperparameters are usually model-specific. Admittedly, the authors mention that they do not intend to make claims about superior performance to LSTMs, however the competitive performance of small RINs is mentioned a couple of times in the manuscript.\\nLe et al. (2015) for instance perform a coarse grid search for each model.\\n4) I wouldn't say that ResNets are Gated Neural Networks, as the branches are just summed up. There is no (multiplicative) gating as in Highway Networks.\\n5) I think what enables the training of very deep networks or LSTMs on long sequences is the presence of a (close-to-)identity component in forward/backward propagation, not the gating. The use of ReLU activations in IRNNs (with identity initialization of the hidden-to-hidden weights) and RINs (effectively initialized with identity plus some noise) makes the recurrence more linear than with squashing activation functions.\\n6) Regarding the absence of gating in RINs: What is your intuition on how the model would perform in tasks for which conditional forgetting is useful. Consider for example a task with long sequences, outputs at every time step and hidden activations not necessarily being encouraged to estimate last step hidden activations. Would RINs readily learn to reset parts of the hidden state?\\n7) Henaff et al. (2016) might be related, as they are also looking into the addition task with long sequences.\\n\\nOverall, the presented idea is novel to the best of my knowledge and the manuscript is well-written. I would recommend it for acceptance, but would like to see the above points addressed (especially 1-3 and some comments on 4-6). After a revision I would consider to increase the score.\\n\\nReferences:\\nHenaff, Mikael, Arthur Szlam, and Yann LeCun. \\\"Recurrent orthogonal networks and long-memory tasks.\\\" In International Conference on Machine Learning, pp. 2034-2042. 2016.\\nLe, Quoc V., Navdeep Jaitly, and Geoffrey E. Hinton. \\\"A simple way to initialize recurrent networks of rectified linear units.\\\" arXiv preprint arXiv:1504.00941 (2015).\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "1  \"The paper entitled 'Siamese Survival Analysis' reports an application of a deep learning to three cases of competing risk survival analysis. The author follow the reasoning that '... these ideas were not explored in the context of survival analysis', thereby disregarding the significant published literature based on the Concordance Index (CI). \\n\\nBesides this deficit, the paper does not present a proper statistical setup (e.g. 'Is censoring assumed to be at random? ...) , and numerical results are only referring to some standard implementations, thereby again neglecting the state-of-the-art solution. That being said, this particular use of deep learning in this context might be novel.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "2  \"In this paper, the authors define a simulated, multi-agent \\u201ctaxi pickup\\u201d task in a GridWorld environment. In the task, there are multiple taxi agents that a model must learn to control. \\u201cCustomers\\u201d randomly appear throughout the task and the taxi agents receive reward for moving to the same square as a customer. Since there are multiple customer and taxi agents, there is a multi-agent coordination problem. Further, the taxi agents have \\u201cbatteries\\u201d, which starts at a positive number, ticks down by one on each time step and a large negative reward is given if this number reaches zero. The battery can be \\u201crecharged\\u201d by moving to a \\u201ccharge\\u201d tile.\\n\\nCooperative multi-agent problem solving is an important problem in machine learning, artificial intelligence, and cognitive science. This paper defines and examines an interesting cooperative problem: Assignment and control of agents to move to certain squares under \\u201cphysical\\u201d constraints. The authors propose a centralized solution to the problem by adapting the Deep Q-learning Network model. I do not know whether using a centralized network where each agent has a window of observations is a novel algorithm. The manuscript itself makes it difficult to assess (more on this later). If it were novel, it would be an incremental development. They assess their solution quantitatively, demonstrating their model performs better than first, a simple heuristic model (I believe de-centralized Dijkstra\\u2019s for each agent, but there is not enough description in the manuscript to know for sure), and then, two other baselines that I could not figure out from the manuscript (I believe it was Dijkstra\\u2019s with two added rules for when to recharge).\\n\\nAlthough the manuscript has many positive aspects to it, I do not believe it should be accepted for the following reasons. First, the manuscript is poorly written, to the point where it has inhibited my ability to assess it. Second, given its contribution, the manuscript is better suited for a conference specific to multi-agent decision-making. There are a few reasons for this. 1) I was not convinced that deep Q-learning was necessary to solve this problem. The manuscript would be much stronger if the authors compared their method to a more sophisticated baseline, for example having each agent be a simple Q-learner with no centralization or \\u201cdeepness\\u201d. This would solve another issue, which is the weakness of their baseline measure. There are many multi-agent techniques that can be applied to the problem that would have served as a better baseline. 2) Although the problem itself is interesting, it is a bit too applied and specific to the particular task they studied than is appropriate for a conference with as broad interests as ICLR. It also is a bit simplistic (I had expected the agents to at least need to learn to move the customer to some square rather than get reward and move to the next job from just getting to the customer\\u2019s square). Can you apply this method to other multi-agent problems? How would it compare to other methods on those problems? \\n\\nI encourage the authors to develop the problem and method further, as well as the analysis and evaluation. \\n\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "3  \"Summary:\\n The paper presents an unsupervised method for detecting adversarial examples of neural networks. The method includes two independent components: an \\u2018input defender\\u2019 which tried to inspect the input, and a \\u2018latent defender\\u2019 trying to inspect a hidden representation. Both are based on the claim that adversarial examples lie outside a certain sub-space occupied by the natural image examples, and modeling this sub-space hence enables their detection. The input defender is based on sparse coding, and the latent defender on modeling the latent activity as a mixture of Gaussians. Experiments are presented on MInst, Cifar10, and ImageNet.\\n \\n-\\tIntroduction: The motivation for detecting adversarial examples is not stated clearly enough. How can such examples be used by a malicious agent to cause damage to a system? Sketching some such scenarios would help the reader understand why the issue is practically important. I was not convinced it is. \\nPage 4: \\n-\\tStep 3 of the algorithm is not clear:\\no\\tHow exactly does HDDA model the data (formally) and how does it estimate the parameters? In the current version, the paper does not explain the HDDA formalism and learning algorithm, which is a main building block in the proposed system (as it provides the density score used for adversarial examples detection). Hence the paper cannot be read as a standalone document. I went on to read the relevant HDDA paper, but it is also not clear which of the model variants presented there is used in this paper.\\no\\tWhat is the relation between the model learned at stage 2 (the centers c^i) and the model learnt by HDDA? Are they completely different models? Or are the C^I used when learning the HDDA model (and how)? \\nIf these are separate models, how are they used in conjunction to give a final density score? If I understand correctly, only the HDDA model is used to get the final score, and the C^i are only used to make the \\\\phy(x) representation more class-seperable. Is that right?\\n-\\tFigure 4, b and c: it is not clear what the (x,y,z) measurements plotted in these 3D drawings are (what are the axis).\\nPage 5:\\n-\\tSection 2: the risk analysis is done in a standard Bayesian way and leads to a ratio of PDFs in equation 5. However, this form is not appropriate for the case presented at this paper, since the method presented only models one of these PDFs (Specifically p(x | W1)  - there is not generative model of p(x|W2)).  \\n-\\tThe authors claim in the last sentence of the section that p(x|W2) is equivalent to 1-p(x|W1), but this is not true: these are two continuous densities, they do not sum to 1, and a model of p(x|W2) is not available (as far as I understand the method)\\nPage 6:\\n-\\tHow is equation 7) optimized?\\n-\\tWhich patchs are extracted from images, for training and at inference time? Are these patchs a dense coverage of the image? Sparsely sampled? Densely sampled with overlaps?\\n-\\tIts not clear enough what exactly is the \\u2018PSNR\\u2019 value which is used for the adversarial example detection, and what exactly is \\u2018profile the PSNR of legitimate samples within each class\\u2019. A formal definition of PSNR and\\u2019profiling\\u2019 is missing (does profiling simply mean finding a threshold for filtering?)\\nPage 7:\\n-\\tFigure 7 is not very informative. Given the ROC curves in figure 8  and table 1 it is redundant. \\n\\nPage 8:\\n-\\tThe results in general indicate that the method is much better than chance, but it is not clear if it is practical, because the false alarm rates for high detection are quite high. For example on ImageNet, 14.2% of the innocent images are mistakenly rejected as malicious to get 90% detection rate. I do not think this working point is useful for a real application\\n-\\tGiven the high flares alarm rate, it is surprising that experiments with multiple checkpoints are not presented (specifically as this case of multiple checkpoints is discussed explicitly in previous sections of the paper).  Experiments with multiple checkpoints are clear required to complete the picture regarding the empirical performance of this method\\n-\\tThe experiments show that essentially, the latent defenders are stronger than the input defender in most cases. However, an ablation study of the latent defender is missing: Specifcially, it is not clear a) how much does stage 2 (model refinement with clusters)  contribute to the accuracy (how does the model do without it? And 3) how important is the HDDA and the specific variant used (which is not clear) important: is it important to model the Gaussians using a sub-space? Of which dimension?\\n\\nOverall:\\nPros:\\n-\\t A nice idea with some novelty,  based on a non-trivial observation\\n-\\tThe experimental results how the idea holds some promise\\nCons\\n-\\tThe method is not presented clearly enough: the main component modeling the network activity is not explained (the HDDA module used)\\n-\\tThe results presented show that the method is probably not suitable for a practical application yet (high false alarm rate for good detection rate)\\n-\\tExperimental results are partial: results are not presented for multiple defenders, no ablation experiments\\n\\n\\nAfter revision:\\nSome of my comments were addressed, and some were not.\\nSpecifically, results were presented for multiple defenders and some ablation experiments were highlihgted\\nThings not addressed:\\n - The risk analysis is still not relevant. The authors removed a clearly flawed sentence, but the analysis still assumes that two densities (of 'good' and 'bad' examples) are modeled, while in the work presented only one of them is. Hence this analysis does not add anything to the paper-  it states a general case which does not fit the current scenario and its relation to the work is not clear. It would have been better to omit it and use the space to describe HDDA and the specific variant used in this work, as this is the main tool doing the distinction.\\n\\nI believe the paper should be accepted.\\n\"   \n",
       "4  \"The paper introduces a new memory mechanism specifically tailored for agent navigation in 2D environments. The memory consists of a 2D array and includes trainable read/write mechanisms. The RL agent's policy is a function of the context read, read, and next step write vectors (which are functions of the observation). The effectiveness of the proposed architecture is evaluated via reinforcement learning (% of mazes solved). The evaluation included 1000 test mazes--which sets a good precedent for evaluation in this subfield. \\n\\nMy main concern is the lack of experiments to test whether the agent really learned to localize and plan routes using it's memory architecture. The downsampling experiment in Section 5.1 seems to indicate the contrary: downsampling the memory should lead to position aliasing which seems to indicate that the agent is not using its memory to store the map and its own location. I'm concerned whether the proposed agent is actually employing a navigation strategy, as seems to be suggested, or is simply a good agent architecture for this task (e.g. for optimization reasons). The short experiment in Appendix E seems to try and answer this question, but it's results are anecdotal at best. \\n\\nIf good RL performance on navigation tasks is the ultimate goal then one can imagine an agent that directly copies the raw map observation (world centric) into memory and use something like a value iteration network or shortest path planning to plan routes. My point is that there are classical algorithms to solve navigation even in partially observable 2D grid worlds, why bother with deep RL here? \"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "\n",
       "   CONFIDENCE  Layer 1  Layer 1 N  Layer 2  Layer 2 N  Layer 3  Layer 3 N  \n",
       "0  4           16.587   5.481      142.202  6.059      0.044    0.044      \n",
       "1  5           1.280    1.332      9.568    1.309     -0.340   -0.340      \n",
       "2  3           11.172   4.013      160.306  6.707     -0.672   -0.672      \n",
       "3  3           28.766   8.781      328.435  12.728    -0.933   -0.933      \n",
       "4  4           3.718    1.993      42.942   2.504     -0.455   -0.455      "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exhaustiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews[reviews['Layer 1 N'] < 2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rajeev3",
   "language": "python",
   "name": "rajeev3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
