{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/tirthankar/miniconda3_1/envs/rajeev3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['ID', 'RECOMMENDATION', 'comments', 'CONFIDENCE', 'Layer 1', 'Layer 1 N', 'Layer 2', 'Layer 2 N', 'Layer 3',\n",
    "       'Layer 3 N']\n",
    "reviews = pd.read_csv('Test_Reviews.csv', usecols=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECOMMENDATION</th>\n",
       "      <th>comments</th>\n",
       "      <th>CONFIDENCE</th>\n",
       "      <th>ID</th>\n",
       "      <th>Layer 1</th>\n",
       "      <th>Layer 1 N</th>\n",
       "      <th>Layer 2</th>\n",
       "      <th>Layer 2 N</th>\n",
       "      <th>Layer 3</th>\n",
       "      <th>Layer 3 N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>\"Summary: \\nThe authors present a simple variation of vanilla recurrent neural networks, which use ReLU hiddens and a fixed identity matrix that is added to the hidden-to-hidden weight matrix. This identity connection acts as a \\u201csurrogate memory\\u201d component, preserving hidden activations over time steps. \\nThe experiments demonstrate that this architecture reliably solves the addition task for up to 400 input frames. It also achieves a very good performance on sequential and permuted MNIST and achieves SOTA performance on bAbI.\\nThe authors observe that the proposed recurrent identity network (RIN) is relatively robust to hyperparameter choices. After Le et al. (2015), the paper presents another convincing case for the application of ReLUs in RNNs.\\n\\nReview: \\nI very much like the paper. The motivation and architecture is presented very clearly and I am happy to also see explorations of simpler recurrent architectures in parallel to research of gated architectures!\\nI have a few comments and questions:\\n1) Clarification: In Section 2.2, do you really mean bit-wise multiplication or element-wise? If bit-wise, can you elaborate why? I might have missed something.\\n2) Why does the learning curve of the IRNN stop around epoch 270 in Figure 2c? Also some curves in the appendix stop abruptly without visible explosions. Were these experiments run until completion? If so, would it be possible to plot the complete curves?\\n3) I think for a fair comparison with LSTMs and IRNNs a limited hyperparameter search should be performed separately on all three architectures at least for the addition task. Optimal hyperparameters are usually model-specific. Admittedly, the authors mention that they do not intend to make claims about superior performance to LSTMs, however the competitive performance of small RINs is mentioned a couple of times in the manuscript.\\nLe et al. (2015) for instance perform a coarse grid search for each model.\\n4) I wouldn't say that ResNets are Gated Neural Networks, as the branches are just summed up. There is no (multiplicative) gating as in Highway Networks.\\n5) I think what enables the training of very deep networks or LSTMs on long sequences is the presence of a (close-to-)identity component in forward/backward propagation, not the gating. The use of ReLU activations in IRNNs (with identity initialization of the hidden-to-hidden weights) and RINs (effectively initialized with identity plus some noise) makes the recurrence more linear than with squashing activation functions.\\n6) Regarding the absence of gating in RINs: What is your intuition on how the model would perform in tasks for which conditional forgetting is useful. Consider for example a task with long sequences, outputs at every time step and hidden activations not necessarily being encouraged to estimate last step hidden activations. Would RINs readily learn to reset parts of the hidden state?\\n7) Henaff et al. (2016) might be related, as they are also looking into the addition task with long sequences.\\n\\nOverall, the presented idea is novel to the best of my knowledge and the manuscript is well-written. I would recommend it for acceptance, but would like to see the above points addressed (especially 1-3 and some comments on 4-6). After a revision I would consider to increase the score.\\n\\nReferences:\\nHenaff, Mikael, Arthur Szlam, and Yann LeCun. \\\"Recurrent orthogonal networks and long-memory tasks.\\\" In International Conference on Machine Learning, pp. 2034-2042. 2016.\\nLe, Quoc V., Navdeep Jaitly, and Geoffrey E. Hinton. \\\"A simple way to initialize recurrent networks of rectified linear units.\\\" arXiv preprint arXiv:1504.00941 (2015).\"</td>\n",
       "      <td>4</td>\n",
       "      <td>Hyp3i2xRb.json</td>\n",
       "      <td>16.587</td>\n",
       "      <td>5.481</td>\n",
       "      <td>142.202</td>\n",
       "      <td>6.059</td>\n",
       "      <td>0.044</td>\n",
       "      <td>5.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>\"The paper entitled 'Siamese Survival Analysis' reports an application of a deep learning to three cases of competing risk survival analysis. The author follow the reasoning that '... these ideas were not explored in the context of survival analysis', thereby disregarding the significant published literature based on the Concordance Index (CI). \\n\\nBesides this deficit, the paper does not present a proper statistical setup (e.g. 'Is censoring assumed to be at random? ...) , and numerical results are only referring to some standard implementations, thereby again neglecting the state-of-the-art solution. That being said, this particular use of deep learning in this context might be novel.\"</td>\n",
       "      <td>5</td>\n",
       "      <td>HkjL6MiTb.json</td>\n",
       "      <td>1.280</td>\n",
       "      <td>1.332</td>\n",
       "      <td>9.568</td>\n",
       "      <td>1.309</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>3.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"In this paper, the authors define a simulated, multi-agent \\u201ctaxi pickup\\u201d task in a GridWorld environment. In the task, there are multiple taxi agents that a model must learn to control. \\u201cCustomers\\u201d randomly appear throughout the task and the taxi agents receive reward for moving to the same square as a customer. Since there are multiple customer and taxi agents, there is a multi-agent coordination problem. Further, the taxi agents have \\u201cbatteries\\u201d, which starts at a positive number, ticks down by one on each time step and a large negative reward is given if this number reaches zero. The battery can be \\u201crecharged\\u201d by moving to a \\u201ccharge\\u201d tile.\\n\\nCooperative multi-agent problem solving is an important problem in machine learning, artificial intelligence, and cognitive science. This paper defines and examines an interesting cooperative problem: Assignment and control of agents to move to certain squares under \\u201cphysical\\u201d constraints. The authors propose a centralized solution to the problem by adapting the Deep Q-learning Network model. I do not know whether using a centralized network where each agent has a window of observations is a novel algorithm. The manuscript itself makes it difficult to assess (more on this later). If it were novel, it would be an incremental development. They assess their solution quantitatively, demonstrating their model performs better than first, a simple heuristic model (I believe de-centralized Dijkstra\\u2019s for each agent, but there is not enough description in the manuscript to know for sure), and then, two other baselines that I could not figure out from the manuscript (I believe it was Dijkstra\\u2019s with two added rules for when to recharge).\\n\\nAlthough the manuscript has many positive aspects to it, I do not believe it should be accepted for the following reasons. First, the manuscript is poorly written, to the point where it has inhibited my ability to assess it. Second, given its contribution, the manuscript is better suited for a conference specific to multi-agent decision-making. There are a few reasons for this. 1) I was not convinced that deep Q-learning was necessary to solve this problem. The manuscript would be much stronger if the authors compared their method to a more sophisticated baseline, for example having each agent be a simple Q-learner with no centralization or \\u201cdeepness\\u201d. This would solve another issue, which is the weakness of their baseline measure. There are many multi-agent techniques that can be applied to the problem that would have served as a better baseline. 2) Although the problem itself is interesting, it is a bit too applied and specific to the particular task they studied than is appropriate for a conference with as broad interests as ICLR. It also is a bit simplistic (I had expected the agents to at least need to learn to move the customer to some square rather than get reward and move to the next job from just getting to the customer\\u2019s square). Can you apply this method to other multi-agent problems? How would it compare to other methods on those problems? \\n\\nI encourage the authors to develop the problem and method further, as well as the analysis and evaluation. \\n\"</td>\n",
       "      <td>3</td>\n",
       "      <td>B1EGg7ZCb.json</td>\n",
       "      <td>11.172</td>\n",
       "      <td>4.013</td>\n",
       "      <td>160.306</td>\n",
       "      <td>6.707</td>\n",
       "      <td>-0.672</td>\n",
       "      <td>2.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>\"Summary:\\n The paper presents an unsupervised method for detecting adversarial examples of neural networks. The method includes two independent components: an \\u2018input defender\\u2019 which tried to inspect the input, and a \\u2018latent defender\\u2019 trying to inspect a hidden representation. Both are based on the claim that adversarial examples lie outside a certain sub-space occupied by the natural image examples, and modeling this sub-space hence enables their detection. The input defender is based on sparse coding, and the latent defender on modeling the latent activity as a mixture of Gaussians. Experiments are presented on MInst, Cifar10, and ImageNet.\\n \\n-\\tIntroduction: The motivation for detecting adversarial examples is not stated clearly enough. How can such examples be used by a malicious agent to cause damage to a system? Sketching some such scenarios would help the reader understand why the issue is practically important. I was not convinced it is. \\nPage 4: \\n-\\tStep 3 of the algorithm is not clear:\\no\\tHow exactly does HDDA model the data (formally) and how does it estimate the parameters? In the current version, the paper does not explain the HDDA formalism and learning algorithm, which is a main building block in the proposed system (as it provides the density score used for adversarial examples detection). Hence the paper cannot be read as a standalone document. I went on to read the relevant HDDA paper, but it is also not clear which of the model variants presented there is used in this paper.\\no\\tWhat is the relation between the model learned at stage 2 (the centers c^i) and the model learnt by HDDA? Are they completely different models? Or are the C^I used when learning the HDDA model (and how)? \\nIf these are separate models, how are they used in conjunction to give a final density score? If I understand correctly, only the HDDA model is used to get the final score, and the C^i are only used to make the \\\\phy(x) representation more class-seperable. Is that right?\\n-\\tFigure 4, b and c: it is not clear what the (x,y,z) measurements plotted in these 3D drawings are (what are the axis).\\nPage 5:\\n-\\tSection 2: the risk analysis is done in a standard Bayesian way and leads to a ratio of PDFs in equation 5. However, this form is not appropriate for the case presented at this paper, since the method presented only models one of these PDFs (Specifically p(x | W1)  - there is not generative model of p(x|W2)).  \\n-\\tThe authors claim in the last sentence of the section that p(x|W2) is equivalent to 1-p(x|W1), but this is not true: these are two continuous densities, they do not sum to 1, and a model of p(x|W2) is not available (as far as I understand the method)\\nPage 6:\\n-\\tHow is equation 7) optimized?\\n-\\tWhich patchs are extracted from images, for training and at inference time? Are these patchs a dense coverage of the image? Sparsely sampled? Densely sampled with overlaps?\\n-\\tIts not clear enough what exactly is the \\u2018PSNR\\u2019 value which is used for the adversarial example detection, and what exactly is \\u2018profile the PSNR of legitimate samples within each class\\u2019. A formal definition of PSNR and\\u2019profiling\\u2019 is missing (does profiling simply mean finding a threshold for filtering?)\\nPage 7:\\n-\\tFigure 7 is not very informative. Given the ROC curves in figure 8  and table 1 it is redundant. \\n\\nPage 8:\\n-\\tThe results in general indicate that the method is much better than chance, but it is not clear if it is practical, because the false alarm rates for high detection are quite high. For example on ImageNet, 14.2% of the innocent images are mistakenly rejected as malicious to get 90% detection rate. I do not think this working point is useful for a real application\\n-\\tGiven the high flares alarm rate, it is surprising that experiments with multiple checkpoints are not presented (specifically as this case of multiple checkpoints is discussed explicitly in previous sections of the paper).  Experiments with multiple checkpoints are clear required to complete the picture regarding the empirical performance of this method\\n-\\tThe experiments show that essentially, the latent defenders are stronger than the input defender in most cases. However, an ablation study of the latent defender is missing: Specifcially, it is not clear a) how much does stage 2 (model refinement with clusters)  contribute to the accuracy (how does the model do without it? And 3) how important is the HDDA and the specific variant used (which is not clear) important: is it important to model the Gaussians using a sub-space? Of which dimension?\\n\\nOverall:\\nPros:\\n-\\t A nice idea with some novelty,  based on a non-trivial observation\\n-\\tThe experimental results how the idea holds some promise\\nCons\\n-\\tThe method is not presented clearly enough: the main component modeling the network activity is not explained (the HDDA module used)\\n-\\tThe results presented show that the method is probably not suitable for a practical application yet (high false alarm rate for good detection rate)\\n-\\tExperimental results are partial: results are not presented for multiple defenders, no ablation experiments\\n\\n\\nAfter revision:\\nSome of my comments were addressed, and some were not.\\nSpecifically, results were presented for multiple defenders and some ablation experiments were highlihgted\\nThings not addressed:\\n - The risk analysis is still not relevant. The authors removed a clearly flawed sentence, but the analysis still assumes that two densities (of 'good' and 'bad' examples) are modeled, while in the work presented only one of them is. Hence this analysis does not add anything to the paper-  it states a general case which does not fit the current scenario and its relation to the work is not clear. It would have been better to omit it and use the space to describe HDDA and the specific variant used in this work, as this is the main tool doing the distinction.\\n\\nI believe the paper should be accepted.\\n\"</td>\n",
       "      <td>3</td>\n",
       "      <td>HyI6s40a-.json</td>\n",
       "      <td>28.766</td>\n",
       "      <td>8.781</td>\n",
       "      <td>328.435</td>\n",
       "      <td>12.728</td>\n",
       "      <td>-0.933</td>\n",
       "      <td>1.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>\"The paper introduces a new memory mechanism specifically tailored for agent navigation in 2D environments. The memory consists of a 2D array and includes trainable read/write mechanisms. The RL agent's policy is a function of the context read, read, and next step write vectors (which are functions of the observation). The effectiveness of the proposed architecture is evaluated via reinforcement learning (% of mazes solved). The evaluation included 1000 test mazes--which sets a good precedent for evaluation in this subfield. \\n\\nMy main concern is the lack of experiments to test whether the agent really learned to localize and plan routes using it's memory architecture. The downsampling experiment in Section 5.1 seems to indicate the contrary: downsampling the memory should lead to position aliasing which seems to indicate that the agent is not using its memory to store the map and its own location. I'm concerned whether the proposed agent is actually employing a navigation strategy, as seems to be suggested, or is simply a good agent architecture for this task (e.g. for optimization reasons). The short experiment in Appendix E seems to try and answer this question, but it's results are anecdotal at best. \\n\\nIf good RL performance on navigation tasks is the ultimate goal then one can imagine an agent that directly copies the raw map observation (world centric) into memory and use something like a value iteration network or shortest path planning to plan routes. My point is that there are classical algorithms to solve navigation even in partially observable 2D grid worlds, why bother with deep RL here? \"</td>\n",
       "      <td>4</td>\n",
       "      <td>Bk9zbyZCZ.json</td>\n",
       "      <td>3.718</td>\n",
       "      <td>1.993</td>\n",
       "      <td>42.942</td>\n",
       "      <td>2.504</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>3.453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RECOMMENDATION  \\\n",
       "0  7                \n",
       "1  4                \n",
       "2  3                \n",
       "3  7                \n",
       "4  7                \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              comments  \\\n",
       "0  \"Summary: \\nThe authors present a simple variation of vanilla recurrent neural networks, which use ReLU hiddens and a fixed identity matrix that is added to the hidden-to-hidden weight matrix. This identity connection acts as a \\u201csurrogate memory\\u201d component, preserving hidden activations over time steps. \\nThe experiments demonstrate that this architecture reliably solves the addition task for up to 400 input frames. It also achieves a very good performance on sequential and permuted MNIST and achieves SOTA performance on bAbI.\\nThe authors observe that the proposed recurrent identity network (RIN) is relatively robust to hyperparameter choices. After Le et al. (2015), the paper presents another convincing case for the application of ReLUs in RNNs.\\n\\nReview: \\nI very much like the paper. The motivation and architecture is presented very clearly and I am happy to also see explorations of simpler recurrent architectures in parallel to research of gated architectures!\\nI have a few comments and questions:\\n1) Clarification: In Section 2.2, do you really mean bit-wise multiplication or element-wise? If bit-wise, can you elaborate why? I might have missed something.\\n2) Why does the learning curve of the IRNN stop around epoch 270 in Figure 2c? Also some curves in the appendix stop abruptly without visible explosions. Were these experiments run until completion? If so, would it be possible to plot the complete curves?\\n3) I think for a fair comparison with LSTMs and IRNNs a limited hyperparameter search should be performed separately on all three architectures at least for the addition task. Optimal hyperparameters are usually model-specific. Admittedly, the authors mention that they do not intend to make claims about superior performance to LSTMs, however the competitive performance of small RINs is mentioned a couple of times in the manuscript.\\nLe et al. (2015) for instance perform a coarse grid search for each model.\\n4) I wouldn't say that ResNets are Gated Neural Networks, as the branches are just summed up. There is no (multiplicative) gating as in Highway Networks.\\n5) I think what enables the training of very deep networks or LSTMs on long sequences is the presence of a (close-to-)identity component in forward/backward propagation, not the gating. The use of ReLU activations in IRNNs (with identity initialization of the hidden-to-hidden weights) and RINs (effectively initialized with identity plus some noise) makes the recurrence more linear than with squashing activation functions.\\n6) Regarding the absence of gating in RINs: What is your intuition on how the model would perform in tasks for which conditional forgetting is useful. Consider for example a task with long sequences, outputs at every time step and hidden activations not necessarily being encouraged to estimate last step hidden activations. Would RINs readily learn to reset parts of the hidden state?\\n7) Henaff et al. (2016) might be related, as they are also looking into the addition task with long sequences.\\n\\nOverall, the presented idea is novel to the best of my knowledge and the manuscript is well-written. I would recommend it for acceptance, but would like to see the above points addressed (especially 1-3 and some comments on 4-6). After a revision I would consider to increase the score.\\n\\nReferences:\\nHenaff, Mikael, Arthur Szlam, and Yann LeCun. \\\"Recurrent orthogonal networks and long-memory tasks.\\\" In International Conference on Machine Learning, pp. 2034-2042. 2016.\\nLe, Quoc V., Navdeep Jaitly, and Geoffrey E. Hinton. \\\"A simple way to initialize recurrent networks of rectified linear units.\\\" arXiv preprint arXiv:1504.00941 (2015).\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "1  \"The paper entitled 'Siamese Survival Analysis' reports an application of a deep learning to three cases of competing risk survival analysis. The author follow the reasoning that '... these ideas were not explored in the context of survival analysis', thereby disregarding the significant published literature based on the Concordance Index (CI). \\n\\nBesides this deficit, the paper does not present a proper statistical setup (e.g. 'Is censoring assumed to be at random? ...) , and numerical results are only referring to some standard implementations, thereby again neglecting the state-of-the-art solution. That being said, this particular use of deep learning in this context might be novel.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "2  \"In this paper, the authors define a simulated, multi-agent \\u201ctaxi pickup\\u201d task in a GridWorld environment. In the task, there are multiple taxi agents that a model must learn to control. \\u201cCustomers\\u201d randomly appear throughout the task and the taxi agents receive reward for moving to the same square as a customer. Since there are multiple customer and taxi agents, there is a multi-agent coordination problem. Further, the taxi agents have \\u201cbatteries\\u201d, which starts at a positive number, ticks down by one on each time step and a large negative reward is given if this number reaches zero. The battery can be \\u201crecharged\\u201d by moving to a \\u201ccharge\\u201d tile.\\n\\nCooperative multi-agent problem solving is an important problem in machine learning, artificial intelligence, and cognitive science. This paper defines and examines an interesting cooperative problem: Assignment and control of agents to move to certain squares under \\u201cphysical\\u201d constraints. The authors propose a centralized solution to the problem by adapting the Deep Q-learning Network model. I do not know whether using a centralized network where each agent has a window of observations is a novel algorithm. The manuscript itself makes it difficult to assess (more on this later). If it were novel, it would be an incremental development. They assess their solution quantitatively, demonstrating their model performs better than first, a simple heuristic model (I believe de-centralized Dijkstra\\u2019s for each agent, but there is not enough description in the manuscript to know for sure), and then, two other baselines that I could not figure out from the manuscript (I believe it was Dijkstra\\u2019s with two added rules for when to recharge).\\n\\nAlthough the manuscript has many positive aspects to it, I do not believe it should be accepted for the following reasons. First, the manuscript is poorly written, to the point where it has inhibited my ability to assess it. Second, given its contribution, the manuscript is better suited for a conference specific to multi-agent decision-making. There are a few reasons for this. 1) I was not convinced that deep Q-learning was necessary to solve this problem. The manuscript would be much stronger if the authors compared their method to a more sophisticated baseline, for example having each agent be a simple Q-learner with no centralization or \\u201cdeepness\\u201d. This would solve another issue, which is the weakness of their baseline measure. There are many multi-agent techniques that can be applied to the problem that would have served as a better baseline. 2) Although the problem itself is interesting, it is a bit too applied and specific to the particular task they studied than is appropriate for a conference with as broad interests as ICLR. It also is a bit simplistic (I had expected the agents to at least need to learn to move the customer to some square rather than get reward and move to the next job from just getting to the customer\\u2019s square). Can you apply this method to other multi-agent problems? How would it compare to other methods on those problems? \\n\\nI encourage the authors to develop the problem and method further, as well as the analysis and evaluation. \\n\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "3  \"Summary:\\n The paper presents an unsupervised method for detecting adversarial examples of neural networks. The method includes two independent components: an \\u2018input defender\\u2019 which tried to inspect the input, and a \\u2018latent defender\\u2019 trying to inspect a hidden representation. Both are based on the claim that adversarial examples lie outside a certain sub-space occupied by the natural image examples, and modeling this sub-space hence enables their detection. The input defender is based on sparse coding, and the latent defender on modeling the latent activity as a mixture of Gaussians. Experiments are presented on MInst, Cifar10, and ImageNet.\\n \\n-\\tIntroduction: The motivation for detecting adversarial examples is not stated clearly enough. How can such examples be used by a malicious agent to cause damage to a system? Sketching some such scenarios would help the reader understand why the issue is practically important. I was not convinced it is. \\nPage 4: \\n-\\tStep 3 of the algorithm is not clear:\\no\\tHow exactly does HDDA model the data (formally) and how does it estimate the parameters? In the current version, the paper does not explain the HDDA formalism and learning algorithm, which is a main building block in the proposed system (as it provides the density score used for adversarial examples detection). Hence the paper cannot be read as a standalone document. I went on to read the relevant HDDA paper, but it is also not clear which of the model variants presented there is used in this paper.\\no\\tWhat is the relation between the model learned at stage 2 (the centers c^i) and the model learnt by HDDA? Are they completely different models? Or are the C^I used when learning the HDDA model (and how)? \\nIf these are separate models, how are they used in conjunction to give a final density score? If I understand correctly, only the HDDA model is used to get the final score, and the C^i are only used to make the \\\\phy(x) representation more class-seperable. Is that right?\\n-\\tFigure 4, b and c: it is not clear what the (x,y,z) measurements plotted in these 3D drawings are (what are the axis).\\nPage 5:\\n-\\tSection 2: the risk analysis is done in a standard Bayesian way and leads to a ratio of PDFs in equation 5. However, this form is not appropriate for the case presented at this paper, since the method presented only models one of these PDFs (Specifically p(x | W1)  - there is not generative model of p(x|W2)).  \\n-\\tThe authors claim in the last sentence of the section that p(x|W2) is equivalent to 1-p(x|W1), but this is not true: these are two continuous densities, they do not sum to 1, and a model of p(x|W2) is not available (as far as I understand the method)\\nPage 6:\\n-\\tHow is equation 7) optimized?\\n-\\tWhich patchs are extracted from images, for training and at inference time? Are these patchs a dense coverage of the image? Sparsely sampled? Densely sampled with overlaps?\\n-\\tIts not clear enough what exactly is the \\u2018PSNR\\u2019 value which is used for the adversarial example detection, and what exactly is \\u2018profile the PSNR of legitimate samples within each class\\u2019. A formal definition of PSNR and\\u2019profiling\\u2019 is missing (does profiling simply mean finding a threshold for filtering?)\\nPage 7:\\n-\\tFigure 7 is not very informative. Given the ROC curves in figure 8  and table 1 it is redundant. \\n\\nPage 8:\\n-\\tThe results in general indicate that the method is much better than chance, but it is not clear if it is practical, because the false alarm rates for high detection are quite high. For example on ImageNet, 14.2% of the innocent images are mistakenly rejected as malicious to get 90% detection rate. I do not think this working point is useful for a real application\\n-\\tGiven the high flares alarm rate, it is surprising that experiments with multiple checkpoints are not presented (specifically as this case of multiple checkpoints is discussed explicitly in previous sections of the paper).  Experiments with multiple checkpoints are clear required to complete the picture regarding the empirical performance of this method\\n-\\tThe experiments show that essentially, the latent defenders are stronger than the input defender in most cases. However, an ablation study of the latent defender is missing: Specifcially, it is not clear a) how much does stage 2 (model refinement with clusters)  contribute to the accuracy (how does the model do without it? And 3) how important is the HDDA and the specific variant used (which is not clear) important: is it important to model the Gaussians using a sub-space? Of which dimension?\\n\\nOverall:\\nPros:\\n-\\t A nice idea with some novelty,  based on a non-trivial observation\\n-\\tThe experimental results how the idea holds some promise\\nCons\\n-\\tThe method is not presented clearly enough: the main component modeling the network activity is not explained (the HDDA module used)\\n-\\tThe results presented show that the method is probably not suitable for a practical application yet (high false alarm rate for good detection rate)\\n-\\tExperimental results are partial: results are not presented for multiple defenders, no ablation experiments\\n\\n\\nAfter revision:\\nSome of my comments were addressed, and some were not.\\nSpecifically, results were presented for multiple defenders and some ablation experiments were highlihgted\\nThings not addressed:\\n - The risk analysis is still not relevant. The authors removed a clearly flawed sentence, but the analysis still assumes that two densities (of 'good' and 'bad' examples) are modeled, while in the work presented only one of them is. Hence this analysis does not add anything to the paper-  it states a general case which does not fit the current scenario and its relation to the work is not clear. It would have been better to omit it and use the space to describe HDDA and the specific variant used in this work, as this is the main tool doing the distinction.\\n\\nI believe the paper should be accepted.\\n\"   \n",
       "4  \"The paper introduces a new memory mechanism specifically tailored for agent navigation in 2D environments. The memory consists of a 2D array and includes trainable read/write mechanisms. The RL agent's policy is a function of the context read, read, and next step write vectors (which are functions of the observation). The effectiveness of the proposed architecture is evaluated via reinforcement learning (% of mazes solved). The evaluation included 1000 test mazes--which sets a good precedent for evaluation in this subfield. \\n\\nMy main concern is the lack of experiments to test whether the agent really learned to localize and plan routes using it's memory architecture. The downsampling experiment in Section 5.1 seems to indicate the contrary: downsampling the memory should lead to position aliasing which seems to indicate that the agent is not using its memory to store the map and its own location. I'm concerned whether the proposed agent is actually employing a navigation strategy, as seems to be suggested, or is simply a good agent architecture for this task (e.g. for optimization reasons). The short experiment in Appendix E seems to try and answer this question, but it's results are anecdotal at best. \\n\\nIf good RL performance on navigation tasks is the ultimate goal then one can imagine an agent that directly copies the raw map observation (world centric) into memory and use something like a value iteration network or shortest path planning to plan routes. My point is that there are classical algorithms to solve navigation even in partially observable 2D grid worlds, why bother with deep RL here? \"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "\n",
       "   CONFIDENCE              ID  Layer 1  Layer 1 N  Layer 2  Layer 2 N  \\\n",
       "0  4           Hyp3i2xRb.json  16.587   5.481      142.202  6.059       \n",
       "1  5           HkjL6MiTb.json  1.280    1.332      9.568    1.309       \n",
       "2  3           B1EGg7ZCb.json  11.172   4.013      160.306  6.707       \n",
       "3  3           HyI6s40a-.json  28.766   8.781      328.435  12.728      \n",
       "4  4           Bk9zbyZCZ.json  3.718    1.993      42.942   2.504       \n",
       "\n",
       "   Layer 3  Layer 3 N  \n",
       "0  0.044    5.699      \n",
       "1 -0.340    3.968      \n",
       "2 -0.672    2.478      \n",
       "3 -0.933    1.299      \n",
       "4 -0.455    3.453      "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exhaustiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_l = reviews[reviews['Layer 1 N'] < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_g = reviews[reviews['Layer 1 N'] > 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECOMMENDATION</th>\n",
       "      <th>comments</th>\n",
       "      <th>CONFIDENCE</th>\n",
       "      <th>Layer 1</th>\n",
       "      <th>Layer 1 N</th>\n",
       "      <th>Layer 2</th>\n",
       "      <th>Layer 2 N</th>\n",
       "      <th>Layer 3</th>\n",
       "      <th>Layer 3 N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>\"The paper entitled 'Siamese Survival Analysis' reports an application of a deep learning to three cases of competing risk survival analysis. The author follow the reasoning that '... these ideas were not explored in the context of survival analysis', thereby disregarding the significant published literature based on the Concordance Index (CI). \\n\\nBesides this deficit, the paper does not present a proper statistical setup (e.g. 'Is censoring assumed to be at random? ...) , and numerical results are only referring to some standard implementations, thereby again neglecting the state-of-the-art solution. That being said, this particular use of deep learning in this context might be novel.\"</td>\n",
       "      <td>5</td>\n",
       "      <td>1.280</td>\n",
       "      <td>1.332</td>\n",
       "      <td>9.568</td>\n",
       "      <td>1.309</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>-0.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>\"The paper introduces a new memory mechanism specifically tailored for agent navigation in 2D environments. The memory consists of a 2D array and includes trainable read/write mechanisms. The RL agent's policy is a function of the context read, read, and next step write vectors (which are functions of the observation). The effectiveness of the proposed architecture is evaluated via reinforcement learning (% of mazes solved). The evaluation included 1000 test mazes--which sets a good precedent for evaluation in this subfield. \\n\\nMy main concern is the lack of experiments to test whether the agent really learned to localize and plan routes using it's memory architecture. The downsampling experiment in Section 5.1 seems to indicate the contrary: downsampling the memory should lead to position aliasing which seems to indicate that the agent is not using its memory to store the map and its own location. I'm concerned whether the proposed agent is actually employing a navigation strategy, as seems to be suggested, or is simply a good agent architecture for this task (e.g. for optimization reasons). The short experiment in Appendix E seems to try and answer this question, but it's results are anecdotal at best. \\n\\nIf good RL performance on navigation tasks is the ultimate goal then one can imagine an agent that directly copies the raw map observation (world centric) into memory and use something like a value iteration network or shortest path planning to plan routes. My point is that there are classical algorithms to solve navigation even in partially observable 2D grid worlds, why bother with deep RL here? \"</td>\n",
       "      <td>4</td>\n",
       "      <td>3.718</td>\n",
       "      <td>1.993</td>\n",
       "      <td>42.942</td>\n",
       "      <td>2.504</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>-0.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>\"This paper introduces bi-directional block self-attention model (Bi-BioSAN) as a general-purpose encoder for sequence modeling tasks in NLP. The experiments include tasks like natural language inference, reading comprehension (SquAD), semantic relatedness and sentence classifications. The new model shows decent performance when comparing with Bi-LSTM, CNN and other baselines while running at a reasonably fast speed.\\n\\nThe advantage of this model is that we can use little memory (as in RNNs) and enjoy the parallelizable computation as in (SANs), and achieve similar (or better) performance.\\n\\nWhile I do appreciate the solid experiment section, I don't think the model itself is sufficient contribution for a publication at ICLR. First, there is not much innovation in the model architecture. The idea of the Bi-BioSAN model simply to split the sentence into blocks and compute self-attention for each of them, and then using the same mechanisms as a pooling operation followed by a fusion level. I think this more counts as careful engineering of the SAN model rather than a main innovation. Second, the model introduces much more parameters. In the experiments, it can easily use 2 times parameters than the commonly used encoders. What if we use the same amount of parameters for Bi-LSTM encoders? Will the gap between the new model and the commonly used ones be smaller?\\n\\n====\\n\\nI appreciate the answers the authors added and I change the score to 6.\"</td>\n",
       "      <td>4</td>\n",
       "      <td>3.445</td>\n",
       "      <td>1.919</td>\n",
       "      <td>37.242</td>\n",
       "      <td>2.300</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>-0.221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>\"In this paper, the authors studied the problem of semi-supervised few-shot classification, by extending the prototypical networks into the setting of semi-supervised learning with examples from distractor classes.  The studied problem is interesting, and the paper is well-written. Extensive experiments are performed to demonstrate the effectiveness of the proposed methods.  While the proposed method is a natural extension of the existing works (i.e., soft k-means and meta-learning).On top of that, It seems the authors have over-claimed their model capability at the first place as the proposed model cannot properly classify the distractor examples but just only consider them as a single class of outliers. Overall, I would like to vote for a weakly acceptance regarding this paper.\"</td>\n",
       "      <td>4</td>\n",
       "      <td>2.072</td>\n",
       "      <td>1.547</td>\n",
       "      <td>22.502</td>\n",
       "      <td>1.772</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>\"I only got access to the paper after the review deadline; and did not have a chance to read it until now. Hence the lateness and brevity.\\n\\nThe paper tackles an important theoretical question; and it offers results that are complementary to existing results (e.g., Soudry et al). However, the paper does not properly relate their results, assumptions in the context of the existing literature. Much explanation is needed in the author reply in order to clear these questions.\\n\\nThe work should not be evaluated from a practical perspective as it is of a theoretical nature.\\n\\nI agree with most of the criticism raised by other reviewers. However, I also believe the authors managed to clear essentially of the criticism in they reply. The paper lacks in clarity as currently written. \\n\\nThe results are interesting, but more explanation is needed for the main message to be conveyed more clearly. I suggest 7, but the paper has a potential to become 8 in my eyes in a future resubmission.\\n\"</td>\n",
       "      <td>4</td>\n",
       "      <td>2.607</td>\n",
       "      <td>1.692</td>\n",
       "      <td>26.111</td>\n",
       "      <td>1.902</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>\"This paper proposes an alternative to the relation network architecture whose computational complexity is linear in the number of objects present in the input. The model achieves good results on bAbI compared to memory networks and the relation network model. From what I understood, it works by computing a weighted average of sentence representations in the input story where the attention weights are the output of an MLP whose input is just a sentence and question (not two sentences and a question). This average is then fed to a softmax layer for answer prediction. I found it difficult to understand how the model is related to relation networks, since it no longer scores every combination of objects (or, in the case of bAbI, sentences), which is the fundamental idea behind relation networks. Why is the approach not evaluated on CLEVR, in which the interaction between two objects is perhaps more critical (and was the main result of the original relation networks paper)? The fact that the model works well on bAbI despite its simplicity is interesting, but it feels like the paper is framed to suggest that object-object interactions are not necessary to explicitly model, which I can't agree with based solely on bAbI experiments. I'd encourage the authors to do a more detailed experimental study with more tasks, but I can't recommend this paper's acceptance in its current form.\\n\\nother questions / comments:\\n- \\\"we use MLP to produce the attention weight without any extrinsic computation between the input sentence and the question.\\\" isn't this statement false because the attention computation takes as input the concatenation of the question and sentence representation?\\n- writing could be cleaned up for spelling / grammar (e.g., \\\"last 70 stories\\\" instead of \\\"last 70 sentences\\\"), currently the paper is very hard to read and it took me a while to understand the model\"</td>\n",
       "      <td>4</td>\n",
       "      <td>3.432</td>\n",
       "      <td>1.915</td>\n",
       "      <td>49.330</td>\n",
       "      <td>2.733</td>\n",
       "      <td>-0.583</td>\n",
       "      <td>-0.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6</td>\n",
       "      <td>\"- algorithm 1 has a lot of problem specific hyperparametes that may be difficult to get right. Not clear how important they are\\n- they analyze the simpler (analytically and likely computationally) Boolean hyperparameter case (each hyperparameter is binary). Not a realistic setting. In their experiments they use these binary parameter spaces so I'm not sure how much I buy that it is straightforward to use continuous valued polynomials. \\n- interesting idea but I think it's more theoretical than practical. Feels like a hammer in need of a nail. \"</td>\n",
       "      <td>3</td>\n",
       "      <td>1.016</td>\n",
       "      <td>1.261</td>\n",
       "      <td>22.572</td>\n",
       "      <td>1.775</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9</td>\n",
       "      <td>\"Congratulations on a very interesting and clear paper.  While ICLR is not focused on neuroscientific studies, this paper clearly belongs here as it shows what representations develop in recurrent networks that are trained on spatial navigation. Interestingly, these include representations that have been observed in mammals and that have attracted considerable attention, even honored with a Nobel prize. \\n\\nI found it is very interesting that the emergence of these representations was contingent on some regularization constraint. This seems similar to the visual domain where edge detectors emerge easily when trained on natural images with sparseness constraints as in Olshausen&amp;Field and later reproduced with many other models that incorporate sparseness constraints. \\n\\nI do have some questions about the training itself. The paper mentions a metabolic cost that is not specified in the paper. This should be added. \\n\\nMy biggest concern is about Figure 6a. I am puzzled why is the error is coming down before the boundary interaction? Even more puzzling, why does this error go up again for the blue curve (no interaction)? Shouldn\\u2019t at least this curve be smooth?\\n\"</td>\n",
       "      <td>4</td>\n",
       "      <td>3.232</td>\n",
       "      <td>1.861</td>\n",
       "      <td>43.019</td>\n",
       "      <td>2.507</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>-0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>9</td>\n",
       "      <td>\"This high-quality paper tackles the quadratic dependency of memory on sequence length in attention-based models, and presents strong empirical results across multiple evaluation tasks. The approach is basically to apply self-attention at two levels, such that each level only has a small, fixed number of items, thereby limiting the memory requirement while having negligible impact on speed. It captures local information into so-called blocks using self-attention, and then applies a second level of self-attention over the blocks themselves.\\n\\nThe paper is well organized and clearly written, modulo minor language mistakes that should be easy to fix with further proof-reading. The contextualization of the method relative to CNNs/RNNs/Transformers is good, and the beneficial trade-offs between memory, runtime and accuracy are thoroughly investigated, and they're compelling.\\n\\nI am curious how the story would look if one tried to push beyond two levels...? For example, how effective might a further inter-sentence attention level be for obtaining representations for long documents? \\n\\nMinor points:\\n- Text between Eq 4 &amp; 5: W^{(1)} appears twice; one instance should probably be W^{(2)}.\\n- Multiple locations, e.g. S4.1: for NLI, the word is *premise*, not *promise*.\\n- Missing word in first sentence of S4.1: ... reason __ the ...\"</td>\n",
       "      <td>4</td>\n",
       "      <td>1.736</td>\n",
       "      <td>1.456</td>\n",
       "      <td>22.195</td>\n",
       "      <td>1.761</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>-0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4</td>\n",
       "      <td>\"This paper presents an extension of binary networks, and the main idea is to use different bit rates for different layers so we can further reduce bitrate of the overall net, and achieve better performance (speed / memory). The paper addresses a real problem which is meaningful, and provides interesting insights, but it is more of an extension.\\n\\nThe description of the Heterogeneous Bitwidth Binarization algorithm is interesting and simple, and potentially can be practical, However it also adds more complication to real world implementations, and might not be an elegant enough approach for practical usages. \\n\\nExperiments wise, the paper has done solid experiments comparing with existing approaches and showed the gain. Results are promising.\\n\\nOverall, I am leaning towards a rejection mostly due to limited novelty. \\n\\n\"</td>\n",
       "      <td>4</td>\n",
       "      <td>2.269</td>\n",
       "      <td>1.600</td>\n",
       "      <td>21.480</td>\n",
       "      <td>1.736</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4</td>\n",
       "      <td>\"The paper proposes to address the quadratic memory/time requirement of Relation Network (RN) by sequentially attending (via multiple layers) on objects and gating the object vectors with the attention weights of each layer. The proposed model obtains state of the art in bAbI story-based QA and bAbI dialog task.\\n\\nPros:\\n- The model achieves the state of the art in bAbI QA and dialog. I think this is a significant achievement given the simplicity of the model.\\n- The paper is clearly written.\\n\\nCons:\\n- I am not sure what is novel in the proposed model. While the authors use notations used in Relation Network (e.g. 'g'), I don't see any relevance to Relation Network. Rather, this exactly resembles End-to-end memory network (MemN2N) and GMemN2N. Please tell me if I am missing something, but I am not sure of the contribution of the paper. Of course, I notice that there are small architectural differences, but if these are responsible for the improvements, I believe the authors should have conducted ablation study or qualitative analysis that show that the small tweaks are meaningful.\\n \\nQuestion:\\n- What is the exact contribution of the paper with respect to MemN2N and GMemN2N?\"</td>\n",
       "      <td>4</td>\n",
       "      <td>3.479</td>\n",
       "      <td>1.928</td>\n",
       "      <td>41.192</td>\n",
       "      <td>2.442</td>\n",
       "      <td>-0.546</td>\n",
       "      <td>-0.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>6</td>\n",
       "      <td>\"Pros: \\nThe paper proposes a \\u201cbi-directional block self-attention network (Bi-BloSAN)\\u201d for sequence encoding, which inherits the advantages of multi-head (Vaswani et al., 2017) and DiSAN (Shen et al., 2017) network but is claimed to be more memory-efficient. The paper is written clearly and is easy to follow. The source code is released for duplicability. The main originality is using block (or hierarchical) structures; i.e., the proposed models split the an entire sequence into blocks, apply an intra-block SAN to each block for modeling local context, and then apply an inter-block SAN to the output for all blocks to capture long-range dependency. The proposed model was tested on nine benchmarks  and achieve good efficiency-memory trade-off. \\n\\nCons:\\n- Methodology of the paper is very incremental compared with previous models.  \\n- Many of the baselines listed in the paper are not competitive; e.g.,  for SNLI, state-of-the-art results are not included in the paper. \\n- The paper argues advantages of the proposed models over CNN by assuming the latter only captures local dependency, which, however, is not supported by discussion on or comparison with hierarchical CNN.\\n- The block splitting (as detailed in appendix) is rather arbitrary in terms of that it potentially divides coherent language segments apart. This is unnatural, e.g., compared  with alternatives such as using linguistic segments as blocks.\\n- The main originality of paper is the block style. However, the paper doesn\\u2019t analyze how and why the block brings improvement. \\n-If we remove intra-block self-attention (but only keep token-level self-attention), whether the performance will be significantly worse?\\n\"</td>\n",
       "      <td>4</td>\n",
       "      <td>3.729</td>\n",
       "      <td>1.996</td>\n",
       "      <td>34.870</td>\n",
       "      <td>2.215</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>-0.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>8</td>\n",
       "      <td>\"The propose data augmentation and BC learning is relevant, much robust than frequency jitter or simple data augmentation. \\n\\nIn equation 2, please check the measure of the mixture. Why not simply use a dB criteria ?\\n\\nThe comments about applying a CNN to local features or novel approach to increase sound recognition could be completed with some ICLR 2017 work towards injected priors using Chirplet Transform.\\n\\nThe authors might discuss more how to extend their model to image recognition, or at least of other modalities as suggested.\\n\\nSection 3.2.2 shall be placed later on, and clarified.\\n\\nDiscussion on mixing more than two sounds leads could be completed by associative properties, we think... ?\\n\"</td>\n",
       "      <td>4</td>\n",
       "      <td>1.256</td>\n",
       "      <td>1.326</td>\n",
       "      <td>22.132</td>\n",
       "      <td>1.759</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>-0.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4</td>\n",
       "      <td>\"The paper proposes combining classification-specific neural networks with auto-encoders. This is done in a straightforward manner by designating a few nodes in the output layer for classification and few for reconstruction. The training objective is then changed to minimize the sum of the classification loss (as measured by cross-entropy for instance) and the reconstruction error (as measured by ell-2 error as is done in training auto-encoders). \\n\\nThe authors minimize the loss function by greedy layer-wise training as is done in several prior works. The authors then perform other experiments on the learned representations in the output layer (those corresponding to classification + those corresponding to reconstruction). For example, the authors plot the nearest-neighbors for classification-features and for reconstruction-features and observe that the two are very different. The authors also observe that interpolating between two reconstruction-feature vectors (by convex combinations) seems to interpolate well between the two corresponding images.\\n\\nWhile the experimental results are interesting they are not striking especially when viewed in the context of the tremendous amount of work on auto-encoders. Training the classification-features along with reconstruction-features does not seem to give any significantly new insights. \"</td>\n",
       "      <td>3</td>\n",
       "      <td>3.383</td>\n",
       "      <td>1.902</td>\n",
       "      <td>34.259</td>\n",
       "      <td>2.194</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>-0.237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\n\\nThis paper proposes to use deep reinforcement learning to solve a multiagent coordination task. In particular, the paper introduces a benchmark domain to model fleet coordination problems as might be encountered in taxi companies. \\n\\nThe paper does not really introduce new methods, and as such, this paper should be seen more as an application paper. I think that such a paper could have merits if it would really push the boundary of the feasible, but I do not think that is really the case with this paper: the task still seems quite simplistic, and the empirical evaluation is not convincing (limited analysis, weak baselines). As such, I do not really see any real grounds for acceptance.\\n\\nFinally, there are also many other weaknesses. The paper is quite poorly written in places, has poor formatting (citations are incorrect and half a bibtex entry is inlined), and is highly inadequate in its treatment of related work. For instance, there are many related papers on:\\n\\n-taxi fleet management (e.g., work by Pradeep Varakantham)\\n \\n-coordination in multi-robot systems for spatially distributed tasks (e.g., Gerkey and much work since)\\n\\n-scaling up multiagent reinforcement learning and multiagent MDPs (Guestrin et al 2002, Kok &amp; Vlassis 2006, etc.)\\n\\n-dealing with partial observability (work on decentralized POMDPs by Peshkin et al, 2000, Bernstein, Amato, etc.)\\n\\n-multiagent deep RL has been very active last 1-2 years. E.g., see other papers by Foerster, Sukhbataar, Omidshafiei\\n\\n\\nOverall, I see this as a paper which with improvements could make a nice workshop contribution, but not as a paper to be published at a top-tier venue.\\n\\n\"</td>\n",
       "      <td>5</td>\n",
       "      <td>2.932</td>\n",
       "      <td>1.780</td>\n",
       "      <td>43.046</td>\n",
       "      <td>2.508</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>7</td>\n",
       "      <td>\"In this work, the authors propose a procedure for tuning the parameters of an HMC algorithm (I guess, if I have understood correctly).\\n\\nI think this paper has a good and strong point: this work points out the difficulties in choosing properly the parameters in a HMC method (such as the step and the number of iterations in the leapfrog integrator, for instance). In the literature, specially in machine learning, there is ``fever\\u2019\\u2019 about HMC, in my opinion, partially unjustified.\\n\\nIf I have understood, your method is an adaptive HMC algorithm  where the parameters are updated online; or is the training  done in advance? Please, remark and clarify this point.\\n\\nHowever, I have other additional comments:\\n\\n- Eqs. (4) and (5) are quite complicated; I think a running toy example can help the interested reader.\\n\\n- I suggest to compare the proposed method to other efficient methods that do not use the gradient information (in some cases as multimodal posteriors, the use of the gradient information can be counter-productive for sampling purposes), such as Multiple Try Metropolis (MTM) schemes\\n\\nL. Martino, J. Read, On the flexibility of the design of Multiple Try Metropolis schemes, Computational Statistics, Volume 28, Issue 6, Pages: 2797-2823, 2013, \\n\\nadaptive techniques, \\n\\nH. Haario, E. Saksman, and J. Tamminen. An adaptive Metropolis algorithm. Bernoulli, 7(2):223\\u2013242, April 2001,\\n\\nand component-wise strategies as Gibbs Sampling, \\n\\nW. R. Gilks and P. Wild, Adaptive rejection sampling for Gibbs sampling, Appl. Statist., vol. 41, no. 2, pp. 337\\u2013348, 199.\\u2028\\n\\nAt least, add a brief paragraph in the introduction citing and discussing this possible alternatives.\"</td>\n",
       "      <td>4</td>\n",
       "      <td>2.702</td>\n",
       "      <td>1.718</td>\n",
       "      <td>29.453</td>\n",
       "      <td>2.021</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>3</td>\n",
       "      <td>\"The paper proposes training an autoencoder such that the middle layer representation consists of the class label of the input and a hidden vector representation called \\\"style memory\\\", which would presumably capture non-class information. The idea of learning representations that decompose into class-specific and class-agnostic parts, and more generally \\\"style\\\" and \\\"content\\\", is an interesting and long-standing problem. The results in the paper are mostly qualitative and only on MNIST. They do not show convincingly that the network managed to learn interesting class-specific and class-agnostic representations. It's not clear whether the examples shown in figures 7 to 11 are representative of the network's general behavior. The tSNE visualization in figure 6 seems to indicate that the style memory representation does not capture class information as well as the raw pixels, but doesn't indicate whether that representation is sensible.\\n\\nThe use of fully connected networks on images may affect the quality of the learned representations, and it may be necessary to use convolutional networks to get interesting results. It may also be interesting to consider class-specific representations that are more general than just the class label. For example, see \\\"Learning a Nonlinear Embedding by Preserving Class Neighbourhood Structure\\\" by Salakhutdinov and Hinton, 2007, which learns hidden vector representations for both class-specific and class-agnostic parts. (This paper should be cited.)\"</td>\n",
       "      <td>5</td>\n",
       "      <td>3.712</td>\n",
       "      <td>1.991</td>\n",
       "      <td>28.519</td>\n",
       "      <td>1.988</td>\n",
       "      <td>-0.342</td>\n",
       "      <td>-0.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>6</td>\n",
       "      <td>\"Pros:\\n1. A new DNA structure GAN is utilized to manipulate/disentangle attributes.\\n\\n2. Non attribute part (Z) is explicitly modeled in the framework.\\n\\n3. Based on the experiment results, this proposed method outperformed previous methods (TD-GAN, IcGAN).\\n\\nCons:\\n1. It assumes that each individual piece represents an independent factor of variation, which can not hold all the time. The authors also admit that when two factors are dependent, this method might fail.\\n\\n2. In Lreconstruct, only min difference between A and A1 is considered. How about A and A2 here? It seems that A2 should also be similar with A since only one bit in A2 and A1 is different.\\n\\n3. Only one attribute can be \\\"manipulated\\\" each time? Is it possible to change more than one attribute each time in this method?\"</td>\n",
       "      <td>5</td>\n",
       "      <td>2.664</td>\n",
       "      <td>1.707</td>\n",
       "      <td>18.986</td>\n",
       "      <td>1.647</td>\n",
       "      <td>-0.473</td>\n",
       "      <td>-0.473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>6</td>\n",
       "      <td>\"The paper proposed a generalized HMC by modifying the leapfrog integrator using neural networks to make the sampler to converge and mix quickly. Mixing is one of the most challenge problems for a MCMC sampler, particularly when there are many modes in a distribution. The derivations look correct to me. In the experiments, the proposed algorithm was compared to other methods, e.g., A-NICE-MC and HMC. It showed that the proposed method could mix between the modes in the posterior. Although the method could mix well when applied to those particular experiments, it lacks theoretical justifications why the method could mix well. \"</td>\n",
       "      <td>3</td>\n",
       "      <td>1.969</td>\n",
       "      <td>1.519</td>\n",
       "      <td>23.844</td>\n",
       "      <td>1.821</td>\n",
       "      <td>-0.596</td>\n",
       "      <td>-0.596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>5</td>\n",
       "      <td>\"This paper proposes a tensor train decomposition with a ring structure for function approximation and data compression. Most of the techniques used are well-known in the tensor community (outside of machine learning). The main contribution of the paper is the introduce such techniques to the ML community and presents experimental results for support.\\n\\nThe paper is rather preliminary in its examination. For example, it is claimed that the proposed decomposition provides \\\"enhanced representation ability\\\", but this is not justified rigorously either via more comprehensive experimentation or via a theoretical justification. Furthermore, the paper lacks in novelty aspect, as it is uses mostly well-known techniques. \"</td>\n",
       "      <td>4</td>\n",
       "      <td>2.298</td>\n",
       "      <td>1.608</td>\n",
       "      <td>22.865</td>\n",
       "      <td>1.786</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>-0.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>7</td>\n",
       "      <td>\"The paper proposes to learn a custom translation or rotation invariant kernel in the Fourier representation to maximize the margin of SVM. Instead of using Monte Carlo approximation as in the traditional random features literature, the main point of the paper is to learn these Fourier features in a min-max sense. This perspective leads to some interesting theoretical results and some new interpretation. Synthetic and some simple real-world experiments demonstrate the effectiveness of the algorithm compared to random features given the fix number of bases.\\n\\nI like the idea of trying to formulate the feature learning problem as a two-player min-max game and its connection to boosting. As for the related work, it seems the authors have missed some very relevant pieces of work in learning these Fourier features through gradient descent [1, 2]. It would be interesting to compare these algorithms as well.\\n\\n[1] Zichao Yang, Marcin Moczulski, Misha Denil, Nando de Freitas, Alex Smola, Le Song, Ziyu Wang. Deep Fried Convnets. ICCV 2015.\\n[2] Zichao Yang, Alexander J. Smola, Le Song, Andrew Gordon Wilson. A la Carte \\u2014 Learning Fast Kernels. AISTATS 2015.\"</td>\n",
       "      <td>3</td>\n",
       "      <td>3.279</td>\n",
       "      <td>1.874</td>\n",
       "      <td>23.452</td>\n",
       "      <td>1.807</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>4</td>\n",
       "      <td>\"The majority of the paper is focused on the observation that (1) making policies that condition on the time step is important in finite horizon problems, and a much smaller component on that (2) if episodes are terminated early during learning (say to restart and promote exploration) that the values should be bootstrapped to reflect that there will be additional rewards received in the true infinite-horizon setting.\\n\\n1 is true and is well known. This is typically described as finite horizon MDP planning and learning and the optimal policy is well known to be nonstationary and depend on the number of remaining time steps. There are a number of papers focusing on this for both planning and learning though these are not cited in the current draft. \\n\\nI don\\u2019t immediately know of work that suggests bootstrapping if an episode is terminated early artificially during training but it seems a very reasonable and straightforward thing to do. \\n\\n\"</td>\n",
       "      <td>5</td>\n",
       "      <td>0.854</td>\n",
       "      <td>1.217</td>\n",
       "      <td>10.572</td>\n",
       "      <td>1.345</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>7</td>\n",
       "      <td>\"The paper presents a novel representation of graphs as multi-channel image-like structures. These structures are extrapolated  by \\n1) mapping the graph nodes into an embedding using an algorithm like node2vec\\n2) compressing the embedding space using pca\\n3) and extracting 2D slices from the compressed space and computing 2D histograms per slice.\\nhe resulting multi-channel image-like structures are then feed into vanilla 2D CNN.\\n  \\nThe papers is well written and clear, and proposes an interesting idea of representing graphs as multi-channel image-like structures. Furthermore, the authors perform experiments with real graph datasets from the social science domain and a comparison with the SoA method both graph kernels and deep learning architectures. The proposed algorithm in 3 out of 5 datasets, two of theme with statistical significant.\"</td>\n",
       "      <td>3</td>\n",
       "      <td>2.031</td>\n",
       "      <td>1.536</td>\n",
       "      <td>21.920</td>\n",
       "      <td>1.752</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>6</td>\n",
       "      <td>\"The authors present an algorithm for training ensembles of policy networks that regularly mixes different policies in the ensemble together by distilling a mixture of two policies into a single policy network, adding it to the ensemble and selecting the strongest networks to remain (under certain definitions of a \\\"strong\\\" network). The experiments compare favorably against PPO and A2C baselines on a variety of MuJoCo tasks, although I would appreciate a wall-time comparison as well, as training the \\\"crossover\\\" network is presumably time-consuming.\\n\\nIt seems that for much of the paper, the authors could dispense with the genetic terminology altogether - and I mean that as a compliment. There are few if any valuable ideas in the field of evolutionary computing and I am glad to see the authors use sensible gradient-based learning for GPO, even if it makes it depart from what many in the field would consider \\\"evolutionary\\\" computing. Another point on terminology that is important to emphasize - the method for training the crossover network by direct supervised learning from expert trajectories is technically not imitation learning but behavioral cloning. I would perhaps even call this a distillation network rather than a crossover network. In many robotics tasks behavioral cloning is known for overfitting to expert trajectories, but that may not be a problem in this setting as \\\"expert\\\" trajectories can be generated in unlimited quantities.\"</td>\n",
       "      <td>4</td>\n",
       "      <td>2.216</td>\n",
       "      <td>1.586</td>\n",
       "      <td>24.164</td>\n",
       "      <td>1.832</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>-0.332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RECOMMENDATION  \\\n",
       "1   4                \n",
       "4   7                \n",
       "6   6                \n",
       "7   6                \n",
       "16  7                \n",
       "17  4                \n",
       "23  6                \n",
       "25  9                \n",
       "36  9                \n",
       "37  4                \n",
       "41  4                \n",
       "43  6                \n",
       "45  8                \n",
       "50  4                \n",
       "53  3                \n",
       "62  7                \n",
       "69  3                \n",
       "70  6                \n",
       "72  6                \n",
       "73  5                \n",
       "74  7                \n",
       "75  4                \n",
       "76  7                \n",
       "80  6                \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        comments  \\\n",
       "1   \"The paper entitled 'Siamese Survival Analysis' reports an application of a deep learning to three cases of competing risk survival analysis. The author follow the reasoning that '... these ideas were not explored in the context of survival analysis', thereby disregarding the significant published literature based on the Concordance Index (CI). \\n\\nBesides this deficit, the paper does not present a proper statistical setup (e.g. 'Is censoring assumed to be at random? ...) , and numerical results are only referring to some standard implementations, thereby again neglecting the state-of-the-art solution. That being said, this particular use of deep learning in this context might be novel.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "4   \"The paper introduces a new memory mechanism specifically tailored for agent navigation in 2D environments. The memory consists of a 2D array and includes trainable read/write mechanisms. The RL agent's policy is a function of the context read, read, and next step write vectors (which are functions of the observation). The effectiveness of the proposed architecture is evaluated via reinforcement learning (% of mazes solved). The evaluation included 1000 test mazes--which sets a good precedent for evaluation in this subfield. \\n\\nMy main concern is the lack of experiments to test whether the agent really learned to localize and plan routes using it's memory architecture. The downsampling experiment in Section 5.1 seems to indicate the contrary: downsampling the memory should lead to position aliasing which seems to indicate that the agent is not using its memory to store the map and its own location. I'm concerned whether the proposed agent is actually employing a navigation strategy, as seems to be suggested, or is simply a good agent architecture for this task (e.g. for optimization reasons). The short experiment in Appendix E seems to try and answer this question, but it's results are anecdotal at best. \\n\\nIf good RL performance on navigation tasks is the ultimate goal then one can imagine an agent that directly copies the raw map observation (world centric) into memory and use something like a value iteration network or shortest path planning to plan routes. My point is that there are classical algorithms to solve navigation even in partially observable 2D grid worlds, why bother with deep RL here? \"                                                                                                                                                                                                                                                                                \n",
       "6   \"This paper introduces bi-directional block self-attention model (Bi-BioSAN) as a general-purpose encoder for sequence modeling tasks in NLP. The experiments include tasks like natural language inference, reading comprehension (SquAD), semantic relatedness and sentence classifications. The new model shows decent performance when comparing with Bi-LSTM, CNN and other baselines while running at a reasonably fast speed.\\n\\nThe advantage of this model is that we can use little memory (as in RNNs) and enjoy the parallelizable computation as in (SANs), and achieve similar (or better) performance.\\n\\nWhile I do appreciate the solid experiment section, I don't think the model itself is sufficient contribution for a publication at ICLR. First, there is not much innovation in the model architecture. The idea of the Bi-BioSAN model simply to split the sentence into blocks and compute self-attention for each of them, and then using the same mechanisms as a pooling operation followed by a fusion level. I think this more counts as careful engineering of the SAN model rather than a main innovation. Second, the model introduces much more parameters. In the experiments, it can easily use 2 times parameters than the commonly used encoders. What if we use the same amount of parameters for Bi-LSTM encoders? Will the gap between the new model and the commonly used ones be smaller?\\n\\n====\\n\\nI appreciate the answers the authors added and I change the score to 6.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "7   \"In this paper, the authors studied the problem of semi-supervised few-shot classification, by extending the prototypical networks into the setting of semi-supervised learning with examples from distractor classes.  The studied problem is interesting, and the paper is well-written. Extensive experiments are performed to demonstrate the effectiveness of the proposed methods.  While the proposed method is a natural extension of the existing works (i.e., soft k-means and meta-learning).On top of that, It seems the authors have over-claimed their model capability at the first place as the proposed model cannot properly classify the distractor examples but just only consider them as a single class of outliers. Overall, I would like to vote for a weakly acceptance regarding this paper.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "16  \"I only got access to the paper after the review deadline; and did not have a chance to read it until now. Hence the lateness and brevity.\\n\\nThe paper tackles an important theoretical question; and it offers results that are complementary to existing results (e.g., Soudry et al). However, the paper does not properly relate their results, assumptions in the context of the existing literature. Much explanation is needed in the author reply in order to clear these questions.\\n\\nThe work should not be evaluated from a practical perspective as it is of a theoretical nature.\\n\\nI agree with most of the criticism raised by other reviewers. However, I also believe the authors managed to clear essentially of the criticism in they reply. The paper lacks in clarity as currently written. \\n\\nThe results are interesting, but more explanation is needed for the main message to be conveyed more clearly. I suggest 7, but the paper has a potential to become 8 in my eyes in a future resubmission.\\n\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "17  \"This paper proposes an alternative to the relation network architecture whose computational complexity is linear in the number of objects present in the input. The model achieves good results on bAbI compared to memory networks and the relation network model. From what I understood, it works by computing a weighted average of sentence representations in the input story where the attention weights are the output of an MLP whose input is just a sentence and question (not two sentences and a question). This average is then fed to a softmax layer for answer prediction. I found it difficult to understand how the model is related to relation networks, since it no longer scores every combination of objects (or, in the case of bAbI, sentences), which is the fundamental idea behind relation networks. Why is the approach not evaluated on CLEVR, in which the interaction between two objects is perhaps more critical (and was the main result of the original relation networks paper)? The fact that the model works well on bAbI despite its simplicity is interesting, but it feels like the paper is framed to suggest that object-object interactions are not necessary to explicitly model, which I can't agree with based solely on bAbI experiments. I'd encourage the authors to do a more detailed experimental study with more tasks, but I can't recommend this paper's acceptance in its current form.\\n\\nother questions / comments:\\n- \\\"we use MLP to produce the attention weight without any extrinsic computation between the input sentence and the question.\\\" isn't this statement false because the attention computation takes as input the concatenation of the question and sentence representation?\\n- writing could be cleaned up for spelling / grammar (e.g., \\\"last 70 stories\\\" instead of \\\"last 70 sentences\\\"), currently the paper is very hard to read and it took me a while to understand the model\"   \n",
       "23  \"- algorithm 1 has a lot of problem specific hyperparametes that may be difficult to get right. Not clear how important they are\\n- they analyze the simpler (analytically and likely computationally) Boolean hyperparameter case (each hyperparameter is binary). Not a realistic setting. In their experiments they use these binary parameter spaces so I'm not sure how much I buy that it is straightforward to use continuous valued polynomials. \\n- interesting idea but I think it's more theoretical than practical. Feels like a hammer in need of a nail. \"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "25  \"Congratulations on a very interesting and clear paper.  While ICLR is not focused on neuroscientific studies, this paper clearly belongs here as it shows what representations develop in recurrent networks that are trained on spatial navigation. Interestingly, these include representations that have been observed in mammals and that have attracted considerable attention, even honored with a Nobel prize. \\n\\nI found it is very interesting that the emergence of these representations was contingent on some regularization constraint. This seems similar to the visual domain where edge detectors emerge easily when trained on natural images with sparseness constraints as in Olshausen&Field and later reproduced with many other models that incorporate sparseness constraints. \\n\\nI do have some questions about the training itself. The paper mentions a metabolic cost that is not specified in the paper. This should be added. \\n\\nMy biggest concern is about Figure 6a. I am puzzled why is the error is coming down before the boundary interaction? Even more puzzling, why does this error go up again for the blue curve (no interaction)? Shouldn\\u2019t at least this curve be smooth?\\n\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "36  \"This high-quality paper tackles the quadratic dependency of memory on sequence length in attention-based models, and presents strong empirical results across multiple evaluation tasks. The approach is basically to apply self-attention at two levels, such that each level only has a small, fixed number of items, thereby limiting the memory requirement while having negligible impact on speed. It captures local information into so-called blocks using self-attention, and then applies a second level of self-attention over the blocks themselves.\\n\\nThe paper is well organized and clearly written, modulo minor language mistakes that should be easy to fix with further proof-reading. The contextualization of the method relative to CNNs/RNNs/Transformers is good, and the beneficial trade-offs between memory, runtime and accuracy are thoroughly investigated, and they're compelling.\\n\\nI am curious how the story would look if one tried to push beyond two levels...? For example, how effective might a further inter-sentence attention level be for obtaining representations for long documents? \\n\\nMinor points:\\n- Text between Eq 4 & 5: W^{(1)} appears twice; one instance should probably be W^{(2)}.\\n- Multiple locations, e.g. S4.1: for NLI, the word is *premise*, not *promise*.\\n- Missing word in first sentence of S4.1: ... reason __ the ...\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "37  \"This paper presents an extension of binary networks, and the main idea is to use different bit rates for different layers so we can further reduce bitrate of the overall net, and achieve better performance (speed / memory). The paper addresses a real problem which is meaningful, and provides interesting insights, but it is more of an extension.\\n\\nThe description of the Heterogeneous Bitwidth Binarization algorithm is interesting and simple, and potentially can be practical, However it also adds more complication to real world implementations, and might not be an elegant enough approach for practical usages. \\n\\nExperiments wise, the paper has done solid experiments comparing with existing approaches and showed the gain. Results are promising.\\n\\nOverall, I am leaning towards a rejection mostly due to limited novelty. \\n\\n\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "41  \"The paper proposes to address the quadratic memory/time requirement of Relation Network (RN) by sequentially attending (via multiple layers) on objects and gating the object vectors with the attention weights of each layer. The proposed model obtains state of the art in bAbI story-based QA and bAbI dialog task.\\n\\nPros:\\n- The model achieves the state of the art in bAbI QA and dialog. I think this is a significant achievement given the simplicity of the model.\\n- The paper is clearly written.\\n\\nCons:\\n- I am not sure what is novel in the proposed model. While the authors use notations used in Relation Network (e.g. 'g'), I don't see any relevance to Relation Network. Rather, this exactly resembles End-to-end memory network (MemN2N) and GMemN2N. Please tell me if I am missing something, but I am not sure of the contribution of the paper. Of course, I notice that there are small architectural differences, but if these are responsible for the improvements, I believe the authors should have conducted ablation study or qualitative analysis that show that the small tweaks are meaningful.\\n \\nQuestion:\\n- What is the exact contribution of the paper with respect to MemN2N and GMemN2N?\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "43  \"Pros: \\nThe paper proposes a \\u201cbi-directional block self-attention network (Bi-BloSAN)\\u201d for sequence encoding, which inherits the advantages of multi-head (Vaswani et al., 2017) and DiSAN (Shen et al., 2017) network but is claimed to be more memory-efficient. The paper is written clearly and is easy to follow. The source code is released for duplicability. The main originality is using block (or hierarchical) structures; i.e., the proposed models split the an entire sequence into blocks, apply an intra-block SAN to each block for modeling local context, and then apply an inter-block SAN to the output for all blocks to capture long-range dependency. The proposed model was tested on nine benchmarks  and achieve good efficiency-memory trade-off. \\n\\nCons:\\n- Methodology of the paper is very incremental compared with previous models.  \\n- Many of the baselines listed in the paper are not competitive; e.g.,  for SNLI, state-of-the-art results are not included in the paper. \\n- The paper argues advantages of the proposed models over CNN by assuming the latter only captures local dependency, which, however, is not supported by discussion on or comparison with hierarchical CNN.\\n- The block splitting (as detailed in appendix) is rather arbitrary in terms of that it potentially divides coherent language segments apart. This is unnatural, e.g., compared  with alternatives such as using linguistic segments as blocks.\\n- The main originality of paper is the block style. However, the paper doesn\\u2019t analyze how and why the block brings improvement. \\n-If we remove intra-block self-attention (but only keep token-level self-attention), whether the performance will be significantly worse?\\n\"                                                                                                                                                                                          \n",
       "45  \"The propose data augmentation and BC learning is relevant, much robust than frequency jitter or simple data augmentation. \\n\\nIn equation 2, please check the measure of the mixture. Why not simply use a dB criteria ?\\n\\nThe comments about applying a CNN to local features or novel approach to increase sound recognition could be completed with some ICLR 2017 work towards injected priors using Chirplet Transform.\\n\\nThe authors might discuss more how to extend their model to image recognition, or at least of other modalities as suggested.\\n\\nSection 3.2.2 shall be placed later on, and clarified.\\n\\nDiscussion on mixing more than two sounds leads could be completed by associative properties, we think... ?\\n\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "50  \"The paper proposes combining classification-specific neural networks with auto-encoders. This is done in a straightforward manner by designating a few nodes in the output layer for classification and few for reconstruction. The training objective is then changed to minimize the sum of the classification loss (as measured by cross-entropy for instance) and the reconstruction error (as measured by ell-2 error as is done in training auto-encoders). \\n\\nThe authors minimize the loss function by greedy layer-wise training as is done in several prior works. The authors then perform other experiments on the learned representations in the output layer (those corresponding to classification + those corresponding to reconstruction). For example, the authors plot the nearest-neighbors for classification-features and for reconstruction-features and observe that the two are very different. The authors also observe that interpolating between two reconstruction-feature vectors (by convex combinations) seems to interpolate well between the two corresponding images.\\n\\nWhile the experimental results are interesting they are not striking especially when viewed in the context of the tremendous amount of work on auto-encoders. Training the classification-features along with reconstruction-features does not seem to give any significantly new insights. \"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "53  \"\\n\\nThis paper proposes to use deep reinforcement learning to solve a multiagent coordination task. In particular, the paper introduces a benchmark domain to model fleet coordination problems as might be encountered in taxi companies. \\n\\nThe paper does not really introduce new methods, and as such, this paper should be seen more as an application paper. I think that such a paper could have merits if it would really push the boundary of the feasible, but I do not think that is really the case with this paper: the task still seems quite simplistic, and the empirical evaluation is not convincing (limited analysis, weak baselines). As such, I do not really see any real grounds for acceptance.\\n\\nFinally, there are also many other weaknesses. The paper is quite poorly written in places, has poor formatting (citations are incorrect and half a bibtex entry is inlined), and is highly inadequate in its treatment of related work. For instance, there are many related papers on:\\n\\n-taxi fleet management (e.g., work by Pradeep Varakantham)\\n \\n-coordination in multi-robot systems for spatially distributed tasks (e.g., Gerkey and much work since)\\n\\n-scaling up multiagent reinforcement learning and multiagent MDPs (Guestrin et al 2002, Kok & Vlassis 2006, etc.)\\n\\n-dealing with partial observability (work on decentralized POMDPs by Peshkin et al, 2000, Bernstein, Amato, etc.)\\n\\n-multiagent deep RL has been very active last 1-2 years. E.g., see other papers by Foerster, Sukhbataar, Omidshafiei\\n\\n\\nOverall, I see this as a paper which with improvements could make a nice workshop contribution, but not as a paper to be published at a top-tier venue.\\n\\n\"                                                                                                                                                                                                                                          \n",
       "62  \"In this work, the authors propose a procedure for tuning the parameters of an HMC algorithm (I guess, if I have understood correctly).\\n\\nI think this paper has a good and strong point: this work points out the difficulties in choosing properly the parameters in a HMC method (such as the step and the number of iterations in the leapfrog integrator, for instance). In the literature, specially in machine learning, there is ``fever\\u2019\\u2019 about HMC, in my opinion, partially unjustified.\\n\\nIf I have understood, your method is an adaptive HMC algorithm  where the parameters are updated online; or is the training  done in advance? Please, remark and clarify this point.\\n\\nHowever, I have other additional comments:\\n\\n- Eqs. (4) and (5) are quite complicated; I think a running toy example can help the interested reader.\\n\\n- I suggest to compare the proposed method to other efficient methods that do not use the gradient information (in some cases as multimodal posteriors, the use of the gradient information can be counter-productive for sampling purposes), such as Multiple Try Metropolis (MTM) schemes\\n\\nL. Martino, J. Read, On the flexibility of the design of Multiple Try Metropolis schemes, Computational Statistics, Volume 28, Issue 6, Pages: 2797-2823, 2013, \\n\\nadaptive techniques, \\n\\nH. Haario, E. Saksman, and J. Tamminen. An adaptive Metropolis algorithm. Bernoulli, 7(2):223\\u2013242, April 2001,\\n\\nand component-wise strategies as Gibbs Sampling, \\n\\nW. R. Gilks and P. Wild, Adaptive rejection sampling for Gibbs sampling, Appl. Statist., vol. 41, no. 2, pp. 337\\u2013348, 199.\\u2028\\n\\nAt least, add a brief paragraph in the introduction citing and discussing this possible alternatives.\"                                                                                                                                                                                     \n",
       "69  \"The paper proposes training an autoencoder such that the middle layer representation consists of the class label of the input and a hidden vector representation called \\\"style memory\\\", which would presumably capture non-class information. The idea of learning representations that decompose into class-specific and class-agnostic parts, and more generally \\\"style\\\" and \\\"content\\\", is an interesting and long-standing problem. The results in the paper are mostly qualitative and only on MNIST. They do not show convincingly that the network managed to learn interesting class-specific and class-agnostic representations. It's not clear whether the examples shown in figures 7 to 11 are representative of the network's general behavior. The tSNE visualization in figure 6 seems to indicate that the style memory representation does not capture class information as well as the raw pixels, but doesn't indicate whether that representation is sensible.\\n\\nThe use of fully connected networks on images may affect the quality of the learned representations, and it may be necessary to use convolutional networks to get interesting results. It may also be interesting to consider class-specific representations that are more general than just the class label. For example, see \\\"Learning a Nonlinear Embedding by Preserving Class Neighbourhood Structure\\\" by Salakhutdinov and Hinton, 2007, which learns hidden vector representations for both class-specific and class-agnostic parts. (This paper should be cited.)\"                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "70  \"Pros:\\n1. A new DNA structure GAN is utilized to manipulate/disentangle attributes.\\n\\n2. Non attribute part (Z) is explicitly modeled in the framework.\\n\\n3. Based on the experiment results, this proposed method outperformed previous methods (TD-GAN, IcGAN).\\n\\nCons:\\n1. It assumes that each individual piece represents an independent factor of variation, which can not hold all the time. The authors also admit that when two factors are dependent, this method might fail.\\n\\n2. In Lreconstruct, only min difference between A and A1 is considered. How about A and A2 here? It seems that A2 should also be similar with A since only one bit in A2 and A1 is different.\\n\\n3. Only one attribute can be \\\"manipulated\\\" each time? Is it possible to change more than one attribute each time in this method?\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "72  \"The paper proposed a generalized HMC by modifying the leapfrog integrator using neural networks to make the sampler to converge and mix quickly. Mixing is one of the most challenge problems for a MCMC sampler, particularly when there are many modes in a distribution. The derivations look correct to me. In the experiments, the proposed algorithm was compared to other methods, e.g., A-NICE-MC and HMC. It showed that the proposed method could mix between the modes in the posterior. Although the method could mix well when applied to those particular experiments, it lacks theoretical justifications why the method could mix well. \"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "73  \"This paper proposes a tensor train decomposition with a ring structure for function approximation and data compression. Most of the techniques used are well-known in the tensor community (outside of machine learning). The main contribution of the paper is the introduce such techniques to the ML community and presents experimental results for support.\\n\\nThe paper is rather preliminary in its examination. For example, it is claimed that the proposed decomposition provides \\\"enhanced representation ability\\\", but this is not justified rigorously either via more comprehensive experimentation or via a theoretical justification. Furthermore, the paper lacks in novelty aspect, as it is uses mostly well-known techniques. \"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "74  \"The paper proposes to learn a custom translation or rotation invariant kernel in the Fourier representation to maximize the margin of SVM. Instead of using Monte Carlo approximation as in the traditional random features literature, the main point of the paper is to learn these Fourier features in a min-max sense. This perspective leads to some interesting theoretical results and some new interpretation. Synthetic and some simple real-world experiments demonstrate the effectiveness of the algorithm compared to random features given the fix number of bases.\\n\\nI like the idea of trying to formulate the feature learning problem as a two-player min-max game and its connection to boosting. As for the related work, it seems the authors have missed some very relevant pieces of work in learning these Fourier features through gradient descent [1, 2]. It would be interesting to compare these algorithms as well.\\n\\n[1] Zichao Yang, Marcin Moczulski, Misha Denil, Nando de Freitas, Alex Smola, Le Song, Ziyu Wang. Deep Fried Convnets. ICCV 2015.\\n[2] Zichao Yang, Alexander J. Smola, Le Song, Andrew Gordon Wilson. A la Carte \\u2014 Learning Fast Kernels. AISTATS 2015.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "75  \"The majority of the paper is focused on the observation that (1) making policies that condition on the time step is important in finite horizon problems, and a much smaller component on that (2) if episodes are terminated early during learning (say to restart and promote exploration) that the values should be bootstrapped to reflect that there will be additional rewards received in the true infinite-horizon setting.\\n\\n1 is true and is well known. This is typically described as finite horizon MDP planning and learning and the optimal policy is well known to be nonstationary and depend on the number of remaining time steps. There are a number of papers focusing on this for both planning and learning though these are not cited in the current draft. \\n\\nI don\\u2019t immediately know of work that suggests bootstrapping if an episode is terminated early artificially during training but it seems a very reasonable and straightforward thing to do. \\n\\n\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "76  \"The paper presents a novel representation of graphs as multi-channel image-like structures. These structures are extrapolated  by \\n1) mapping the graph nodes into an embedding using an algorithm like node2vec\\n2) compressing the embedding space using pca\\n3) and extracting 2D slices from the compressed space and computing 2D histograms per slice.\\nhe resulting multi-channel image-like structures are then feed into vanilla 2D CNN.\\n  \\nThe papers is well written and clear, and proposes an interesting idea of representing graphs as multi-channel image-like structures. Furthermore, the authors perform experiments with real graph datasets from the social science domain and a comparison with the SoA method both graph kernels and deep learning architectures. The proposed algorithm in 3 out of 5 datasets, two of theme with statistical significant.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "80  \"The authors present an algorithm for training ensembles of policy networks that regularly mixes different policies in the ensemble together by distilling a mixture of two policies into a single policy network, adding it to the ensemble and selecting the strongest networks to remain (under certain definitions of a \\\"strong\\\" network). The experiments compare favorably against PPO and A2C baselines on a variety of MuJoCo tasks, although I would appreciate a wall-time comparison as well, as training the \\\"crossover\\\" network is presumably time-consuming.\\n\\nIt seems that for much of the paper, the authors could dispense with the genetic terminology altogether - and I mean that as a compliment. There are few if any valuable ideas in the field of evolutionary computing and I am glad to see the authors use sensible gradient-based learning for GPO, even if it makes it depart from what many in the field would consider \\\"evolutionary\\\" computing. Another point on terminology that is important to emphasize - the method for training the crossover network by direct supervised learning from expert trajectories is technically not imitation learning but behavioral cloning. I would perhaps even call this a distillation network rather than a crossover network. In many robotics tasks behavioral cloning is known for overfitting to expert trajectories, but that may not be a problem in this setting as \\\"expert\\\" trajectories can be generated in unlimited quantities.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "\n",
       "    CONFIDENCE  Layer 1  Layer 1 N  Layer 2  Layer 2 N  Layer 3  Layer 3 N  \n",
       "1   5           1.280    1.332      9.568    1.309     -0.340   -0.340      \n",
       "4   4           3.718    1.993      42.942   2.504     -0.455   -0.455      \n",
       "6   4           3.445    1.919      37.242   2.300     -0.221   -0.221      \n",
       "7   4           2.072    1.547      22.502   1.772      0.197    0.197      \n",
       "16  4           2.607    1.692      26.111   1.902     -0.035   -0.035      \n",
       "17  4           3.432    1.915      49.330   2.733     -0.583   -0.583      \n",
       "23  3           1.016    1.261      22.572   1.775     -0.997   -0.997      \n",
       "25  4           3.232    1.861      43.019   2.507     -0.150   -0.150      \n",
       "36  4           1.736    1.456      22.195   1.761     -0.142   -0.142      \n",
       "37  4           2.269    1.600      21.480   1.736      0.065    0.065      \n",
       "41  4           3.479    1.928      41.192   2.442     -0.546   -0.546      \n",
       "43  4           3.729    1.996      34.870   2.215     -0.630   -0.630      \n",
       "45  4           1.256    1.326      22.132   1.759     -0.312   -0.312      \n",
       "50  3           3.383    1.902      34.259   2.194     -0.237   -0.237      \n",
       "53  5           2.932    1.780      43.046   2.508     -0.036   -0.036      \n",
       "62  4           2.702    1.718      29.453   2.021      0.052    0.052      \n",
       "69  5           3.712    1.991      28.519   1.988     -0.342   -0.342      \n",
       "70  5           2.664    1.707      18.986   1.647     -0.473   -0.473      \n",
       "72  3           1.969    1.519      23.844   1.821     -0.596   -0.596      \n",
       "73  4           2.298    1.608      22.865   1.786     -0.193   -0.193      \n",
       "74  3           3.279    1.874      23.452   1.807      0.326    0.326      \n",
       "75  5           0.854    1.217      10.572   1.345      0.522    0.522      \n",
       "76  3           2.031    1.536      21.920   1.752      0.189    0.189      \n",
       "80  4           2.216    1.586      24.164   1.832     -0.332   -0.332      "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECOMMENDATION</th>\n",
       "      <th>comments</th>\n",
       "      <th>CONFIDENCE</th>\n",
       "      <th>Layer 1</th>\n",
       "      <th>Layer 1 N</th>\n",
       "      <th>Layer 2</th>\n",
       "      <th>Layer 2 N</th>\n",
       "      <th>Layer 3</th>\n",
       "      <th>Layer 3 N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>\"Summary:\\n The paper presents an unsupervised method for detecting adversarial examples of neural networks. The method includes two independent components: an \\u2018input defender\\u2019 which tried to inspect the input, and a \\u2018latent defender\\u2019 trying to inspect a hidden representation. Both are based on the claim that adversarial examples lie outside a certain sub-space occupied by the natural image examples, and modeling this sub-space hence enables their detection. The input defender is based on sparse coding, and the latent defender on modeling the latent activity as a mixture of Gaussians. Experiments are presented on MInst, Cifar10, and ImageNet.\\n \\n-\\tIntroduction: The motivation for detecting adversarial examples is not stated clearly enough. How can such examples be used by a malicious agent to cause damage to a system? Sketching some such scenarios would help the reader understand why the issue is practically important. I was not convinced it is. \\nPage 4: \\n-\\tStep 3 of the algorithm is not clear:\\no\\tHow exactly does HDDA model the data (formally) and how does it estimate the parameters? In the current version, the paper does not explain the HDDA formalism and learning algorithm, which is a main building block in the proposed system (as it provides the density score used for adversarial examples detection). Hence the paper cannot be read as a standalone document. I went on to read the relevant HDDA paper, but it is also not clear which of the model variants presented there is used in this paper.\\no\\tWhat is the relation between the model learned at stage 2 (the centers c^i) and the model learnt by HDDA? Are they completely different models? Or are the C^I used when learning the HDDA model (and how)? \\nIf these are separate models, how are they used in conjunction to give a final density score? If I understand correctly, only the HDDA model is used to get the final score, and the C^i are only used to make the \\\\phy(x) representation more class-seperable. Is that right?\\n-\\tFigure 4, b and c: it is not clear what the (x,y,z) measurements plotted in these 3D drawings are (what are the axis).\\nPage 5:\\n-\\tSection 2: the risk analysis is done in a standard Bayesian way and leads to a ratio of PDFs in equation 5. However, this form is not appropriate for the case presented at this paper, since the method presented only models one of these PDFs (Specifically p(x | W1)  - there is not generative model of p(x|W2)).  \\n-\\tThe authors claim in the last sentence of the section that p(x|W2) is equivalent to 1-p(x|W1), but this is not true: these are two continuous densities, they do not sum to 1, and a model of p(x|W2) is not available (as far as I understand the method)\\nPage 6:\\n-\\tHow is equation 7) optimized?\\n-\\tWhich patchs are extracted from images, for training and at inference time? Are these patchs a dense coverage of the image? Sparsely sampled? Densely sampled with overlaps?\\n-\\tIts not clear enough what exactly is the \\u2018PSNR\\u2019 value which is used for the adversarial example detection, and what exactly is \\u2018profile the PSNR of legitimate samples within each class\\u2019. A formal definition of PSNR and\\u2019profiling\\u2019 is missing (does profiling simply mean finding a threshold for filtering?)\\nPage 7:\\n-\\tFigure 7 is not very informative. Given the ROC curves in figure 8  and table 1 it is redundant. \\n\\nPage 8:\\n-\\tThe results in general indicate that the method is much better than chance, but it is not clear if it is practical, because the false alarm rates for high detection are quite high. For example on ImageNet, 14.2% of the innocent images are mistakenly rejected as malicious to get 90% detection rate. I do not think this working point is useful for a real application\\n-\\tGiven the high flares alarm rate, it is surprising that experiments with multiple checkpoints are not presented (specifically as this case of multiple checkpoints is discussed explicitly in previous sections of the paper).  Experiments with multiple checkpoints are clear required to complete the picture regarding the empirical performance of this method\\n-\\tThe experiments show that essentially, the latent defenders are stronger than the input defender in most cases. However, an ablation study of the latent defender is missing: Specifcially, it is not clear a) how much does stage 2 (model refinement with clusters)  contribute to the accuracy (how does the model do without it? And 3) how important is the HDDA and the specific variant used (which is not clear) important: is it important to model the Gaussians using a sub-space? Of which dimension?\\n\\nOverall:\\nPros:\\n-\\t A nice idea with some novelty,  based on a non-trivial observation\\n-\\tThe experimental results how the idea holds some promise\\nCons\\n-\\tThe method is not presented clearly enough: the main component modeling the network activity is not explained (the HDDA module used)\\n-\\tThe results presented show that the method is probably not suitable for a practical application yet (high false alarm rate for good detection rate)\\n-\\tExperimental results are partial: results are not presented for multiple defenders, no ablation experiments\\n\\n\\nAfter revision:\\nSome of my comments were addressed, and some were not.\\nSpecifically, results were presented for multiple defenders and some ablation experiments were highlihgted\\nThings not addressed:\\n - The risk analysis is still not relevant. The authors removed a clearly flawed sentence, but the analysis still assumes that two densities (of 'good' and 'bad' examples) are modeled, while in the work presented only one of them is. Hence this analysis does not add anything to the paper-  it states a general case which does not fit the current scenario and its relation to the work is not clear. It would have been better to omit it and use the space to describe HDDA and the specific variant used in this work, as this is the main tool doing the distinction.\\n\\nI believe the paper should be accepted.\\n\"</td>\n",
       "      <td>3</td>\n",
       "      <td>28.766</td>\n",
       "      <td>8.781</td>\n",
       "      <td>328.435</td>\n",
       "      <td>12.728</td>\n",
       "      <td>-0.933</td>\n",
       "      <td>-0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>\"The paper addresses the problem of tensor decomposition which is relevant and interesting. The paper proposes Tensor Ring (TR) decomposition which improves over and bases on the Tensor Train (TT) decomposition method. TT decomposes a tensor in to a sequences of latent tensors where the first and last tensors are a 2D matrices. \\n\\nThe proposed TR method generalizes TT in that the first and last tensors are also 3rd-order tensors instead of 2nd-order. I think such generalization is interesting but the innovation seems to be very limited. \\n\\nThe paper develops three different kinds of solvers for TR decomposition, i.e., SVD, ALS and SGD. All of these are well known methods. \\n\\nFinally, the paper provides experimental results on synthetic data (3 oscillated functions) and image data (few sampled images). I think the paper could be greatly improved by providing more experiments and ablations to validate the benefits of the proposed methods.\\n\\nPlease refer to below for more comments and questions.\\n\\n-- The rating has been updated.\\n\\nPros:\\n1. The topic is interesting.\\n2. The generalization over TT makes sense.\\n\\nCons:\\n1. The writing of the paper could be improved and more clear: the conclusions on inner product and F-norm can be integrated into \\\"Theorem 5\\\". And those \\\"theorems\\\" in section 4 are just some properties from previous definitions; they are not theorems. \\n2. The property of TR decomposition is that the tensors can be shifted (circular invariance). This is an interesting property and it seems to be the major strength of TR over TT. I think the paper could be significantly improved by providing more applications of this property in both theory and experiments.\\n3. As the number of latent tensors increase, the ALS method becomes much worse approximation of the original optimization. Any insights or results on the optimization performance vs. the number of latent tensors?\\n4. Also, the paper mentions Eq. 5 (ALS) is optimized by solving d subproblems alternatively. I think this only contains a single round of optimization. Should ALS be applied repeated (each round solves d problems) until convergence?\\n5. What is the memory consumption for different solvers?\\n6. SGD also needs to update at least d times for all d latent tensors. Why is the complexity O(r^3) independent of the parameter d?\\n7. The ALS is so slow (if looking at the results in section 5.1), which becomes not practical. The experimental part could be improved by providing more results and description about a guidance on how to choose from different solvers.\\n8. What does \\\"iteration\\\" mean in experimental results such as table 2? Different algorithms have different cost for \\\"each iteration\\\" so comparing that seems not fair. The results could make more sense by providing total time consumptions and time cost per iteration. also applies to table 4.\\n9. Why is the \\\\epsion in table 3 not consistent? Why not choose \\\\epsion = 9e-4 and \\\\epsilon=2e-15 for tensorization?\\n10. Also, table 3 could be greatly improved by providing more ablations such as results for (n=16, d=8), (n=4, d=4), etc. That could help readers to better understand the effect of TR.\\n11. Section 5.3 could be improved by providing a curve (compression vs. error) instead of just providing a table of sampled operating points.\\n12. The paper mentions the application of image representation but only experiment on 32x32 images. How does the proposed method handle large images? Otherwise, it does not seem to be a practical application.\\n13. Figure 5: Are the RSE measures computed over the whole CIFAR-10 dataset or the displayed images?\\n\\nMinor:\\n- Typo: Page 4 Line 7 \\\"Note that this algorithm use the similar strategy\\\": use -&gt; uses\"</td>\n",
       "      <td>4</td>\n",
       "      <td>23.499</td>\n",
       "      <td>7.354</td>\n",
       "      <td>281.795</td>\n",
       "      <td>11.058</td>\n",
       "      <td>-0.491</td>\n",
       "      <td>-0.491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RECOMMENDATION  \\\n",
       "3   7                \n",
       "29  5                \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               comments  \\\n",
       "3   \"Summary:\\n The paper presents an unsupervised method for detecting adversarial examples of neural networks. The method includes two independent components: an \\u2018input defender\\u2019 which tried to inspect the input, and a \\u2018latent defender\\u2019 trying to inspect a hidden representation. Both are based on the claim that adversarial examples lie outside a certain sub-space occupied by the natural image examples, and modeling this sub-space hence enables their detection. The input defender is based on sparse coding, and the latent defender on modeling the latent activity as a mixture of Gaussians. Experiments are presented on MInst, Cifar10, and ImageNet.\\n \\n-\\tIntroduction: The motivation for detecting adversarial examples is not stated clearly enough. How can such examples be used by a malicious agent to cause damage to a system? Sketching some such scenarios would help the reader understand why the issue is practically important. I was not convinced it is. \\nPage 4: \\n-\\tStep 3 of the algorithm is not clear:\\no\\tHow exactly does HDDA model the data (formally) and how does it estimate the parameters? In the current version, the paper does not explain the HDDA formalism and learning algorithm, which is a main building block in the proposed system (as it provides the density score used for adversarial examples detection). Hence the paper cannot be read as a standalone document. I went on to read the relevant HDDA paper, but it is also not clear which of the model variants presented there is used in this paper.\\no\\tWhat is the relation between the model learned at stage 2 (the centers c^i) and the model learnt by HDDA? Are they completely different models? Or are the C^I used when learning the HDDA model (and how)? \\nIf these are separate models, how are they used in conjunction to give a final density score? If I understand correctly, only the HDDA model is used to get the final score, and the C^i are only used to make the \\\\phy(x) representation more class-seperable. Is that right?\\n-\\tFigure 4, b and c: it is not clear what the (x,y,z) measurements plotted in these 3D drawings are (what are the axis).\\nPage 5:\\n-\\tSection 2: the risk analysis is done in a standard Bayesian way and leads to a ratio of PDFs in equation 5. However, this form is not appropriate for the case presented at this paper, since the method presented only models one of these PDFs (Specifically p(x | W1)  - there is not generative model of p(x|W2)).  \\n-\\tThe authors claim in the last sentence of the section that p(x|W2) is equivalent to 1-p(x|W1), but this is not true: these are two continuous densities, they do not sum to 1, and a model of p(x|W2) is not available (as far as I understand the method)\\nPage 6:\\n-\\tHow is equation 7) optimized?\\n-\\tWhich patchs are extracted from images, for training and at inference time? Are these patchs a dense coverage of the image? Sparsely sampled? Densely sampled with overlaps?\\n-\\tIts not clear enough what exactly is the \\u2018PSNR\\u2019 value which is used for the adversarial example detection, and what exactly is \\u2018profile the PSNR of legitimate samples within each class\\u2019. A formal definition of PSNR and\\u2019profiling\\u2019 is missing (does profiling simply mean finding a threshold for filtering?)\\nPage 7:\\n-\\tFigure 7 is not very informative. Given the ROC curves in figure 8  and table 1 it is redundant. \\n\\nPage 8:\\n-\\tThe results in general indicate that the method is much better than chance, but it is not clear if it is practical, because the false alarm rates for high detection are quite high. For example on ImageNet, 14.2% of the innocent images are mistakenly rejected as malicious to get 90% detection rate. I do not think this working point is useful for a real application\\n-\\tGiven the high flares alarm rate, it is surprising that experiments with multiple checkpoints are not presented (specifically as this case of multiple checkpoints is discussed explicitly in previous sections of the paper).  Experiments with multiple checkpoints are clear required to complete the picture regarding the empirical performance of this method\\n-\\tThe experiments show that essentially, the latent defenders are stronger than the input defender in most cases. However, an ablation study of the latent defender is missing: Specifcially, it is not clear a) how much does stage 2 (model refinement with clusters)  contribute to the accuracy (how does the model do without it? And 3) how important is the HDDA and the specific variant used (which is not clear) important: is it important to model the Gaussians using a sub-space? Of which dimension?\\n\\nOverall:\\nPros:\\n-\\t A nice idea with some novelty,  based on a non-trivial observation\\n-\\tThe experimental results how the idea holds some promise\\nCons\\n-\\tThe method is not presented clearly enough: the main component modeling the network activity is not explained (the HDDA module used)\\n-\\tThe results presented show that the method is probably not suitable for a practical application yet (high false alarm rate for good detection rate)\\n-\\tExperimental results are partial: results are not presented for multiple defenders, no ablation experiments\\n\\n\\nAfter revision:\\nSome of my comments were addressed, and some were not.\\nSpecifically, results were presented for multiple defenders and some ablation experiments were highlihgted\\nThings not addressed:\\n - The risk analysis is still not relevant. The authors removed a clearly flawed sentence, but the analysis still assumes that two densities (of 'good' and 'bad' examples) are modeled, while in the work presented only one of them is. Hence this analysis does not add anything to the paper-  it states a general case which does not fit the current scenario and its relation to the work is not clear. It would have been better to omit it and use the space to describe HDDA and the specific variant used in this work, as this is the main tool doing the distinction.\\n\\nI believe the paper should be accepted.\\n\"   \n",
       "29  \"The paper addresses the problem of tensor decomposition which is relevant and interesting. The paper proposes Tensor Ring (TR) decomposition which improves over and bases on the Tensor Train (TT) decomposition method. TT decomposes a tensor in to a sequences of latent tensors where the first and last tensors are a 2D matrices. \\n\\nThe proposed TR method generalizes TT in that the first and last tensors are also 3rd-order tensors instead of 2nd-order. I think such generalization is interesting but the innovation seems to be very limited. \\n\\nThe paper develops three different kinds of solvers for TR decomposition, i.e., SVD, ALS and SGD. All of these are well known methods. \\n\\nFinally, the paper provides experimental results on synthetic data (3 oscillated functions) and image data (few sampled images). I think the paper could be greatly improved by providing more experiments and ablations to validate the benefits of the proposed methods.\\n\\nPlease refer to below for more comments and questions.\\n\\n-- The rating has been updated.\\n\\nPros:\\n1. The topic is interesting.\\n2. The generalization over TT makes sense.\\n\\nCons:\\n1. The writing of the paper could be improved and more clear: the conclusions on inner product and F-norm can be integrated into \\\"Theorem 5\\\". And those \\\"theorems\\\" in section 4 are just some properties from previous definitions; they are not theorems. \\n2. The property of TR decomposition is that the tensors can be shifted (circular invariance). This is an interesting property and it seems to be the major strength of TR over TT. I think the paper could be significantly improved by providing more applications of this property in both theory and experiments.\\n3. As the number of latent tensors increase, the ALS method becomes much worse approximation of the original optimization. Any insights or results on the optimization performance vs. the number of latent tensors?\\n4. Also, the paper mentions Eq. 5 (ALS) is optimized by solving d subproblems alternatively. I think this only contains a single round of optimization. Should ALS be applied repeated (each round solves d problems) until convergence?\\n5. What is the memory consumption for different solvers?\\n6. SGD also needs to update at least d times for all d latent tensors. Why is the complexity O(r^3) independent of the parameter d?\\n7. The ALS is so slow (if looking at the results in section 5.1), which becomes not practical. The experimental part could be improved by providing more results and description about a guidance on how to choose from different solvers.\\n8. What does \\\"iteration\\\" mean in experimental results such as table 2? Different algorithms have different cost for \\\"each iteration\\\" so comparing that seems not fair. The results could make more sense by providing total time consumptions and time cost per iteration. also applies to table 4.\\n9. Why is the \\\\epsion in table 3 not consistent? Why not choose \\\\epsion = 9e-4 and \\\\epsilon=2e-15 for tensorization?\\n10. Also, table 3 could be greatly improved by providing more ablations such as results for (n=16, d=8), (n=4, d=4), etc. That could help readers to better understand the effect of TR.\\n11. Section 5.3 could be improved by providing a curve (compression vs. error) instead of just providing a table of sampled operating points.\\n12. The paper mentions the application of image representation but only experiment on 32x32 images. How does the proposed method handle large images? Otherwise, it does not seem to be a practical application.\\n13. Figure 5: Are the RSE measures computed over the whole CIFAR-10 dataset or the displayed images?\\n\\nMinor:\\n- Typo: Page 4 Line 7 \\\"Note that this algorithm use the similar strategy\\\": use -> uses\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "\n",
       "    CONFIDENCE  Layer 1  Layer 1 N  Layer 2  Layer 2 N  Layer 3  Layer 3 N  \n",
       "3   3           28.766   8.781      328.435  12.728    -0.933   -0.933      \n",
       "29  4           23.499   7.354      281.795  11.058    -0.491   -0.491      "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "path = './Data/SignData/test/reviews'\n",
    "reviews = os.listdir(path)\n",
    "filenames = os.listdir('./Data/SignData/test_data')\n",
    "\n",
    "review_text = []\n",
    "indices = []\n",
    "for i, filename in enumerate(filenames):\n",
    "    split = filename.split('_')\n",
    "    fname, count = ''.join(c for c in split[:-1]), split[-1]\n",
    "    if fname in reviews:\n",
    "        rev = json.load(open(os.path.join(path, fname)))['reviews'][int(count)]\n",
    "        rev['ID'] = fname\n",
    "        review_text.append(rev)\n",
    "#         review_text[fname].append(rev)\n",
    "    else:\n",
    "        indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: Hyp3i2xRb.json\n",
    "# 23: BkIkkseAZ.json\n",
    "# 54: B17JTOe0-.json\n",
    "# 53: Hyp-JJJRW.json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Round(num):\n",
    "    return np.round(num, decimals=3)\n",
    "\n",
    "import numpy as np\n",
    "l1, l2 = np.array([0.05428571,0.93013972,-0.99966815]), np.array([33.26288336,252.25067107,0.99966679])\n",
    "def normalize(s):\n",
    "    s = np.array(s)\n",
    "    sent = s[2]\n",
    "    s = (s - l1)/(l2 - l1)\n",
    "    s = (s*9) + 1\n",
    "    s[2] = (((sent - (-1))*9)/2) + 1\n",
    "    return s\n",
    "\n",
    "reviews = []\n",
    "import csv\n",
    "for i, review in enumerate(review_text):\n",
    "    new_scores = list(map(lambda x: Round(x), normalize(review_text[i]['SCORES'])))\n",
    "    review['SCORES'] = list(map(lambda x: Round(x), review['SCORES']))\n",
    "    review['Layer 1'], review['Layer 1 N'] = review['SCORES'][0], new_scores[0]\n",
    "    review['Layer 2'], review['Layer 2 N'] = review['SCORES'][1], new_scores[1]\n",
    "    review['Layer 3'], review['Layer 3 N'] = review['SCORES'][2], new_scores[2]\n",
    "    reviews.append(review)\n",
    "\n",
    "field_names = reviews[0].keys()\n",
    "with open('Test_Reviews.csv', 'w') as csvfile: \n",
    "    writer = csv.DictWriter(csvfile, fieldnames = field_names) \n",
    "    writer.writeheader() \n",
    "    writer.writerows(reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rajeev3",
   "language": "python",
   "name": "rajeev3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
