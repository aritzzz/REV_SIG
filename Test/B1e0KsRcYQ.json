{"rating": 0, "authors": "", "title": " ", "abstract": " ", "chair_comments": " ", "accepted": false, "id": "B1e0KsRcYQ", "reviews": [{"RECOMMENDATION": "4", "REVIEW TITLE": "Method needs some clarification. ", "comments": "Summary: This paper presents a way to combine existing factorized second order representations with a codebook style hard assignment. The number of parameters required to produce this encoded representation is shown to be very low. Like other factorized representations, the number of computations as well as the size of any intermediate representations is low. The overall embedding is trained for retrieval using a triplet loss. Results are shown on Stanford online, CUB and Cars-196 datasets.\n\nComments:\n\nReview of relevant works seems adequate. The results seem reproducible. \n\nThe only contribution of this paper is combining the factorized second order representations  of (Kim et. al. 2017) with a codebook style assignment (sec. 3.2). Seems marginal.\n\nThe scheme described in Sec. 3.2 needs clarification. The assignment is applied to x as h(x) \\kron x in (7). Then the entire N^2 D^2 dimensional second order descriptor h(x) \\kron x \\kron h(x) \\kron x is projected on a N^2 D^2 dim w_i. The latter is factorized into p_i, q_i \\in \\mathbb{R}^{Nd}, which are further factorized into codebook specific projections u_{i,j}, v_{i,j} \\in \\mathbb{R}^{d}. Is this different from classical assignment, where x is hard assigned to one of the N codewords as h(x), then projected using \\mathbb{R}^d dimensional p_i, q_i specific to that codeword ?\n\nIn section 4.1 and Table 2, is the HPBP with codebook the same as the proposed CHPBP ? The wording in \"Then we re-implement ... naively to a codebook strategy\"  seems confusing.\n\nThe method denoted \"Margin\" in Table 4 seems to be better than the proposed approach on CUB. How does it compare in terms of efficiency, memory/computation ?\n\nIs it possible to see any classification results? Most of the relevant second order embeddings have been evaluated in that setting.\n\n\n===============After rebuttal ===============================\n\nAfter reading all reviews, considering author rebuttal and AC inputs, I believe my initial rating is a bit generous. I would like to downgrade it to 4. It has been pointed out that many recent works that are of a similar flavor, published in CVPR 2018 and ECCV 2018, have slightly better results on the same dataset. Further, the only novelty of this work is the proposed factorization and not the encoding scheme. This alone is not sufficient to merit acceptance. ", "VARIANCE": 0, "CONFIDENCE": "5"}, {"RECOMMENDATION": "6", "REVIEW TITLE": "Interesting idea of bilinear pooling with codebooks. But, needs more experiments for validating the idea.", "comments": "Summary:\nThis paper proposes a novel bilinear representation based on a codebook model.\nThe proposed method is build upon the form of Hadamard Product for efficient representation of a bilinear model.\nThrough introducing the framework of codebook, it is naturally extended into a multiple-rank representation while the efficient pooling scheme is also derived from the (sparse) codeword assignment.\nIn addition, the authors also present an efficient formulation in which the codebook-based projections are factorized via a shared projection to further reduce the parameter size.\nThe experimental results on image retrieval tasks show that the proposed method produces better classification accuracy with a limited amount of parameters.\n\nComments:\nPros:\n+ It is interesting that one-rank bilinear pooling is naturally extended to multiple-rank one via introducing codebooks.\n+ Good performance in the image retrieval tasks.\n\nCons:\n- This paper lacks important comparison for fairly evaluating the effectiveness of the proposed formulation.\n- It also lacks detailed description and discussion for the methods.\n\nDue to the above-mentioned weak points, the reviewer cannot fully understand whether the performance improvement really comes from the proposed formulation or not. Thus, this manuscript is currently judged as border. The detailed comments are shown in the followings.\n\n- Comparison\nEventually, the proposed method is closely related to the multiple-rank representation of a bilinear model;\n\nz_i = x^T W_i x (Eq.5) ~ x^T u_i v_i^T x (one-rank, Eq.6) ~ x^T U_i V_i^T x (multiple-rank), ... Eq.(A)\n\nwhich is a straightforward extension from the one-rank model. From this viewpoint, the proposed form in Eq.10 is regarded as an extension of (A) by introducing non-linearity as\n\nz_i = x^T U_i {h(x)h(x)^T} V_i^T x.  ... Eq.(10)\n\nThus, the main technical contribution is found in the weighting by {h(x)h(x)^T}, but its impact on the performance is not evaluated in the experiments. Furthermore, it is also possible to simply introduce such a non-linearity into the model (A) according to [Kim et al.,2017];\n\nz_i = \\sigma(x^T U_i) \\sigma(V_i^T x) = 1^T {\\sigma(U_i^T x) .* \\sigma(V_i^T x)}, ... Eq.(B)\n\nwhere \".*\" indicates Hadamard Product, and we can more directly apply the method of [Kim et al., 2017] to the multiple-rank model by\n\nz_i = p^T {\\sigma(U_i^T x) .* \\sigma(V_i^T x)}, ... Eq.(C)\n\nwhere p is a R-dimensional vector. On the other hand, it is also necessary to compare the proposed method with [Kim et al.,2017] which is formulated by\n\nz = P^T {\\sigma(U^T x) .* \\sigma(V^T x)}, ... Eq.(D)\n\nwhere U and V are matrices of d x K and P is K x D. The parameter K (shared rank) should be determined so that the total parameter size of (2dK + KD) is compatible to that of the proposed method, 2NdD.\n\nIn summary, for demonstrating the effectiveness of the proposed method in Eq.(10), it is inevitable to compare it with the models (A, B, D) and hopefully (C).\n\n- Presentation\nIn Section 4.2, the performance results of the factorization model in Eq.(13) are merely shown without deep discussion nor analysis on them. In particular, it is unclear why the JCF of N=32 and R=32 outperforms the CHPBP of N=32. Those two methods are different only in the form of U and V:\n(CHPBP) U_i -> U'_i A (JCF),\nwhere U_i and U'_i have the same dimensionality of d x 32, and thus we can say that JCF overly parameterizes the projection by redundantly introducing A of 32 x 32. Thus, the projection capacity of JCF is completely the same as that of CHPBP. Therefore, it needs detailed discussion for the performance improvement shown in Figure 1.\n\nMinor comments are:\n* There are lots of notations, and thus it would be better to show a summary of the notations.\n* In Section 4.1, there is no clear description about the methods of BP and HPBP. Actually, the method of HPBP is different from the one presented in [Kim et al., 2017].\n", "VARIANCE": 0, "CONFIDENCE": "4"}, {"RECOMMENDATION": 0, "REVIEW TITLE": " ", "comments": " ", "VARIANCE": 0, "CONFIDENCE": 0}, {"RECOMMENDATION": "5", "REVIEW TITLE": "The proposed representation method is tested on only one task and considers only one evaluation metric", "comments": "The paper proposes a second order method to represent images. More exactly, multiple (low-dimensional) projections of Kronecker products of low-dimensional representations are used to represent a limited set of dimensions of second-order representations. It is an extension of HPBP (Kim et al., ICLR 2017) but with codebook assigment. \n\nThe main advantage of the method is that, if the number of projection dimensions is small enough, the number of learned parameters is small and the learning process is fast. The method can be easily used as last layers of a neural network. Although the derivations of the method are straightforward, I think the paper is of interest for the computer vision community. \n\nNonetheless, I think that the experimental evaluation is weak. Indeed, the article only considers the specific problem of transfer learning and considers only one evaluation metric (recall@k). However, recent papers that evaluate their method for that task also use the Normalized Mutual Information (NMI) (e.g. [A,B]) or the F1-score [B] as evaluation metrics. \nThe paper does not compare the same task and datasets as (Kim et al., ICLR 2017) either.\nIt is then difficult to evaluate whether the proposed representation is useful only for the considered task. Other tasks and evaluation metrics should be considered.\nMoreover, only the case where D=32 and R=8 are evaluated. It would be useful to observe the behavior of the approaches for different values of R. \nIn Section 3.2, it is mentioned that feature maps become rapidly intractable if the dimension of z is above 10. Other Factorizations are then proposed. How do these factorizations affect the second order nature of the representation of z? Is the proposed projection in Eq. (10) still a good approximation of the second order information induced by the features x?\n\n\nThe paper says that the method is efficient but does not mention training times. How does the method compare in terms of clockwork times compared to other approaches (on machines with similar architecture)?\n\nIn conclusion, the experimental evaluation of the method is currently too weak.\n\n\n[A] Hyun Oh Song, Stefanie Jegelka, Vivek Rathod, Kevin Murphy: Deep Metric Learning via Facility Location. CVPR 2017\n[B] Wang et al., Deep Metric Learning with Angular Loss, ICCV 2017\n\nafter rebuttal:\nThe authors still did not address my concern about testing on only one task with only one evaluation metric.", "VARIANCE": 0, "CONFIDENCE": "2"}]}