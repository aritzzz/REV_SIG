{"rating": "9", "confidence": "4", "review": "\"Congratulations on a very interesting and clear paper.  While ICLR is not focused on neuroscientific studies, this paper clearly belongs here as it shows what representations develop in recurrent networks that are trained on spatial navigation. Interestingly, these include representations that have been observed in mammals and that have attracted considerable attention, even honored with a Nobel prize. \\n\\nI found it is very interesting that the emergence of these representations was contingent on some regularization constraint. This seems similar to the visual domain where edge detectors emerge easily when trained on natural images with sparseness constraints as in Olshausen&Field and later reproduced with many other models that incorporate sparseness constraints. \\n\\nI do have some questions about the training itself. The paper mentions a metabolic cost that is not specified in the paper. This should be added. \\n\\nMy biggest concern is about Figure 6a. I am puzzled why is the error is coming down before the boundary interaction? Even more puzzling, why does this error go up again for the blue curve (no interaction)? Shouldn\\u2019t at least this curve be smooth?\\n\"", "variance": 0, "title": " "}