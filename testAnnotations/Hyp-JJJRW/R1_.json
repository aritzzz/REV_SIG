{"rating": "3", "confidence": "5", "review": "\"This paper proposes to train a classifier neural network not just to classifier, but also to reconstruct a representation of its input, in order to factorize the class information from the appearance (or \\\"style\\\" as used in this paper). This is done by first using unsupervised pretraining and then fine-tuning using a weighted combination of the regular multinomial NLL loss and a reconstruction loss at the last hidden layer. Experiments on MNIST are provided to analyse what this approach learns.\\n\\nUnfortunately, I fail to see a significantly valuable contribution from this work. First, the paper could do a better job at motivating the problem being addressed. Why is it important to separate class from style? Should it allow better classification performance? If so, it's never measured in this work. If that's not the motivation, then what is it?\\n\\nSecond, all experiments were conducted on the MNIST dataset. In 2017, most would expect experiments on at least one other, more complex dataset, to trust any claims on a method.\\n\\nFinally, the results are not particularly impressive. I don't find the reconstructions demonstrated particularly compelling (they are generally pretty different from the original input). Also, that the \\\"style\\\" representation contain less (and I'd say slightly less, in Figure 7 b and d, we still see a lot of same class nearest neighbors) is not exactly a surprising result. And the results of figure 9, showing poor reconstructions when changing the class representation essentially demonstrates that the method isn't able to factorize class and style successfully. The interpolation results of Figure 11 are also underwhelming, though possibly mostly because the reconstructions are in general not great. But most importantly, none of these results are measured in a quantitative way: they are all qualitative, and thus subjective.\\n\\nFor all these reasons, I'm afraid I must recommend this paper be rejected.\"", "variance": 0, "title": " ", "Scores": {"layer_1": "6.599032258", "layer_2": "72.85928143712573", "layer_3": -0.9976135109152112}}