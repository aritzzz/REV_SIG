{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils_ import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import logging\n",
    "from collections import OrderedDict\n",
    "import argparse\n",
    "import numpy as np\n",
    "from Models import Pipeline, MTLoss, Prediction #CrossAttention, Context\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SimpleNamespace(dim = 768, upscale_dim = 256, codes='128,64,32,8', batch_size=2, learning_rate=0.001, weight_decay=0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLoaders2(main_task_path = './Data/SignData/train_data', scaffold_task_path = './Data/2018/train_data', batch_size=8, slice=[-1, -1, -1], test_path='./Data/SignData/test_data'):\n",
    "\tprint('Reading the Main Task Dataset...')\n",
    "\tmain_task_dataset = RevSigData(main_task_path, mode='MAIN', slice_=slice[0], transform=Transform(), sigtx=ScaleSigScores())\n",
    "\t#main_task_dataset = dataset.readData(main_task_path, Transform(), mode='MAIN', n=slice[0])\n",
    "\tprint('Reading the Scaffolds Task Dataset...')\n",
    "\tscaffold_task_dataset = RevSigData(scaffold_task_path, mode='SCAFFOLDS', slice_=slice[1], transform=Transform())\n",
    "\t#scaffold_task_dataset = dataset.readData(scaffold_task_path, Transform(), mode='SCAFFOLDS', n=slice[1])\n",
    "\t\n",
    "\n",
    "\tif test_path:\n",
    "\t\tprint('Reading the test Dataset')\n",
    "\t\ttest_dataset = RevSigData(test_path, mode='TEST', slice_=slice[2], transform=Transform(), sigtx=ScaleSigScores())\n",
    "\t\t#test_dataset = dataset.readData(test_path, Transform(), mode='TEST', n=slice[2])\n",
    "\telse:\n",
    "\t\ttest_dataset = None\n",
    "\n",
    "\n",
    "\t#length of the both task datasets\n",
    "\tmain_task_len = len(main_task_dataset)\n",
    "\tscaffold_task_len = len(scaffold_task_dataset)\n",
    "\ttest_len = len(test_dataset)\n",
    "\n",
    "\t#inflate the smaller dataset to match the size of the larger one\n",
    "\tif main_task_len < scaffold_task_len:\n",
    "\t\tdifference = scaffold_task_len - main_task_len\n",
    "\t\tsample = [random.choice(main_task_dataset) for _ in range(difference)]\n",
    "\t\tmain_task_dataset = main_task_dataset + sample\n",
    "\t\n",
    "\t# print(len(main_task_dataset), len(scaffold_task_dataset))\n",
    "\t#print(main_task_len, scaffold_task_len)\n",
    "\treturn (main_task_dataset, scaffold_task_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_task_dataset, scaffold_task_dataset, test_dataset = getLoaders2(batch_size=args.batch_size, slice=[-1,-1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_task_dataloader = DataLoader(main_task_dataset, batch_size = args.batch_size, shuffle = True, num_workers=4)\n",
    "# scaffold_task_dataloader = DataLoader(scaffold_task_dataset, batch_size = args.batch_size, shuffle=True, num_workers=4)\n",
    "# if test_dataset != None:\n",
    "#     test_data_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4)\n",
    "# else:\n",
    "#     test_data_loader = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(model, main_task_predictor, scaffold_task_predictor, Criterion, test_loader):\n",
    "# \twith torch.no_grad():\n",
    "# \t\teval_loss = []\n",
    "# \t\tfor i, d in enumerate(test_loader,0):\n",
    "# \t\t\tscaffold_task_data = d\n",
    "# \t\t\tpapers_sc, reviews_sc, recs_sc, confs_sc, sign_m = scaffold_task_data[0].transpose(1,2).float().to(device),\\\n",
    "# \t\t\t\t\t\t\t scaffold_task_data[1].transpose(1,2).float().to(device), \\\n",
    "# \t\t\t\t\t\t\t scaffold_task_data[2].float().to(device),\\\n",
    "# \t\t\t\t\t\t\t scaffold_task_data[3].float().to(device),\\\n",
    "# \t\t\t\t\t\t\t scaffold_task_data[4].float().to(device)\n",
    "\n",
    "# \t\t\tex, subj, opine = sign_m[:,0], sign_m[:,1], sign_m[:,2]\n",
    "# \t\t\tout, rec_codes, conf_codes = model(papers_sc, reviews_sc)\n",
    "# \t\t\trec_preds, conf_preds = scaffold_task_predictor(rec_codes.view(out.shape[0], -1), conf_codes.view(out.shape[0], -1))\n",
    "\n",
    "# \t\t\t#out_m, rec_codes_m, conf_codes_m = model(papers_sc, reviews_sc)\n",
    "# \t\t\tex_preds, subj_preds, intensity_preds = main_task_predictor(out, rec_codes, conf_codes)\n",
    "\n",
    "\n",
    "# \t\t\tloss = Criterion([rec_preds.squeeze(1), conf_preds.squeeze(1), ex_preds.squeeze(1), subj_preds.squeeze(1), intensity_preds.squeeze(1)], [recs_sc, confs_sc, ex, subj, opine])\n",
    "\t\t\t\n",
    "# \t\t\teval_loss.append(loss.item())\n",
    "# \t\treturn np.average(eval_loss)\n",
    "\n",
    "\n",
    "\n",
    "# def train(args, dataloaders):\n",
    "#     main_task_loader, scaffold_task_loader, test_loader = dataloaders\n",
    "#     model = Pipeline.Pipeline(args).to(device)\n",
    "#     main_task_predictor = Prediction.MainPrediction(args.upscale_dim, args.upscale_dim, 16).to(device)\n",
    "#     scaffold_task_predictor = Prediction.ScaffoldPrediction(args.upscale_dim, 8).to(device)\n",
    "\n",
    "#     print(model)\n",
    "#     for name, param in model.named_parameters():\n",
    "#         print(name, param.shape)\n",
    "#     print(\"No. of Trainable parameters {}\".format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "\n",
    "#     Criterion = MTLoss.MTLoss().to(device2)\n",
    "#     optimizer = torch.optim.Adam(list(model.parameters()) + list(Criterion.parameters()), lr=args.learning_rate, weight_decay=args.weight_decay) #+ list(main_task_predictor.parameters()) + list(scaffold_task_predictor.parameters())\n",
    "#     optimizerMain = torch.optim.Adam(main_task_predictor.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "#     optimizerScaffold = torch.optim.Adam(scaffold_task_predictor.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "#     epochs = 100\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         model.train()\n",
    "#         epoch_loss = []\n",
    "#         for i, d in enumerate(zip(scaffold_task_loader, main_task_loader),0):\n",
    "#             #print(i)\n",
    "#             main_task_data = d[1]\n",
    "#             scaffold_task_data = d[0]\n",
    "#             papers_sc, reviews_sc, recs_sc, confs_sc = scaffold_task_data[0].transpose(1,2).float().to(device),\\\n",
    "#                                  scaffold_task_data[1].transpose(1,2).float().to(device), \\\n",
    "#                                  scaffold_task_data[2].float().to(device),\\\n",
    "#                                  scaffold_task_data[3].float().to(device)\n",
    "\n",
    "#             #print(ex.shape, subj.shape, opine.shape, recs_sc.shape, confs_sc.shape)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             optimizerMain.zero_grad()\n",
    "#             optimizerScaffold.zero_grad()\n",
    "#             out, rec_codes, conf_codes = model(papers_sc, reviews_sc)\n",
    "#             rec_preds, conf_preds = scaffold_task_predictor(rec_codes.view(out.shape[0], -1), conf_codes.view(out.shape[0], -1))\n",
    "            \n",
    "#             del papers_sc\n",
    "#             del reviews_sc\n",
    "            \n",
    "#             papers_sc, reviews_sc, sign_m = main_task_data[0].transpose(1,2).float().to(device),\\\n",
    "#                                  main_task_data[1].transpose(1,2).float().to(device), \\\n",
    "#                                  main_task_data[2].float().to(device)\n",
    "\n",
    "#             ex, subj, opine = sign_m[:,0], sign_m[:,1], sign_m[:,2]\n",
    "\n",
    "#             #do the for the main task\n",
    "#             out_m, rec_codes_m, conf_codes_m = model(papers_sc, reviews_sc)\n",
    "#             ex_preds, subj_preds, intensity_preds = main_task_predictor(out_m, rec_codes_m, conf_codes_m)\n",
    "#             #print(ex_preds.shape, subj_preds.shape, intensity_preds.shape)\n",
    "\n",
    "\n",
    "#             loss = Criterion([rec_preds.squeeze(1), conf_preds.squeeze(1), ex_preds.squeeze(1), subj_preds.squeeze(1), intensity_preds.squeeze(1)], [recs_sc, confs_sc, ex, subj, opine])\n",
    "#             epoch_loss.append(loss.item())\n",
    "#             loss.backward()\n",
    "#             optimizerMain.step()\n",
    "#             optimizerScaffold.step()\n",
    "#             optimizer.step()\n",
    "#         #print(\"Epoch {} Loss: {:.3f}\".format(epoch, np.average(epoch_loss)))\n",
    "#             del papers_sc\n",
    "#             del reviews_sc\n",
    "#             gc.collect()\n",
    "#         # \tbreak\n",
    "#         # break\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             eval_loss = evaluate(model, main_task_predictor, scaffold_task_predictor, Criterion, test_loader)\n",
    "\n",
    "#             print('Epoch: {} Train Loss: {:.6f}, Test Loss: {:.6f}'.format(epoch, np.average(epoch_loss),\\\n",
    "#                             eval_loss))\n",
    "#             # print(\"Exhaustive {}\".format(list(zip(ex_preds.data, ex.data))))\n",
    "#             # print(\"Subjectivity {}\".format(list(zip(subj_preds.data, subj.data))))\n",
    "#             # print(\"Intensity {}\".format(list(zip(intensity_preds.data, opine.data))))\n",
    "#             # print(\"Recommendation {}\".format(list(zip(rec_preds.data, recs_sc.data))))\n",
    "#             # print(\"Confidence {}\".format(list(zip(conf_preds.data, confs_sc.data))))\n",
    "\n",
    "#             #logging.info('Predictions, Actual : {}'.format(str(list(zip(recs_preds_t, recs_sc_t)))))\n",
    "#         #break\n",
    "\n",
    "\n",
    "# def main(args, dataloaders=(main_task_dataloader, scaffold_task_dataloader, test_data_loader)):\n",
    "#     train(args, dataloaders)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# main(args, dataloaders=(main_task_dataloader, scaffold_task_dataloader, test_data_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Test the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, main_task_predictor, scaffold_task_predictor, test_loader, Criterion=None):\n",
    "    with torch.no_grad():\n",
    "        eval_loss = []\n",
    "        ex_preds_, ex_actual = [], []\n",
    "        subj_preds_, subj_actual = [], []\n",
    "        int_preds_, int_actual = [], []\n",
    "        rec_preds_, rec_actual = [], []\n",
    "        conf_preds_, conf_actual = [], []\n",
    "        for i, d in enumerate(test_loader,0):\n",
    "            scaffold_task_data = d\n",
    "            papers_sc, reviews_sc, recs_sc, confs_sc, sign_m = scaffold_task_data[0].transpose(1,2).float().to(device),\\\n",
    "                             scaffold_task_data[1].transpose(1,2).float().to(device), \\\n",
    "                             scaffold_task_data[2].float().to(device),\\\n",
    "                             scaffold_task_data[3].float().to(device),\\\n",
    "                             scaffold_task_data[4].float().to(device)\n",
    "\n",
    "            ex, subj, opine = sign_m[:,0], sign_m[:,1], sign_m[:,2]\n",
    "            out, rec_codes, conf_codes = model(papers_sc, reviews_sc)\n",
    "            rec_preds, conf_preds = scaffold_task_predictor(rec_codes.view(out.shape[0], -1), conf_codes.view(out.shape[0], -1))\n",
    "\n",
    "            #out_m, rec_codes_m, conf_codes_m = model(papers_sc, reviews_sc)\n",
    "            ex_preds, subj_preds, intensity_preds = main_task_predictor(out, rec_codes, conf_codes)\n",
    "            ex_preds_.append(ex_preds.item())\n",
    "            ex_actual.append(ex.item())\n",
    "            subj_preds_.append(subj_preds.item())\n",
    "            subj_actual.append(subj.item())\n",
    "            int_preds_.append(intensity_preds.item())\n",
    "            int_actual.append(opine.item())\n",
    "\n",
    "\n",
    "\n",
    "            if Criterion != None:\n",
    "                loss = Criterion([rec_preds.squeeze(1), conf_preds.squeeze(1), ex_preds.squeeze(1), subj_preds.squeeze(1), intensity_preds.squeeze(1)], [recs_sc, confs_sc, ex, subj, opine])\n",
    "                eval_loss.append(loss.item())\n",
    "            else:\n",
    "                eval_loss.append(0)\n",
    "\n",
    "        return np.average(eval_loss), (ex_preds_, ex_actual), (subj_preds_, subj_actual), (int_preds_, int_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "checkpoint = torch.load('./MODELS/exp3.pt', map_location=device)\n",
    "args = SimpleNamespace(dim = checkpoint['dim'], upscale_dim = checkpoint['upscale_dim'], codes=checkpoint['codes']) \n",
    "model = Pipeline.Pipeline(args).to(device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "main_task_predictor = Prediction.MainPrediction(args.upscale_dim, args.upscale_dim, 32).to(device)\n",
    "main_task_predictor.load_state_dict(checkpoint['main_state_dict'])\n",
    "scaffold_task_predictor = Prediction.ScaffoldPrediction(args.upscale_dim, 8).to(device)\n",
    "scaffold_task_predictor.load_state_dict(checkpoint['scaffold_state_dict'])\n",
    "Criterion = MTLoss.MTLoss().to(device)\n",
    "Criterion.load_state_dict(checkpoint['criterion_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the Main Task Dataset...\n",
      "Reading the Scaffolds Task Dataset...\n",
      "Reading the test Dataset\n"
     ]
    }
   ],
   "source": [
    "_, _, test_dataset = getLoaders2(batch_size=1, slice=[-1,-1,-1])\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, exhaustive, subjective, opinion = evaluate(model, main_task_predictor, scaffold_task_predictor, test_data_loader, Criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(zip(*opinion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "opine_pred, opine_actual = opinion\n",
    "subj_pred, subj_actual = subjective\n",
    "exhaustive_pred, exhaustive_actual = exhaustive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "def cosine(a, b):\n",
    "    return dot(a,b)/(norm(a)*norm(b))\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(np.mean((np.asarray(predictions)-np.asarray(targets))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric(score):\n",
    "    RMSE = rmse(score[0], score[1])\n",
    "    sim = cosine(score[0], score[1])\n",
    "    print(\"RMSE: {}, cosine similarity: {}\".format(RMSE, sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5017433881250435, cosine similarity: 0.9895367837062644\n",
      "RMSE: 0.8054140323941106, cosine similarity: 0.982373976678173\n",
      "RMSE: 1.45750686097663, cosine similarity: 0.9397649115706209\n"
     ]
    }
   ],
   "source": [
    "for score in [(exhaustive_pred, exhaustive_actual), (subj_pred, subj_actual), (opine_pred, opine_actual)]:\n",
    "    get_metric(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.5518540202548305, cosine similarity: 0.8932938675323975\n",
      "RMSE: 2.1199669478437224, cosine similarity: 0.8705800832137459\n",
      "RMSE: 1.6752461775372902, cosine similarity: 0.9184800659455056\n"
     ]
    }
   ],
   "source": [
    "exhaustive_pred = [np.average(exhaustive_actual)]*len(exhaustive_actual)\n",
    "subj_pred = [np.average(subj_actual)]*len(exhaustive_actual)\n",
    "opine_pred = [np.average(opine_actual)]*len(exhaustive_actual)\n",
    "for score in [(exhaustive_pred, exhaustive_actual), (subj_pred, subj_actual), (opine_pred, opine_actual)]:\n",
    "    get_metric(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "path = './Data/SignData/test/reviews'\n",
    "reviews = os.listdir(path)\n",
    "filenames = os.listdir('./Data/SignData/test_data/')\n",
    "\n",
    "review_text = []\n",
    "indices = []\n",
    "for i, filename in enumerate(filenames):\n",
    "    split = filename.split('_')\n",
    "    fname, count = ''.join(c for c in split[:-1]), split[-1]\n",
    "    if fname in reviews:\n",
    "        rev = json.load(open(os.path.join(path, fname)))['reviews'][int(count)]\n",
    "        review_text.append(rev)\n",
    "    else:\n",
    "        indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "dict_ = defaultdict(lambda: {})\n",
    "for i in range(len(opine_pred)):\n",
    "    scores = {}\n",
    "    if i not in indices:\n",
    "        scores['layer1'] = (exhaustive_pred[i], exhaustive_actual[i])\n",
    "        scores['layer2'] = (subj_pred[i], subj_actual[i])\n",
    "        scores['layer3'] = (opine_pred[i], opine_actual[i])\n",
    "        dict_[i] = scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 89, 66, 62, 59, 54, 37)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "91, 89, 66, 62, 59, 54, (37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "l1, l2 = np.array([0.05428571,0.93013972,-0.99966815]), np.array([33.26288336,252.25067107,0.99966679])\n",
    "def normalize(s):\n",
    "    s = np.array(s)\n",
    "    sent = s[2]\n",
    "    s = (s - l1)/(l2 - l1)\n",
    "    s = (s*9) + 1\n",
    "    s[2] = (((sent - (-1))*9)/2) + 1\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in [79]:\n",
    "#     new_scores = normalize(review_text[i]['SCORES'])\n",
    "#     print(new_scores)\n",
    "#     print(review_text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, review in enumerate(review_text):\n",
    "    new_scores = normalize(review_text[i]['SCORES'])\n",
    "    for k,v in dict_.items():\n",
    "        if np.round(dict_[k]['layer1'][1], decimals=3) == np.round(new_scores[0], decimals=3):\n",
    "            review_text[i]['PREDICTIONS'] = dict_[k]\n",
    "            review_text[i]['NORMALISED'] = new_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = []\n",
    "# for k,v in dict_.items():\n",
    "#     pred = []\n",
    "#     pred.append(np.round(dict_[k]['layer1'][0], 3))\n",
    "#     pred.append(np.round(dict_[k]['layer2'][0], 3))\n",
    "#     pred.append(np.round(dict_[k]['layer3'][0], 3))\n",
    "#     predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECOMMENDATION</th>\n",
       "      <th>REVIEW TITLE</th>\n",
       "      <th>comments</th>\n",
       "      <th>VARIANCE</th>\n",
       "      <th>CONFIDENCE</th>\n",
       "      <th>SCORES</th>\n",
       "      <th>ID</th>\n",
       "      <th>Layer 1</th>\n",
       "      <th>Layer 1 N</th>\n",
       "      <th>Layer 2</th>\n",
       "      <th>Layer 2 N</th>\n",
       "      <th>Layer 3</th>\n",
       "      <th>Layer 3 N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>\"Summary: \\nThe authors present a simple varia...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[16.587, 142.202, 0.044]</td>\n",
       "      <td>Hyp3i2xRb.json</td>\n",
       "      <td>16.587</td>\n",
       "      <td>5.481</td>\n",
       "      <td>142.202</td>\n",
       "      <td>6.059</td>\n",
       "      <td>0.044</td>\n",
       "      <td>5.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>\"The paper entitled 'Siamese Survival Analysis...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[1.28, 9.568, -0.34]</td>\n",
       "      <td>HkjL6MiTb.json</td>\n",
       "      <td>1.280</td>\n",
       "      <td>1.332</td>\n",
       "      <td>9.568</td>\n",
       "      <td>1.309</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>3.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>\"In this paper, the authors define a simulated...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[11.172, 160.306, -0.672]</td>\n",
       "      <td>B1EGg7ZCb.json</td>\n",
       "      <td>11.172</td>\n",
       "      <td>4.013</td>\n",
       "      <td>160.306</td>\n",
       "      <td>6.707</td>\n",
       "      <td>-0.672</td>\n",
       "      <td>2.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>\"Summary:\\n The paper presents an unsupervised...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[28.766, 328.435, -0.933]</td>\n",
       "      <td>HyI6s40a-.json</td>\n",
       "      <td>28.766</td>\n",
       "      <td>8.781</td>\n",
       "      <td>328.435</td>\n",
       "      <td>12.728</td>\n",
       "      <td>-0.933</td>\n",
       "      <td>1.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>\"The paper introduces a new memory mechanism s...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[3.718, 42.942, -0.455]</td>\n",
       "      <td>Bk9zbyZCZ.json</td>\n",
       "      <td>3.718</td>\n",
       "      <td>1.993</td>\n",
       "      <td>42.942</td>\n",
       "      <td>2.504</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>3.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>\"The paper presents a novel representation of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[2.031, 21.92, 0.189]</td>\n",
       "      <td>HkOhuyA6-.json</td>\n",
       "      <td>2.031</td>\n",
       "      <td>1.536</td>\n",
       "      <td>21.920</td>\n",
       "      <td>1.752</td>\n",
       "      <td>0.189</td>\n",
       "      <td>6.349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>\"This paper investigates the complexity of neu...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[4.023, 50.659, 0.685]</td>\n",
       "      <td>Sy-tszZRZ.json</td>\n",
       "      <td>4.023</td>\n",
       "      <td>2.076</td>\n",
       "      <td>50.659</td>\n",
       "      <td>2.781</td>\n",
       "      <td>0.685</td>\n",
       "      <td>8.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>\"This paper is an extension of the \\u201cproto...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[6.816, 64.86, -0.322]</td>\n",
       "      <td>HJcSzz-CZ.json</td>\n",
       "      <td>6.816</td>\n",
       "      <td>2.832</td>\n",
       "      <td>64.860</td>\n",
       "      <td>3.289</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>4.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>\"The authors tackle the problem of estimating ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[6.889, 85.239, -0.781]</td>\n",
       "      <td>HkjL6MiTb.json</td>\n",
       "      <td>6.889</td>\n",
       "      <td>2.852</td>\n",
       "      <td>85.239</td>\n",
       "      <td>4.019</td>\n",
       "      <td>-0.781</td>\n",
       "      <td>1.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>\"The authors present an algorithm for training...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[2.216, 24.164, -0.332]</td>\n",
       "      <td>ByOnmlWC-.json</td>\n",
       "      <td>2.216</td>\n",
       "      <td>1.586</td>\n",
       "      <td>24.164</td>\n",
       "      <td>1.832</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>4.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RECOMMENDATION REVIEW TITLE  \\\n",
       "0                7                \n",
       "1                4                \n",
       "2                3                \n",
       "3                7                \n",
       "4                7                \n",
       "..             ...          ...   \n",
       "76               7                \n",
       "77               6                \n",
       "78               6                \n",
       "79               4                \n",
       "80               6                \n",
       "\n",
       "                                             comments  VARIANCE  CONFIDENCE  \\\n",
       "0   \"Summary: \\nThe authors present a simple varia...         0           4   \n",
       "1   \"The paper entitled 'Siamese Survival Analysis...         0           5   \n",
       "2   \"In this paper, the authors define a simulated...         0           3   \n",
       "3   \"Summary:\\n The paper presents an unsupervised...         0           3   \n",
       "4   \"The paper introduces a new memory mechanism s...         0           4   \n",
       "..                                                ...       ...         ...   \n",
       "76  \"The paper presents a novel representation of ...         0           3   \n",
       "77  \"This paper investigates the complexity of neu...         0           5   \n",
       "78  \"This paper is an extension of the \\u201cproto...         0           5   \n",
       "79  \"The authors tackle the problem of estimating ...         0           4   \n",
       "80  \"The authors present an algorithm for training...         0           4   \n",
       "\n",
       "                       SCORES              ID  Layer 1  Layer 1 N  Layer 2  \\\n",
       "0    [16.587, 142.202, 0.044]  Hyp3i2xRb.json   16.587      5.481  142.202   \n",
       "1        [1.28, 9.568, -0.34]  HkjL6MiTb.json    1.280      1.332    9.568   \n",
       "2   [11.172, 160.306, -0.672]  B1EGg7ZCb.json   11.172      4.013  160.306   \n",
       "3   [28.766, 328.435, -0.933]  HyI6s40a-.json   28.766      8.781  328.435   \n",
       "4     [3.718, 42.942, -0.455]  Bk9zbyZCZ.json    3.718      1.993   42.942   \n",
       "..                        ...             ...      ...        ...      ...   \n",
       "76      [2.031, 21.92, 0.189]  HkOhuyA6-.json    2.031      1.536   21.920   \n",
       "77     [4.023, 50.659, 0.685]  Sy-tszZRZ.json    4.023      2.076   50.659   \n",
       "78     [6.816, 64.86, -0.322]  HJcSzz-CZ.json    6.816      2.832   64.860   \n",
       "79    [6.889, 85.239, -0.781]  HkjL6MiTb.json    6.889      2.852   85.239   \n",
       "80    [2.216, 24.164, -0.332]  ByOnmlWC-.json    2.216      1.586   24.164   \n",
       "\n",
       "    Layer 2 N  Layer 3  Layer 3 N  \n",
       "0       6.059    0.044      5.699  \n",
       "1       1.309   -0.340      3.968  \n",
       "2       6.707   -0.672      2.478  \n",
       "3      12.728   -0.933      1.299  \n",
       "4       2.504   -0.455      3.453  \n",
       "..        ...      ...        ...  \n",
       "76      1.752    0.189      6.349  \n",
       "77      2.781    0.685      8.583  \n",
       "78      3.289   -0.322      4.051  \n",
       "79      4.019   -0.781      1.985  \n",
       "80      1.832   -0.332      4.004  \n",
       "\n",
       "[81 rows x 13 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# tst_reviews = pd.read_csv('Test_Reviews.csv')\n",
    "# tst_reviews[\"Predictions\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, rev in enumerate(review_text):\n",
    "#     print(i)\n",
    "#     print(rev['PREDICTIONS'])\n",
    "#     print(rev['NORMALISED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tst_indices = [0, 20, 50, 51] #, 43, 29, 28, 8, 3]\n",
    "# for ind in tst_indices:\n",
    "#     print(review_text[ind])\n",
    "#     print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Study Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Round(num):\n",
    "#     return np.round(num, decimals=3)\n",
    "\n",
    "# reviews = []\n",
    "# import csv\n",
    "# for i, review in enumerate(review_text):\n",
    "#     print(i)\n",
    "#     new_scores = list(map(lambda x: Round(x), normalize(review_text[i]['SCORES'])))\n",
    "#     review['SCORES'] = list(map(lambda x: Round(x), review['SCORES']))\n",
    "#     preds = [review_text[i]['PREDICTIONS']['layer1'][0], review_text[i]['PREDICTIONS']['layer2'][0], review_text[i]['PREDICTIONS']['layer3'][0]]\n",
    "#     review['PREDICTIONS'] = list(map(lambda x: Round(x), preds))\n",
    "#     review['Layer 1'], review['Layer 1 N'] = review['SCORES'][0], new_scores[0]\n",
    "#     review['Layer 2'], review['Layer 2 N'] = review['SCORES'][1], new_scores[1]\n",
    "#     review['Layer 3'], review['Layer 3 N'] = review['SCORES'][2], new_scores[2]\n",
    "#     reviews.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_names = reviews[0].keys()\n",
    "with open('Test_Reviews_.csv', 'w') as csvfile: \n",
    "    writer = csv.DictWriter(csvfile, fieldnames = field_names) \n",
    "    writer.writeheader() \n",
    "    writer.writerows(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECOMMENDATION</th>\n",
       "      <th>REVIEW TITLE</th>\n",
       "      <th>comments</th>\n",
       "      <th>VARIANCE</th>\n",
       "      <th>CONFIDENCE</th>\n",
       "      <th>SCORES</th>\n",
       "      <th>PREDICTIONS</th>\n",
       "      <th>NORMALISED</th>\n",
       "      <th>Layer 1</th>\n",
       "      <th>Layer 1 N</th>\n",
       "      <th>Layer 2</th>\n",
       "      <th>Layer 2 N</th>\n",
       "      <th>Layer 3</th>\n",
       "      <th>Layer 3 N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>\"Summary: \\nThe authors present a simple varia...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[16.587, 142.202, 0.044]</td>\n",
       "      <td>[5.478, 6.908, 3.191]</td>\n",
       "      <td>[5.48062988 6.05905833 5.69919155]</td>\n",
       "      <td>16.587</td>\n",
       "      <td>5.481</td>\n",
       "      <td>142.202</td>\n",
       "      <td>6.059</td>\n",
       "      <td>0.044</td>\n",
       "      <td>5.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>\"The paper entitled 'Siamese Survival Analysis...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[1.28, 9.568, -0.34]</td>\n",
       "      <td>[1.449, 1.612, 4.07]</td>\n",
       "      <td>[1.33218592 1.30933134 3.96794648]</td>\n",
       "      <td>1.280</td>\n",
       "      <td>1.332</td>\n",
       "      <td>9.568</td>\n",
       "      <td>1.309</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>3.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>\"In this paper, the authors define a simulated...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[11.172, 160.306, -0.672]</td>\n",
       "      <td>[4.463, 5.594, 2.866]</td>\n",
       "      <td>[4.01313185 6.70739261 2.47807651]</td>\n",
       "      <td>11.172</td>\n",
       "      <td>4.013</td>\n",
       "      <td>160.306</td>\n",
       "      <td>6.707</td>\n",
       "      <td>-0.672</td>\n",
       "      <td>2.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>\"Summary:\\n The paper presents an unsupervised...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[28.766, 328.435, -0.933]</td>\n",
       "      <td>[8.405, 10.596, 2.652]</td>\n",
       "      <td>[ 8.78125838 12.72822394  1.29945041]</td>\n",
       "      <td>28.766</td>\n",
       "      <td>8.781</td>\n",
       "      <td>328.435</td>\n",
       "      <td>12.728</td>\n",
       "      <td>-0.933</td>\n",
       "      <td>1.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>\"The paper introduces a new memory mechanism s...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[3.718, 42.942, -0.455]</td>\n",
       "      <td>[2.159, 2.73, 4.341]</td>\n",
       "      <td>[1.99291843 2.50449618 3.45302132]</td>\n",
       "      <td>3.718</td>\n",
       "      <td>1.993</td>\n",
       "      <td>42.942</td>\n",
       "      <td>2.504</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>3.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>\"The majority of the paper is focused on the o...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.854, 10.572, 0.522]</td>\n",
       "      <td>[1.464, 1.66, 4.214]</td>\n",
       "      <td>[1.21681132 1.34527799 7.84947663]</td>\n",
       "      <td>0.854</td>\n",
       "      <td>1.217</td>\n",
       "      <td>10.572</td>\n",
       "      <td>1.345</td>\n",
       "      <td>0.522</td>\n",
       "      <td>7.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>\"The paper presents a novel representation of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[2.031, 21.92, 0.189]</td>\n",
       "      <td>[1.366, 1.54, 4.307]</td>\n",
       "      <td>[1.5358337  1.75166137 6.34885049]</td>\n",
       "      <td>2.031</td>\n",
       "      <td>1.536</td>\n",
       "      <td>21.920</td>\n",
       "      <td>1.752</td>\n",
       "      <td>0.189</td>\n",
       "      <td>6.349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>\"This paper investigates the complexity of neu...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[4.023, 50.659, 0.685]</td>\n",
       "      <td>[2.166, 3.052, 5.553]</td>\n",
       "      <td>[2.07553903 2.78082102 8.58274539]</td>\n",
       "      <td>4.023</td>\n",
       "      <td>2.076</td>\n",
       "      <td>50.659</td>\n",
       "      <td>2.781</td>\n",
       "      <td>0.685</td>\n",
       "      <td>8.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>\"This paper is an extension of the \\u201cproto...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[6.816, 64.86, -0.322]</td>\n",
       "      <td>[2.802, 3.496, 3.618]</td>\n",
       "      <td>[2.83244285 3.28939428 4.05086217]</td>\n",
       "      <td>6.816</td>\n",
       "      <td>2.832</td>\n",
       "      <td>64.860</td>\n",
       "      <td>3.289</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>4.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>\"The authors tackle the problem of estimating ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[6.889, 85.239, -0.781]</td>\n",
       "      <td>[3.485, 4.346, 2.992]</td>\n",
       "      <td>[2.8522656  4.01916201 1.98517081]</td>\n",
       "      <td>6.889</td>\n",
       "      <td>2.852</td>\n",
       "      <td>85.239</td>\n",
       "      <td>4.019</td>\n",
       "      <td>-0.781</td>\n",
       "      <td>1.985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RECOMMENDATION REVIEW TITLE  \\\n",
       "0                7                \n",
       "1                4                \n",
       "2                3                \n",
       "3                7                \n",
       "4                7                \n",
       "..             ...          ...   \n",
       "75               4                \n",
       "76               7                \n",
       "77               6                \n",
       "78               6                \n",
       "79               4                \n",
       "\n",
       "                                             comments  VARIANCE  CONFIDENCE  \\\n",
       "0   \"Summary: \\nThe authors present a simple varia...         0           4   \n",
       "1   \"The paper entitled 'Siamese Survival Analysis...         0           5   \n",
       "2   \"In this paper, the authors define a simulated...         0           3   \n",
       "3   \"Summary:\\n The paper presents an unsupervised...         0           3   \n",
       "4   \"The paper introduces a new memory mechanism s...         0           4   \n",
       "..                                                ...       ...         ...   \n",
       "75  \"The majority of the paper is focused on the o...         0           5   \n",
       "76  \"The paper presents a novel representation of ...         0           3   \n",
       "77  \"This paper investigates the complexity of neu...         0           5   \n",
       "78  \"This paper is an extension of the \\u201cproto...         0           5   \n",
       "79  \"The authors tackle the problem of estimating ...         0           4   \n",
       "\n",
       "                       SCORES             PREDICTIONS  \\\n",
       "0    [16.587, 142.202, 0.044]   [5.478, 6.908, 3.191]   \n",
       "1        [1.28, 9.568, -0.34]    [1.449, 1.612, 4.07]   \n",
       "2   [11.172, 160.306, -0.672]   [4.463, 5.594, 2.866]   \n",
       "3   [28.766, 328.435, -0.933]  [8.405, 10.596, 2.652]   \n",
       "4     [3.718, 42.942, -0.455]    [2.159, 2.73, 4.341]   \n",
       "..                        ...                     ...   \n",
       "75     [0.854, 10.572, 0.522]    [1.464, 1.66, 4.214]   \n",
       "76      [2.031, 21.92, 0.189]    [1.366, 1.54, 4.307]   \n",
       "77     [4.023, 50.659, 0.685]   [2.166, 3.052, 5.553]   \n",
       "78     [6.816, 64.86, -0.322]   [2.802, 3.496, 3.618]   \n",
       "79    [6.889, 85.239, -0.781]   [3.485, 4.346, 2.992]   \n",
       "\n",
       "                               NORMALISED  Layer 1  Layer 1 N  Layer 2  \\\n",
       "0      [5.48062988 6.05905833 5.69919155]   16.587      5.481  142.202   \n",
       "1      [1.33218592 1.30933134 3.96794648]    1.280      1.332    9.568   \n",
       "2      [4.01313185 6.70739261 2.47807651]   11.172      4.013  160.306   \n",
       "3   [ 8.78125838 12.72822394  1.29945041]   28.766      8.781  328.435   \n",
       "4      [1.99291843 2.50449618 3.45302132]    3.718      1.993   42.942   \n",
       "..                                    ...      ...        ...      ...   \n",
       "75     [1.21681132 1.34527799 7.84947663]    0.854      1.217   10.572   \n",
       "76     [1.5358337  1.75166137 6.34885049]    2.031      1.536   21.920   \n",
       "77     [2.07553903 2.78082102 8.58274539]    4.023      2.076   50.659   \n",
       "78     [2.83244285 3.28939428 4.05086217]    6.816      2.832   64.860   \n",
       "79     [2.8522656  4.01916201 1.98517081]    6.889      2.852   85.239   \n",
       "\n",
       "    Layer 2 N  Layer 3  Layer 3 N  \n",
       "0       6.059    0.044      5.699  \n",
       "1       1.309   -0.340      3.968  \n",
       "2       6.707   -0.672      2.478  \n",
       "3      12.728   -0.933      1.299  \n",
       "4       2.504   -0.455      3.453  \n",
       "..        ...      ...        ...  \n",
       "75      1.345    0.522      7.849  \n",
       "76      1.752    0.189      6.349  \n",
       "77      2.781    0.685      8.583  \n",
       "78      3.289   -0.322      4.051  \n",
       "79      4.019   -0.781      1.985  \n",
       "\n",
       "[80 rows x 14 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = pd.read_csv('Test_Reviews_.csv')\n",
    "tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECOMMENDATION</th>\n",
       "      <th>REVIEW TITLE</th>\n",
       "      <th>comments</th>\n",
       "      <th>VARIANCE</th>\n",
       "      <th>CONFIDENCE</th>\n",
       "      <th>SCORES</th>\n",
       "      <th>ID</th>\n",
       "      <th>Layer 1</th>\n",
       "      <th>Layer 1 N</th>\n",
       "      <th>Layer 2</th>\n",
       "      <th>Layer 2 N</th>\n",
       "      <th>Layer 3</th>\n",
       "      <th>Layer 3 N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>\"Summary: \\nThe authors present a simple varia...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[16.587, 142.202, 0.044]</td>\n",
       "      <td>Hyp3i2xRb.json</td>\n",
       "      <td>16.587</td>\n",
       "      <td>5.481</td>\n",
       "      <td>142.202</td>\n",
       "      <td>6.059</td>\n",
       "      <td>0.044</td>\n",
       "      <td>5.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>\"The paper entitled 'Siamese Survival Analysis...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[1.28, 9.568, -0.34]</td>\n",
       "      <td>HkjL6MiTb.json</td>\n",
       "      <td>1.280</td>\n",
       "      <td>1.332</td>\n",
       "      <td>9.568</td>\n",
       "      <td>1.309</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>3.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>\"In this paper, the authors define a simulated...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[11.172, 160.306, -0.672]</td>\n",
       "      <td>B1EGg7ZCb.json</td>\n",
       "      <td>11.172</td>\n",
       "      <td>4.013</td>\n",
       "      <td>160.306</td>\n",
       "      <td>6.707</td>\n",
       "      <td>-0.672</td>\n",
       "      <td>2.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>\"Summary:\\n The paper presents an unsupervised...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[28.766, 328.435, -0.933]</td>\n",
       "      <td>HyI6s40a-.json</td>\n",
       "      <td>28.766</td>\n",
       "      <td>8.781</td>\n",
       "      <td>328.435</td>\n",
       "      <td>12.728</td>\n",
       "      <td>-0.933</td>\n",
       "      <td>1.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>\"The paper introduces a new memory mechanism s...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[3.718, 42.942, -0.455]</td>\n",
       "      <td>Bk9zbyZCZ.json</td>\n",
       "      <td>3.718</td>\n",
       "      <td>1.993</td>\n",
       "      <td>42.942</td>\n",
       "      <td>2.504</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>3.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>\"The paper presents a novel representation of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[2.031, 21.92, 0.189]</td>\n",
       "      <td>HkOhuyA6-.json</td>\n",
       "      <td>2.031</td>\n",
       "      <td>1.536</td>\n",
       "      <td>21.920</td>\n",
       "      <td>1.752</td>\n",
       "      <td>0.189</td>\n",
       "      <td>6.349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>\"This paper investigates the complexity of neu...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[4.023, 50.659, 0.685]</td>\n",
       "      <td>Sy-tszZRZ.json</td>\n",
       "      <td>4.023</td>\n",
       "      <td>2.076</td>\n",
       "      <td>50.659</td>\n",
       "      <td>2.781</td>\n",
       "      <td>0.685</td>\n",
       "      <td>8.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>\"This paper is an extension of the \\u201cproto...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[6.816, 64.86, -0.322]</td>\n",
       "      <td>HJcSzz-CZ.json</td>\n",
       "      <td>6.816</td>\n",
       "      <td>2.832</td>\n",
       "      <td>64.860</td>\n",
       "      <td>3.289</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>4.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>\"The authors tackle the problem of estimating ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[6.889, 85.239, -0.781]</td>\n",
       "      <td>HkjL6MiTb.json</td>\n",
       "      <td>6.889</td>\n",
       "      <td>2.852</td>\n",
       "      <td>85.239</td>\n",
       "      <td>4.019</td>\n",
       "      <td>-0.781</td>\n",
       "      <td>1.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>\"The authors present an algorithm for training...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[2.216, 24.164, -0.332]</td>\n",
       "      <td>ByOnmlWC-.json</td>\n",
       "      <td>2.216</td>\n",
       "      <td>1.586</td>\n",
       "      <td>24.164</td>\n",
       "      <td>1.832</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>4.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RECOMMENDATION REVIEW TITLE  \\\n",
       "0                7                \n",
       "1                4                \n",
       "2                3                \n",
       "3                7                \n",
       "4                7                \n",
       "..             ...          ...   \n",
       "76               7                \n",
       "77               6                \n",
       "78               6                \n",
       "79               4                \n",
       "80               6                \n",
       "\n",
       "                                             comments  VARIANCE  CONFIDENCE  \\\n",
       "0   \"Summary: \\nThe authors present a simple varia...         0           4   \n",
       "1   \"The paper entitled 'Siamese Survival Analysis...         0           5   \n",
       "2   \"In this paper, the authors define a simulated...         0           3   \n",
       "3   \"Summary:\\n The paper presents an unsupervised...         0           3   \n",
       "4   \"The paper introduces a new memory mechanism s...         0           4   \n",
       "..                                                ...       ...         ...   \n",
       "76  \"The paper presents a novel representation of ...         0           3   \n",
       "77  \"This paper investigates the complexity of neu...         0           5   \n",
       "78  \"This paper is an extension of the \\u201cproto...         0           5   \n",
       "79  \"The authors tackle the problem of estimating ...         0           4   \n",
       "80  \"The authors present an algorithm for training...         0           4   \n",
       "\n",
       "                       SCORES              ID  Layer 1  Layer 1 N  Layer 2  \\\n",
       "0    [16.587, 142.202, 0.044]  Hyp3i2xRb.json   16.587      5.481  142.202   \n",
       "1        [1.28, 9.568, -0.34]  HkjL6MiTb.json    1.280      1.332    9.568   \n",
       "2   [11.172, 160.306, -0.672]  B1EGg7ZCb.json   11.172      4.013  160.306   \n",
       "3   [28.766, 328.435, -0.933]  HyI6s40a-.json   28.766      8.781  328.435   \n",
       "4     [3.718, 42.942, -0.455]  Bk9zbyZCZ.json    3.718      1.993   42.942   \n",
       "..                        ...             ...      ...        ...      ...   \n",
       "76      [2.031, 21.92, 0.189]  HkOhuyA6-.json    2.031      1.536   21.920   \n",
       "77     [4.023, 50.659, 0.685]  Sy-tszZRZ.json    4.023      2.076   50.659   \n",
       "78     [6.816, 64.86, -0.322]  HJcSzz-CZ.json    6.816      2.832   64.860   \n",
       "79    [6.889, 85.239, -0.781]  HkjL6MiTb.json    6.889      2.852   85.239   \n",
       "80    [2.216, 24.164, -0.332]  ByOnmlWC-.json    2.216      1.586   24.164   \n",
       "\n",
       "    Layer 2 N  Layer 3  Layer 3 N  \n",
       "0       6.059    0.044      5.699  \n",
       "1       1.309   -0.340      3.968  \n",
       "2       6.707   -0.672      2.478  \n",
       "3      12.728   -0.933      1.299  \n",
       "4       2.504   -0.455      3.453  \n",
       "..        ...      ...        ...  \n",
       "76      1.752    0.189      6.349  \n",
       "77      2.781    0.685      8.583  \n",
       "78      3.289   -0.322      4.051  \n",
       "79      4.019   -0.781      1.985  \n",
       "80      1.832   -0.332      4.004  \n",
       "\n",
       "[81 rows x 13 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_reviews"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rajeev2",
   "language": "python",
   "name": "rajeev2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
